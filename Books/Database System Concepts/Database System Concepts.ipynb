{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database System Concepts\n",
    "\n",
    "*Authors: Abraham Silberschatz, Henry F. Korth, and S. Sudarshan*\n",
    "\n",
    "**ISBN: 978-0-07-352332-3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a name=\"toc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Chapter 1: Introduction](#chapter1)\n",
    "- [Chapter 2: Introduction to the Relational Model](#chapter2)\n",
    "- [Chapter 3: Introduction to SQL](#chapter3)\n",
    "- [Chapter 4: Intermediate SQL](#chapter4)\n",
    "- [Chapter 6: Formal Relational Query Languages](#chapter6)\n",
    "- [Chapter 7: Database Design and the E-R Model](#chapter7)\n",
    "- [Chapter 8: Relational Database Design](#chapter8)\n",
    "- [Chapter 10: Storage and File Structure](#chapter10)\n",
    "- [Chapter 11: Indexing and Hashing](#chapter11)\n",
    "- [Chapter 12: Query Processing](#chapter12)\n",
    "- [Chapter 13: Query Optimization](#chapter13)\n",
    "- [Chapter 14: Transactions](#chapter14)\n",
    "- [Chapter 15: Concurrency Control](#chapter15)\n",
    "- [Chapter 16: Recovery System](#chapter16)\n",
    "- [Chapter 20: Data Warehousing and Mining](#chapter20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.h2database.com/html/main.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%defaultDatasource jdbc:h2:mem:db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A: Detailed University Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![E-R Diagram for University](images/Figure_A_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS classroom (\n",
    "    building    VARCHAR(15),\n",
    "    roomNumber  VARCHAR(7),\n",
    "    capacity    NUMERIC(4,0),\n",
    "    PRIMARY KEY (building, roomNumber)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS department (\n",
    "    deptName    VARCHAR(20),\n",
    "    building    VARCHAR(15),\n",
    "    budget      NUMERIC(12,2) CHECK (budget > 0),\n",
    "    PRIMARY KEY (deptName)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS course (\n",
    "    courseId    VARCHAR(8),\n",
    "    title       VARCHAR(50),\n",
    "    deptName    VARCHAR(20),\n",
    "    credits     NUMERIC(2,0) CHECK (credits > 0),\n",
    "    PRIMARY KEY (courseId),\n",
    "    FOREIGN KEY (deptName) REFERENCES department ON DELETE SET NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS instructor (\n",
    "    instructorId VARCHAR(5),\n",
    "    name         VARCHAR(20) NOT NULL,\n",
    "    deptName     VARCHAR(20),\n",
    "    salary       NUMERIC(8,2) CHECK (salary > 29000),\n",
    "    PRIMARY KEY (instructorId),\n",
    "    FOREIGN KEY (deptName) REFERENCES department ON DELETE SET NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS section (\n",
    "    courseId    VARCHAR(8),\n",
    "    sectionId   VARCHAR(8),\n",
    "    semester    VARCHAR(6) CHECK (semester IN ('Fall', 'Winter', 'Spring', 'Summer')),\n",
    "    year        NUMERIC(4,0) CHECK (year > 1701 AND year < 2100),\n",
    "    building    VARCHAR(15),\n",
    "    roomNumber  VARCHAR(7),\n",
    "    timeSlotId  VARCHAR(4),\n",
    "    PRIMARY KEY (courseId, sectionId, semester, year),\n",
    "    FOREIGN KEY (courseId) REFERENCES course ON DELETE CASCADE,\n",
    "    FOREIGN KEY (building, roomNumber) REFERENCES classroom ON DELETE SET NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS teaches (\n",
    "    instructorId VARCHAR(5),\n",
    "    courseId     VARCHAR(8),\n",
    "    sectionId    VARCHAR(8),\n",
    "    semester     VARCHAR(6),\n",
    "    year         NUMERIC(4,0),\n",
    "    PRIMARY KEY (instructorId, courseId, sectionId, semester, year),\n",
    "    FOREIGN KEY (courseId, sectionId, semester, year) REFERENCES section ON DELETE CASCADE,\n",
    "    FOREIGN KEY (instructorId) REFERENCES instructor ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS student (\n",
    "    studentId   VARCHAR(5),\n",
    "    name        VARCHAR(20) NOT NULL,\n",
    "    deptName    VARCHAR(20),\n",
    "    totalCredit NUMERIC(3,0) CHECK (totalCredit >= 0),\n",
    "    PRIMARY KEY (studentId),\n",
    "    FOREIGN KEY (deptName) REFERENCES department ON DELETE SET NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS takes (\n",
    "    studentId   VARCHAR(5),\n",
    "    courseId    VARCHAR(8),\n",
    "    sectionId   VARCHAR(8),\n",
    "    semester    VARCHAR(6),\n",
    "    year        NUMERIC(4,0),\n",
    "    grade       VARCHAR(2),\n",
    "    PRIMARY KEY (studentId, courseId, sectionId, semester, year),\n",
    "    FOREIGN KEY (courseId, sectionId, semester, year) REFERENCES section ON DELETE CASCADE,\n",
    "    FOREIGN KEY (studentID) REFERENCES student ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS advisor (\n",
    "    studentId    VARCHAR(5),\n",
    "    instructorId VARCHAR(5),\n",
    "    PRIMARY KEY (studentId),\n",
    "    FOREIGN KEY (studentId) REFERENCES student ON DELETE CASCADE,\n",
    "    FOREIGN KEY (instructorId) REFERENCES instructor ON DELETE SET NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS prereq (\n",
    "    courseId    VARCHAR(8),\n",
    "    prereqId    VARCHAR(8),\n",
    "    PRIMARY KEY (courseId, prereqId),\n",
    "    FOREIGN KEY (courseId) REFERENCES course ON DELETE CASCADE,\n",
    "    FOREIGN KEY (prereqId) REFERENCES course\n",
    ");\n",
    "\n",
    "CREATE TABLE timeSlot (\n",
    "    timeSlotId  VARCHAR(4),\n",
    "    day         VARCHAR(1),\n",
    "    startHr     NUMERIC(2) CHECK (startHr >= 0 AND startHr < 24),\n",
    "    startMin    NUMERIC(2) CHECK (startMin >= 0 AND startMin < 60),\n",
    "    endHr       NUMERIC(2) CHECK (endHr >= 0 AND endHr < 24),\n",
    "    endMin      NUMERIC(2) CHECK (endMin >= 0 AND endMin < 60),\n",
    "    PRIMARY KEY (timeSlotId, day, startHr, startMin)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Clear Tables\n",
    "DELETE FROM prereq;\n",
    "DELETE FROM timeSlot;\n",
    "DELETE FROM advisor;\n",
    "DELETE FROM takes;\n",
    "DELETE FROM student;\n",
    "DELETE FROM teaches;\n",
    "DELETE FROM section;\n",
    "DELETE FROM instructor;\n",
    "DELETE FROM course;\n",
    "DELETE FROM department;\n",
    "DELETE FROM classroom;\n",
    "-- Classroom\n",
    "INSERT INTO classroom VALUES ('Packard', '101', '500');\n",
    "INSERT INTO classroom VALUES ('Painter', '514', '10');\n",
    "INSERT INTO classroom VALUES ('Taylor', '3128', '70');\n",
    "INSERT INTO classroom VALUES ('Watson', '100', '30');\n",
    "INSERT INTO classroom VALUES ('Watson', '120', '50');\n",
    "-- Department\n",
    "INSERT INTO department VALUES ('Biology', 'Watson', '90000');\n",
    "INSERT INTO department VALUES ('Comp. Sci.', 'Taylor', '100000');\n",
    "INSERT INTO department VALUES ('Elec. Eng.', 'Taylor', '85000');\n",
    "INSERT INTO department VALUES ('Finance', 'Painter', '120000');\n",
    "INSERT INTO department VALUES ('History', 'Painter', '50000');\n",
    "INSERT INTO department VALUES ('Music', 'Packard', '80000');\n",
    "INSERT INTO department VALUES ('Physics', 'Watson', '70000');\n",
    "-- Course\n",
    "INSERT INTO course VALUES ('BIO-101', 'Intro. to Biology', 'Biology', '4');\n",
    "INSERT INTO course VALUES ('BIO-301', 'Genetics', 'Biology', '4');\n",
    "INSERT INTO course VALUES ('BIO-399', 'Computational Biology', 'Biology', '3');\n",
    "INSERT INTO course VALUES ('CS-101', 'Intro. to Computer Science', 'Comp. Sci.', '4');\n",
    "INSERT INTO course VALUES ('CS-190', 'Game Design', 'Comp. Sci.', '4');\n",
    "INSERT INTO course VALUES ('CS-315', 'Robotics', 'Comp. Sci.', '3');\n",
    "INSERT INTO course VALUES ('CS-319', 'Image Processing', 'Comp. Sci.', '3');\n",
    "INSERT INTO course VALUES ('CS-347', 'Database System Concepts', 'Comp. Sci.', '3');\n",
    "INSERT INTO course VALUES ('EE-181', 'Intro. to Digital Systems', 'Elec. Eng.', '3');\n",
    "INSERT INTO course VALUES ('FIN-201', 'Investment Banking', 'Finance', '3');\n",
    "INSERT INTO course VALUES ('HIS-351', 'World History', 'History', '3');\n",
    "INSERT INTO course VALUES ('MU-199', 'Music Video Production', 'Music', '3');\n",
    "INSERT INTO course VALUES ('PHY-101', 'Physical Principles', 'Physics', '4');\n",
    "-- Instructor\n",
    "INSERT INTO instructor VALUES ('10101', 'Srinivasan', 'Comp. Sci.', '65000');\n",
    "INSERT INTO instructor VALUES ('12121', 'Wu', 'Finance', '90000');\n",
    "INSERT INTO instructor VALUES ('15151', 'Mozart', 'Music', '40000');\n",
    "INSERT INTO instructor VALUES ('22222', 'Einstein', 'Physics', '95000');\n",
    "INSERT INTO instructor VALUES ('32343', 'El Said', 'History', '60000');\n",
    "INSERT INTO instructor VALUES ('33456', 'Gold', 'Physics', '87000');\n",
    "INSERT INTO instructor VALUES ('45565', 'Katz', 'Comp. Sci.', '75000');\n",
    "INSERT INTO instructor VALUES ('58583', 'Califieri', 'History', '62000');\n",
    "INSERT INTO instructor VALUES ('76543', 'Singh', 'Finance', '80000');\n",
    "INSERT INTO instructor VALUES ('76766', 'Crick', 'Biology', '72000');\n",
    "INSERT INTO instructor VALUES ('83821', 'Brandt', 'Comp. Sci.', '92000');\n",
    "INSERT INTO instructor VALUES ('98345', 'Kim', 'Elec. Eng.', '80000');\n",
    "-- Section\n",
    "INSERT INTO section VALUES ('BIO-101', '1', 'Summer', '2009', 'Painter', '514', 'B');\n",
    "INSERT INTO section VALUES ('BIO-301', '1', 'Summer', '2010', 'Painter', '514', 'A');\n",
    "INSERT INTO section VALUES ('CS-101', '1', 'Fall', '2009', 'Packard', '101', 'H');\n",
    "INSERT INTO section VALUES ('CS-101', '1', 'Spring', '2010', 'Packard', '101', 'F');\n",
    "INSERT INTO section VALUES ('CS-190', '1', 'Spring', '2009', 'Taylor', '3128', 'E');\n",
    "INSERT INTO section VALUES ('CS-190', '2', 'Spring', '2009', 'Taylor', '3128', 'A');\n",
    "INSERT INTO section VALUES ('CS-315', '1', 'Spring', '2010', 'Watson', '120', 'D');\n",
    "INSERT INTO section VALUES ('CS-319', '1', 'Spring', '2010', 'Watson', '100', 'B');\n",
    "INSERT INTO section VALUES ('CS-319', '2', 'Spring', '2010', 'Taylor', '3128', 'C');\n",
    "INSERT INTO section VALUES ('CS-347', '1', 'Fall', '2009', 'Taylor', '3128', 'A');\n",
    "INSERT INTO section VALUES ('EE-181', '1', 'Spring', '2009', 'Taylor', '3128', 'C');\n",
    "INSERT INTO section VALUES ('FIN-201', '1', 'Spring', '2010', 'Packard', '101', 'B');\n",
    "INSERT INTO section VALUES ('HIS-351', '1', 'Spring', '2010', 'Painter', '514', 'C');\n",
    "INSERT INTO section VALUES ('MU-199', '1', 'Spring', '2010', 'Packard', '101', 'D');\n",
    "INSERT INTO section VALUES ('PHY-101', '1', 'Fall', '2009', 'Watson', '100', 'A');\n",
    "-- Teaches\n",
    "INSERT INTO teaches VALUES ('10101', 'CS-101', '1', 'Fall', '2009');\n",
    "INSERT INTO teaches VALUES ('10101', 'CS-315', '1', 'Spring', '2010');\n",
    "INSERT INTO teaches VALUES ('10101', 'CS-347', '1', 'Fall', '2009');\n",
    "INSERT INTO teaches VALUES ('12121', 'FIN-201', '1', 'Spring', '2010');\n",
    "INSERT INTO teaches VALUES ('15151', 'MU-199', '1', 'Spring', '2010');\n",
    "INSERT INTO teaches VALUES ('22222', 'PHY-101', '1', 'Fall', '2009');\n",
    "INSERT INTO teaches VALUES ('32343', 'HIS-351', '1', 'Spring', '2010');\n",
    "INSERT INTO teaches VALUES ('45565', 'CS-101', '1', 'Spring', '2010');\n",
    "INSERT INTO teaches VALUES ('45565', 'CS-319', '1', 'Spring', '2010');\n",
    "INSERT INTO teaches VALUES ('76766', 'BIO-101', '1', 'Summer', '2009');\n",
    "INSERT INTO teaches VALUES ('76766', 'BIO-301', '1', 'Summer', '2010');\n",
    "INSERT INTO teaches VALUES ('83821', 'CS-190', '1', 'Spring', '2009');\n",
    "INSERT INTO teaches VALUES ('83821', 'CS-190', '2', 'Spring', '2009');\n",
    "INSERT INTO teaches VALUES ('83821', 'CS-319', '2', 'Spring', '2010');\n",
    "INSERT INTO teaches VALUES ('98345', 'EE-181', '1', 'Spring', '2009');\n",
    "-- Student\n",
    "INSERT INTO student VALUES ('00128', 'Zhang', 'Comp. Sci.', '102');\n",
    "INSERT INTO student VALUES ('12345', 'Shankar', 'Comp. Sci.', '32');\n",
    "INSERT INTO student VALUES ('19991', 'Brandt', 'History', '80');\n",
    "INSERT INTO student VALUES ('23121', 'Chavez', 'Finance', '110');\n",
    "INSERT INTO student VALUES ('44553', 'Peltier', 'Physics', '56');\n",
    "INSERT INTO student VALUES ('45678', 'Levy', 'Physics', '46');\n",
    "INSERT INTO student VALUES ('54321', 'Williams', 'Comp. Sci.', '54');\n",
    "INSERT INTO student VALUES ('55739', 'Sanchez', 'Music', '38');\n",
    "INSERT INTO student VALUES ('70557', 'Snow', 'Physics', '0');\n",
    "INSERT INTO student VALUES ('76543', 'Brown', 'Comp. Sci.', '58');\n",
    "INSERT INTO student VALUES ('76653', 'Aoi', 'Elec. Eng.', '60');\n",
    "INSERT INTO student VALUES ('98765', 'Bourikas', 'Elec. Eng.', '98');\n",
    "INSERT INTO student VALUES ('98988', 'Tanaka', 'Biology', '120');\n",
    "-- Takes\n",
    "INSERT INTO takes VALUES ('00128', 'CS-101', '1', 'Fall', '2009', 'A');\n",
    "INSERT INTO takes VALUES ('00128', 'CS-347', '1', 'Fall', '2009', 'A-');\n",
    "INSERT INTO takes VALUES ('12345', 'CS-101', '1', 'Fall', '2009', 'C');\n",
    "INSERT INTO takes VALUES ('12345', 'CS-190', '2', 'Spring', '2009', 'A');\n",
    "INSERT INTO takes VALUES ('12345', 'CS-315', '1', 'Spring', '2010', 'A');\n",
    "INSERT INTO takes VALUES ('12345', 'CS-347', '1', 'Fall', '2009', 'A');\n",
    "INSERT INTO takes VALUES ('19991', 'HIS-351', '1', 'Spring', '2010', 'B');\n",
    "INSERT INTO takes VALUES ('23121', 'FIN-201', '1', 'Spring', '2010', 'C+');\n",
    "INSERT INTO takes VALUES ('44553', 'PHY-101', '1', 'Fall', '2009', 'B-');\n",
    "INSERT INTO takes VALUES ('45678', 'CS-101', '1', 'Fall', '2009', 'F');\n",
    "INSERT INTO takes VALUES ('45678', 'CS-101', '1', 'Spring', '2010', 'B+');\n",
    "INSERT INTO takes VALUES ('45678', 'CS-319', '1', 'Spring', '2010', 'B');\n",
    "INSERT INTO takes VALUES ('54321', 'CS-101', '1', 'Fall', '2009', 'A-');\n",
    "INSERT INTO takes VALUES ('54321', 'CS-190', '2', 'Spring', '2009', 'B+');\n",
    "INSERT INTO takes VALUES ('55739', 'MU-199', '1', 'Spring', '2010', 'A-');\n",
    "INSERT INTO takes VALUES ('76543', 'CS-101', '1', 'Fall', '2009', 'A');\n",
    "INSERT INTO takes VALUES ('76543', 'CS-319', '2', 'Spring', '2010', 'A');\n",
    "INSERT INTO takes VALUES ('76653', 'EE-181', '1', 'Spring', '2009', 'C');\n",
    "INSERT INTO takes VALUES ('98765', 'CS-101', '1', 'Fall', '2009', 'C-');\n",
    "INSERT INTO takes VALUES ('98765', 'CS-315', '1', 'Spring', '2010', 'B');\n",
    "INSERT INTO takes VALUES ('98988', 'BIO-101', '1', 'Summer', '2009', 'A');\n",
    "INSERT INTO takes VALUES ('98988', 'BIO-301', '1', 'Summer', '2010', null);\n",
    "-- Advisor\n",
    "INSERT INTO advisor VALUES ('00128', '45565');\n",
    "INSERT INTO advisor VALUES ('12345', '10101');\n",
    "INSERT INTO advisor VALUES ('23121', '76543');\n",
    "INSERT INTO advisor VALUES ('44553', '22222');\n",
    "INSERT INTO advisor VALUES ('45678', '22222');\n",
    "INSERT INTO advisor VALUES ('76543', '45565');\n",
    "INSERT INTO advisor VALUES ('76653', '98345');\n",
    "INSERT INTO advisor VALUES ('98765', '98345');\n",
    "INSERT INTO advisor VALUES ('98988', '76766');\n",
    "-- Time Slot\n",
    "INSERT INTO timeSlot VALUES ('A', 'M', '8', '0', '8', '50');\n",
    "INSERT INTO timeSlot VALUES ('A', 'W', '8', '0', '8', '50');\n",
    "INSERT INTO timeSlot VALUES ('A', 'F', '8', '0', '8', '50');\n",
    "INSERT INTO timeSlot VALUES ('B', 'M', '9', '0', '9', '50');\n",
    "INSERT INTO timeSlot VALUES ('B', 'W', '9', '0', '9', '50');\n",
    "INSERT INTO timeSlot VALUES ('B', 'F', '9', '0', '9', '50');\n",
    "INSERT INTO timeSlot VALUES ('C', 'M', '11', '0', '11', '50');\n",
    "INSERT INTO timeSlot VALUES ('C', 'W', '11', '0', '11', '50');\n",
    "INSERT INTO timeSlot VALUES ('C', 'F', '11', '0', '11', '50');\n",
    "INSERT INTO timeSlot VALUES ('D', 'M', '13', '0', '13', '50');\n",
    "INSERT INTO timeSlot VALUES ('D', 'W', '13', '0', '13', '50');\n",
    "INSERT INTO timeSlot VALUES ('D', 'F', '13', '0', '13', '50');\n",
    "INSERT INTO timeSlot VALUES ('E', 'T', '10', '30', '11', '45 ');\n",
    "INSERT INTO timeSlot VALUES ('E', 'R', '10', '30', '11', '45 ');\n",
    "INSERT INTO timeSlot VALUES ('F', 'T', '14', '30', '15', '45 ');\n",
    "INSERT INTO timeSlot VALUES ('F', 'R', '14', '30', '15', '45 ');\n",
    "INSERT INTO timeSlot VALUES ('G', 'M', '16', '0', '16', '50');\n",
    "INSERT INTO timeSlot VALUES ('G', 'W', '16', '0', '16', '50');\n",
    "INSERT INTO timeSlot VALUES ('G', 'F', '16', '0', '16', '50');\n",
    "INSERT INTO timeSlot VALUES ('H', 'W', '10', '0', '12', '30');\n",
    "-- Prereq\n",
    "INSERT INTO prereq VALUES ('BIO-301', 'BIO-101');\n",
    "INSERT INTO prereq VALUES ('BIO-399', 'BIO-101');\n",
    "INSERT INTO prereq VALUES ('CS-190', 'CS-101');\n",
    "INSERT INTO prereq VALUES ('CS-315', 'CS-101');\n",
    "INSERT INTO prereq VALUES ('CS-319', 'CS-101');\n",
    "INSERT INTO prereq VALUES ('CS-347', 'CS-101');\n",
    "INSERT INTO prereq VALUES ('EE-181', 'PHY-101');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Introduction <a name=\"chapter1\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **database-management system** (DBMS) consists of a collection of interrelated data and a collection of programs to access that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 View of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Abstraction\n",
    "\n",
    "- **Physical Level**: *How is the data stored in the database?*\n",
    "- **Logical Level**: *What is the data stored in the database?*\n",
    "- **View Level**: *How should users of the database interact with the data?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instances and Schemas\n",
    "\n",
    "- **Instance**: A collection of information stored in the database at a particular moment.\n",
    "- **Schema**: The overall design of the database.\n",
    "    - **Physical Schema**: Describes the database design at the physical level.\n",
    "    - **Logical Schema**: Describes the database design at the logical level.\n",
    "- **Physical Data Independence**: The ability to modify the physical schema without changing the logical schema or the application.\n",
    "- **Logical Data Independence**: The ability to modify the logical schema without changing the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Models\n",
    "\n",
    "- **Data Model**: A collection of conceptual tools for describing data, data relationships, data semantics, and consistency constraints.\n",
    "    - Relational Model\n",
    "    - Entity-Relationship Model\n",
    "    - Object-Based Data Model\n",
    "    - Semistructured Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Database Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Database Architecture](images/Figure_1_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Introduction to the Relational Model <a name=\"chapter2\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Structure of Relational Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Relation**: A set of tuples $\\left( A_1, A_2, ..., A_n \\right)$ in which each attribute $A_i$ is a member of the domain $D_i$.\n",
    "    - *Relation = Table*\n",
    "    - *Tuple = Row*\n",
    "    - *Attribute = Column*\n",
    "- **Relation Instance**: A specific set of tuples of a relation.\n",
    "- **Domain**: A set of permitted values of an attribute.\n",
    "- **Atomic**: A domain in which every element is semantically indivisible.\n",
    "- **Null**: A special value that signifies that the value is unknown or does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Database Schema\n",
    "\n",
    "- **Database Schema**: The logical design of a database.\n",
    "- **Database Instance**: A snapshot of the data in a database at a given instant in time.\n",
    "- **Relation Schema**: A list of attributes and their corresponding domains.\n",
    "\n",
    "$$R \\left( A_1, A_2, ..., A_n \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Keys\n",
    "\n",
    "- A **superkey** of a relation is a set of one or more attributes whose values are guaranteed to identify tuples in the relation uniquely\n",
    "- A **candidate key** is a minimal superkey, that is, a set of attributes that forms a superkey, but none of whose subsets is a superkey.\n",
    "- A **primary key** is one of the candidate keys of a relation.\n",
    "- A **foreign key** is a set of attributes in a referencing relation, such that for each tuple in the **referencing relation**, the values of the foreign key attributes are guaranteed to occur as the primary key value of a tuple in the **referenced relation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Introduction to SQL <a name=\"chapter3\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Overview of the SQL Query Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data-Definition Language** (DDL) provides commands for defining relation schemas, deleting relations, and modifying relation schemas.\n",
    "- **Data-Manipulation Language** (DML) includes a query language and commands to insert tuples into, delete tuples from, and modify tuples in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SQL Data Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- INT\n",
    "-- BOOLEAN\n",
    "-- TINYINT\n",
    "-- SMALLINT\n",
    "-- BIGINT\n",
    "-- IDENTITY\n",
    "-- DECIMAL\n",
    "-- DOUBLE\n",
    "-- REAL\n",
    "-- TIME\n",
    "-- DATE\n",
    "-- TIMESTAMP\n",
    "-- TIMESTAMP WITH TIME ZONE\n",
    "-- BINARY\n",
    "-- OTHER\n",
    "-- VARCHAR\n",
    "-- VARCHAR_IGNORECASE\n",
    "-- CHAR\n",
    "-- BLOB\n",
    "-- CLOB\n",
    "-- UUID\n",
    "-- ARRAY\n",
    "-- ENUM\n",
    "-- GEOMETRY\n",
    "-- INTERVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Schema Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Visit https://en.wikipedia.org/wiki/Data_definition_language\n",
    "-- for more information regarding DDL.\n",
    "-- CREATE TABLE r\n",
    "-- (\n",
    "-- Attribute1 Domain1,\n",
    "-- Attribute2 Domain2,\n",
    "-- ...\n",
    "-- AttributeN DomainN,\n",
    "-- (IntegrityConstraint1),\n",
    "-- ...\n",
    "-- (IntegrityConstraintk),\n",
    "-- );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Basic Structure of SQL Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Clause and From Clause\n",
    "\n",
    "- The **`SELECT`** clause specifies the attributes to project for the output.\n",
    "- The **`FROM`** clause specifies the relation from which to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8074d215-20aa-4c96-8d44-74b5d8fdb55b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- List attribute deptName of all relation instructor.\n",
    "SELECT deptName\n",
    "FROM instructor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f603c5-0cad-46eb-91f3-4a223afac2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- List attribute deptName of all relation instructor.\n",
    "-- Disallow Duplicates\n",
    "SELECT DISTINCT deptName\n",
    "FROM instructor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f2cf52-8f4d-4214-976e-05fa99816dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- List attribute deptName of all relation instructor.\n",
    "-- Allow Duplicates\n",
    "SELECT ALL deptName\n",
    "FROM instructor;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db488790-7926-4e4b-bca5-7d57f58114b3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d07a631-e5ab-4dfb-9e3c-142f6ef4c064",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d55b24-ac01-4827-a296-32aa496ebb82",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac22883e-c04a-4c55-81cc-75e1e7bb95e8",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f74069-9243-4438-b811-e86ea3d7a538",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- List 1.\n",
    "SELECT 1.0;\n",
    "\n",
    "-- List Addition.\n",
    "SELECT 1.0 + 1.0;\n",
    "\n",
    "-- List Subtraction\n",
    "SELECT 1.0 - 1.0;\n",
    "\n",
    "-- List Multiplication.\n",
    "SELECT 2.0 * 2.0;\n",
    "\n",
    "-- List Division;\n",
    "SELECT 1.0 / 2.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\* Attribute**\n",
    "\n",
    "- The **`*`** symbol denotes all attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c25c9b9-31e7-4013-a33c-0cdef070f1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT * FROM instructor;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where Clause\n",
    "\n",
    "- The **`WHERE`** clause specifies conditions by which the query should be filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6f8175-de98-45e9-8972-33676599463c",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Connectives: 'and', 'or', 'not'\n",
    "-- Operators: '<', '<=', '>', '>=', '=', '<>'\n",
    "SELECT name\n",
    "FROM instructor\n",
    "WHERE deptName = 'Comp. Sci.' AND salary > 70000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cartesian Product\n",
    "\n",
    "- The **Cartesian product** outputs all pairs of rows from the two input relations (regardless of whether or not they have the same values on common attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c80742-11b2-465e-ab34-f08bfbbc672a",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT name, courseId\n",
    "FROM instructor, teaches\n",
    "WHERE instructor.instructorId = teaches.instructorId \n",
    "    AND instructor.deptName = 'Comp. Sci.';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Join\n",
    "\n",
    "- The **natural join** outputs pairs of rows from the two input relations that have the same value on all attributes that have the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3442e7e8-ec95-4c5c-babc-8ba8ea810857",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT name, courseId\n",
    "FROM instructor NATURAL JOIN teaches\n",
    "WHERE deptName = 'Comp. Sci.';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Additional Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename Operation\n",
    "\n",
    "- The **`AS`** operation aliases attributes and relations for efficiency and disambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b14d431-bfa2-448a-9bf1-75b687f89cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are the names of all instructors whose salary \n",
    "-- is greater than at least one instructor in the Biology \n",
    "-- department?\n",
    "SELECT DISTINCT T.name\n",
    "FROM instructor AS T, instructor AS S\n",
    "WHERE T.salary > S.salary AND S.deptName = 'Biology';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order By Clause\n",
    "\n",
    "- The **`ORDER BY`** clause specifies the ordering by which the tuples in the result of a query should be sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952b4eb7-8b4f-4c47-8c2a-4bd330860446",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f08bcca-2c2c-463c-a26e-4557678c1c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1312540b-a483-464d-a541-1af751d994e1",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Alphabetically, what are the names of all instructors in the \n",
    "-- Physics department?\n",
    "SELECT name\n",
    "FROM instructor\n",
    "WHERE deptName = 'Physics'\n",
    "ORDER BY name;\n",
    "\n",
    "-- Ascending\n",
    "SELECT name\n",
    "FROM instructor\n",
    "WHERE deptName = 'Physics'\n",
    "ORDER BY name ASC;\n",
    "\n",
    "-- Descending\n",
    "SELECT name\n",
    "FROM instructor\n",
    "WHERE deptName = 'Physics'\n",
    "ORDER BY name DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where Clause 'Between' Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b41f09c-5de9-435e-bdef-74e028446733",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are the names of instructors with salary amounts \n",
    "-- between $90,000 and $100,000?\n",
    "SELECT name\n",
    "FROM instructor\n",
    "WHERE salary BETWEEN 90000 AND 100000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where Clause 'Tuple Equality' Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78019d4-6e59-40fc-aa23-7d88acf07765",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are the instructor names and the courses they taught \n",
    "-- for all instructors in the Biology department who have \n",
    "-- taught some course?\n",
    "SELECT name, courseId\n",
    "FROM instructor, teaches\n",
    "WHERE (instructor.instructorId, deptName) = (teaches.instructorId, 'Biology');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Set Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Union Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d4b7eb-7a84-4e6e-bf38-ee1b349f2e74",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are all the courses taught either in Fall 2009 or \n",
    "-- in Spring 2010, or both?\n",
    "-- Disallow Duplicates\n",
    "(SELECT courseId FROM section WHERE semester = 'Fall' AND year = 2009)\n",
    "UNION\n",
    "(SELECT courseId FROM section WHERE semester = 'Spring' AND year = 2010);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0022cd-3a42-489f-ad5d-43b706e66215",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are all the courses taught either in Fall 2009 or \n",
    "-- in Spring 2010, or both?\n",
    "-- Allow Duplicates\n",
    "(SELECT courseId FROM section WHERE semester = 'Fall' AND year = 2009)\n",
    "UNION ALL\n",
    "(SELECT courseId FROM section WHERE semester = 'Spring' AND year = 2010);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intersect Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CS-101"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- What are all the courses taught either in Fall 2009 and \n",
    "-- in Spring 2010?\n",
    "-- Disallow Duplicates\n",
    "(SELECT courseId FROM section WHERE semester = 'Fall' AND year = 2009)\n",
    "INTERSECT\n",
    "(SELECT courseId FROM section WHERE semester = 'Spring' AND year = 2010);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Except Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6a2830-a2d2-44f9-9e30-4c683411da68",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are all the courses taught either in Fall 2009 but not \n",
    "-- in Spring 2010?\n",
    "-- Disallow Duplicates\n",
    "(SELECT courseId FROM section WHERE semester = 'Fall' AND year = 2009)\n",
    "EXCEPT\n",
    "(SELECT courseId FROM section WHERE semester = 'Spring' AND year = 2010);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b5fad8-96d2-486c-b78b-e23d3bb9f41b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3d4393-92b9-4fb8-a3a1-dfa4602c2335",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e2eefe-6f7c-46e5-a837-9f56eb7b508a",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aaf084-792c-4068-83ba-819eb02cb6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fbf12f-c3fe-4b44-a8f6-39e1767e9c82",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b134deb9-94ce-4a12-8402-3dc67f174029",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fdb5e7-e558-4131-92ce-f1e8817ca45f",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5028b2-b16d-4f5a-b6e2-8b6732b4138b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT NULL;\n",
    "\n",
    "-- Addition, All NULL\n",
    "-- SELECT NULL + NULL;\n",
    "-- SELECT 1.0 + NULL;\n",
    "-- SELECT NULL + 1.0;\n",
    "\n",
    "-- Subtraction, All NULL\n",
    "-- SELECT NULL - NULL;\n",
    "-- SELECT 1.0 - NULL;\n",
    "-- SELECT NULL - 1.0;\n",
    "\n",
    "-- Multiplication, All NULL\n",
    "-- SELECT NULL * NULL;\n",
    "-- SELECT 1.0 * NULL;\n",
    "-- SELECT NULL * 1.0;\n",
    "\n",
    "-- Division, All NULL\n",
    "-- SELECT NULL / NULL;\n",
    "-- SELECT 1.0 / NULL;\n",
    "-- SELECT NULL / 1.0;\n",
    "\n",
    "-- And\n",
    "SELECT NULL AND TRUE;\n",
    "SELECT NULL AND FALSE;\n",
    "\n",
    "-- Or\n",
    "SELECT NULL OR TRUE;\n",
    "SELECT NULL OR FALSE;\n",
    "\n",
    "-- Not\n",
    "SELECT NOT NULL;\n",
    "\n",
    "-- Is\n",
    "SELECT NULL IS NULL;\n",
    "SELECT NULL IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Aggregate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a1fa96-e2b4-47d3-9607-02a9de81d33d",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befe3f5d-3b1d-4bd5-b9e2-3fde420432e2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1347201c-045e-4b21-8c16-5b492e6d9154",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484873f0-bc71-431a-b9c3-3da6f368b40d",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a52bd9-0842-486a-a825-325c049171c2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- Average\n",
    "SELECT AVG(salary)\n",
    "FROM instructor;\n",
    "\n",
    "-- Minimum\n",
    "SELECT MIN(salary)\n",
    "FROM instructor;\n",
    "\n",
    "-- Maximum\n",
    "SELECT MAX(salary)\n",
    "FROM instructor;\n",
    "\n",
    "-- Sum\n",
    "SELECT SUM(salary)\n",
    "FROM instructor;\n",
    "\n",
    "-- Count\n",
    "SELECT COUNT(*)\n",
    "FROM instructor;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distinct Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- What is the total number of instructors who teach a course \n",
    "-- in Spring 2010 semester?\n",
    "SELECT COUNT(DISTINCT instructorId)\n",
    "FROM teaches\n",
    "WHERE (semester, year) = ('Spring', 2010);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation with  Grouping\n",
    "\n",
    "- The **`GROUP BY`** clause specifies attributes by which tuples with the same value on all specified attributes are placed in the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abebd535-bd0d-474b-bedc-205ac1b7bdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What is the average salary in each department?\n",
    "SELECT deptName, AVG(salary) AS avgSalary\n",
    "FROM instructor\n",
    "GROUP BY deptName;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having Clause\n",
    "\n",
    "- The **`HAVING`** clause specifies conditions by which the query should be filtered after groups have been formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1df7bc-341a-4e6d-9285-d28df0abca8b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What is the average salary in each department \n",
    "-- if the average salary is greater than $42,000?\n",
    "SELECT deptName, AVG(salary) AS avgSalary\n",
    "FROM instructor\n",
    "GROUP BY deptName\n",
    "HAVING AVG(salary) > 42000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation with Null Values\n",
    "\n",
    "- All aggregate functions except `COUNT(*)` ignore null values in their input collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Nested Subqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **subquery** is a select-from-where expression that is nested within another query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Membership\n",
    "\n",
    "- The **`IN`** connective tests set membership.\n",
    "- The **`NOT IN`** connective tests the absense of set membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CS-101"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- What are all the courses taught either in Fall 2009 and \n",
    "-- in Spring 2010?\n",
    "SELECT DISTINCT courseId\n",
    "FROM section\n",
    "WHERE semester = 'Fall'\n",
    "    AND year = 2009\n",
    "    AND courseId IN (\n",
    "        SELECT courseId\n",
    "        FROM section\n",
    "        WHERE semester = 'Spring'\n",
    "            AND year = 2010\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Comparison\n",
    "\n",
    "- The **`SOME`** connective asserts a condition for any member of a set.\n",
    "- The **`ALL`** connective asserts a condition for all members of a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503be093-5578-4bad-814c-6e65ce8b5362",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f840f5-3d8e-4b66-864f-88a43c937ced",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are the names of all instructors whose salary \n",
    "-- is greater than at least one instructor in the Biology \n",
    "-- department?\n",
    "SELECT name\n",
    "FROM instructor\n",
    "WHERE salary > SOME (\n",
    "    SELECT salary\n",
    "    FROM instructor\n",
    "    WHERE deptName = 'Biology'\n",
    ");\n",
    "\n",
    "-- What are the names of all instructors whose salary \n",
    "-- is greater than all instructors in the Biology \n",
    "-- department?\n",
    "SELECT name\n",
    "FROM instructor\n",
    "WHERE salary > ALL (\n",
    "    SELECT salary\n",
    "    FROM instructor\n",
    "    WHERE deptName = 'Biology'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existence Tests\n",
    "\n",
    "- The **`EXISTS`** connective asserts whether a set is empty.\n",
    "- The **`NOT EXISTS`** connective asserts whether a set is non-empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CS-101"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- What are all the courses taught either in Fall 2009 and \n",
    "-- in Spring 2010?\n",
    "SELECT courseId\n",
    "FROM section AS S\n",
    "WHERE semester = 'Fall'\n",
    "    AND year = 2009\n",
    "    AND EXISTS (\n",
    "        SELECT *\n",
    "        FROM section AS T\n",
    "        WHERE semester = 'Spring'\n",
    "            AND year = 2010\n",
    "            AND S.courseId = T.courseId\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniqueness Tests\n",
    "\n",
    "- The **`UNIQUE`** connective asserts whether a set contains no duplicates.\n",
    "- The **`NOT UNIQUE`** connective asserts whether a set contains duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- DOES NOT WORK WITH H2!\n",
    "-- What are all the courses that were offered at most once \n",
    "-- in 2009?\n",
    "-- SELECT T.courseId\n",
    "-- FROM course AS T\n",
    "-- WHERE UNIQUE (\n",
    "--     SELECT R.courseId\n",
    "--     FROM section AS R\n",
    "--     WHERE T.courseId = R.courseId\n",
    "--         AND R.year = 2009\n",
    "-- );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Clause\n",
    "\n",
    "- The **`WITH`** clause defines a temporary relation whose definition is available only to the query in which the clause occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- DOES NOT WORK WITH H2!\n",
    "-- What department has the maximum budget?\n",
    "-- WITH maxBudget(value) AS (\n",
    "--     SELECT MAX(budget) FROM department\n",
    "-- )\n",
    "-- SELECT budget\n",
    "-- FROM department, maxBudget\n",
    "-- WHERE department.budget = maxBudget.value;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalary Subqueries\n",
    "\n",
    "- A **scalar subquery** is a subequery that returns only one tuple containing a single attribute.\n",
    "- A scalar subquery can be used wherever an expression returning a value is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26e70f1-a6b2-4bb4-b153-15a3abab69c6",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- What are all the departments along with the number of\n",
    "-- instructors in each department?\n",
    "SELECT deptName, (\n",
    "    SELECT COUNT(*)\n",
    "    FROM instructor\n",
    "    WHERE department.deptName = instructor.deptName\n",
    ") AS numInstructors\n",
    "FROM department;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Modification of the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deletion\n",
    "\n",
    "- The **`DELETE`** statement deletes all tuples in a relation for which a given predicate is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf6b75b-fa60-4952-a916-863e05931406",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9781fece-23b8-4bfc-90b7-aa0b58f92c91",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49afec92-0297-456d-9231-eb7cac67fab2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb4f0f0-7c0b-43ca-aff7-d4dc4f7ff718",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7889211d-2324-40d0-b7a9-7f26dc9b1179",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0feff66-88f7-4ca9-941b-6fcb2f47acc2",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SET AUTOCOMMIT FALSE;\n",
    "\n",
    "SELECT CONCAT('Setup: ', COUNT(*))\n",
    "FROM instructor;\n",
    "\n",
    "-- \n",
    "DELETE FROM instructor;\n",
    "-- \n",
    "SELECT CONCAT('Test 1: ', COUNT(*)) \n",
    "FROM instructor;\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "-- \n",
    "DELETE FROM instructor\n",
    "WHERE deptName = 'Finance';\n",
    "-- \n",
    "SELECT CONCAT('Test 2: ', COUNT(*))\n",
    "FROM instructor\n",
    "WHERE deptName = 'Finance';\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "-- \n",
    "DELETE FROM instructor\n",
    "WHERE salary BETWEEN 13000 AND 15000;\n",
    "-- \n",
    "SELECT CONCAT('Test 3: ', COUNT(*)) \n",
    "FROM instructor\n",
    "WHERE salary BETWEEN 13000 AND 15000;\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "-- \n",
    "DELETE FROM instructor\n",
    "WHERE deptName IN (\n",
    "    SELECT deptName\n",
    "    FROM department\n",
    "    WHERE building = 'Watson'\n",
    ");\n",
    "-- \n",
    "SELECT CONCAT('Test 4: ', COUNT(*)) \n",
    "FROM instructor\n",
    "WHERE deptName IN (\n",
    "    SELECT deptName\n",
    "    FROM department\n",
    "    WHERE building = 'Watson'\n",
    ");\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "SELECT CONCAT('Teardown: ', COUNT(*))\n",
    "FROM instructor;\n",
    "\n",
    "SET AUTOCOMMIT TRUE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insertion\n",
    "\n",
    "- The **`INSERT`** statement inserts tuples into a relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2779e8-e7ee-45a4-a866-4517bd0c4f41",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5367b26-a2a5-4794-b562-3420345655b7",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ac8444-4ae2-497f-8e67-e56f36d4ddf9",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b57d3e0-6f7e-4d3d-8148-f996de26f344",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SET AUTOCOMMIT FALSE;\n",
    "\n",
    "SELECT CONCAT('Setup: ', COUNT(*))\n",
    "FROM course;\n",
    "\n",
    "-- \n",
    "INSERT INTO course\n",
    "VALUES ('CS-437', 'Database Systems', 'Comp. Sci.', 4);\n",
    "-- \n",
    "SELECT CONCAT('Test 1: ', COUNT(*)) \n",
    "FROM course;\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "-- \n",
    "INSERT INTO course (courseId, title, deptName, credits)\n",
    "VALUES ('CS-437', 'Database Systems', 'Comp. Sci.', 4);\n",
    "-- \n",
    "SELECT CONCAT('Test 2: ', COUNT(*)) \n",
    "FROM course;\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "SELECT CONCAT('Teardown: ', COUNT(*))\n",
    "FROM course;\n",
    "\n",
    "SET AUTOCOMMIT TRUE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update\n",
    "\n",
    "- The **`UPDATE`** statement updates tuples of a relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51dd440-fa24-4880-960f-b28fb067410c",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3f762e-a77f-4697-b770-2e7c76e127e3",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SET AUTOCOMMIT FALSE;\n",
    "\n",
    "SELECT CONCAT('Setup: ', COUNT(*))\n",
    "FROM instructor;\n",
    "\n",
    "-- \n",
    "UPDATE instructor\n",
    "SET salary = salary * 1.05;\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "-- \n",
    "UPDATE instructor\n",
    "SET salary = salary * 1.05\n",
    "WHERE salary < 70000;\n",
    "-- \n",
    "ROLLBACK;\n",
    "\n",
    "SELECT CONCAT('Teardown: ', COUNT(*))\n",
    "FROM instructor;\n",
    "\n",
    "SET AUTOCOMMIT TRUE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Intermediate SQL <a name=\"chapter4\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Join Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebe113d-8b00-4ed2-8d70-1b0cca29106d",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT *\n",
    "FROM student NATURAL JOIN takes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Conditions\n",
    "\n",
    "- The **`JOIN ... USING`** clause specifies the required attributes to match for the join.\n",
    "- The **`JOIN ... ON <condition>`** clause specifies the required condition to satisfy for the join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Joins\n",
    "\n",
    "- The **`INNER JOIN`** do not preserve nonmatched tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01471ce-f3c3-4ae7-b961-d0fe507ab2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- DOES NOT WORK WITH H2!\n",
    "-- SELECT * \n",
    "-- FROM student INNER JOIN takes USING (studentId);\n",
    "\n",
    "SELECT student.name, takes.courseId\n",
    "FROM student INNER JOIN takes\n",
    "    ON student.studentId = takes.studentId;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer Joins\n",
    "\n",
    "- The **`LEFT OUTER JOIN`** preserves tuples only in the relation left of the *left outer join* operation.\n",
    "- The **`RIGHT OUTER JOIN`** preserves tuples only in the relation right of the *left outer join* operation.\n",
    "- The **`FULL OUTER JOIN`** preserves tuples in both relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a7180f-449b-4571-a1fa-5e61385b8e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8b6837-a36b-46bf-93dd-83d24c6c7ded",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT student.name, takes.courseId\n",
    "FROM student LEFT OUTER JOIN takes\n",
    "    ON student.studentId = takes.studentId;\n",
    "    \n",
    "SELECT student.name, takes.courseId\n",
    "FROM student RIGHT OUTER JOIN takes\n",
    "    ON student.studentId = takes.studentId;\n",
    "    \n",
    "-- DOES NOT WORK WITH H2!\n",
    "-- SELECT student.name, takes.courseId\n",
    "-- FROM student FULL OUTER JOIN takes\n",
    "--     ON student.studentId = takes.studentId;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6: Formal Relational Query Languages <a name=\"chapter6\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 The Relational Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment Operation\n",
    "\n",
    "- **Notation**: $tempVariable \\gets expression$\n",
    "- **Definition**: Assigns a relational-algebra expression into a temporary relation variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Operation\n",
    "\n",
    "- **Notation**: $\\sigma_{predicate}(r)$\n",
    "    - *And*: $\\wedge$\n",
    "    - *Or*: $\\vee$\n",
    "    - *Not*: $\\neg$\n",
    "- **Definition**: Return rows of the input relation that satisfy the predicate.\n",
    "$$\\sigma_{p}(r) = \\left\\{ t \\mid t \\in r \\wedge p(t) \\right\\}$$\n",
    "- **Example**: *What are all the instructors who are in the Physics department?*\n",
    "$$\\sigma_{deptName = 'Physics'}(instructor)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Operation\n",
    "\n",
    "- **Notation**: $\\prod_{attribute_1, attribute_2, ..., attribute_k}(r)$\n",
    "- **Definition**: Output specfied attributes from all rows of the input relation. Remove duplicate tuples from the output.\n",
    "- **Example**: *What are the IDs, names, and salaries of all instructors?*\n",
    "$$\\prod_{instructorId, name, salary}(instructor)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Union Operation\n",
    "\n",
    "- **Notation**: $r \\cup s$\n",
    "- **Definition**: Output the union of tuples from the two input relations.\n",
    "$$r \\cup s = \\left\\{ t \\mid t \\in r \\vee t \\in s \\right\\}$$\n",
    "- **Example**: *What are all the courses that are taught in Fall 2009 or in Spring 2010, or in both?*\n",
    "$$\\prod_{courseId}\\left( \\sigma_{semester = 'Fall' \\wedge year = 2009}(section) \\right) \\cup \\prod_{courseId}\\left( \\sigma_{semester = 'Spring' \\wedge year = 2010}(section) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Difference Operation\n",
    "\n",
    "- **Notation**: $r - s$\n",
    "- **Definition**: Output the tuples that are contained in the first relation but not in the second relation.\n",
    "$$r - s = \\left\\{ t \\mid t \\in r \\wedge t \\notin s \\right\\}$$\n",
    "- **Example**: *What are all the courses that are taught in Fall 2009 but not in Spring 2010?*\n",
    "$$\\prod_{courseId}\\left( \\sigma_{semester = 'Fall' \\wedge year = 2009}(section) \\right) - \\prod_{courseId}\\left( \\sigma_{semester = 'Spring' \\wedge year = 2010}(section) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cartesian Product Operation\n",
    "\n",
    "- **Notation**: $r \\times s$\n",
    "- **Definition**: Output all pairs of rows from the two input relations.\n",
    "$$r \\times s = \\left\\{ tq \\mid t \\in r \\wedge q \\in s \\right\\}$$\n",
    "- **Example**: *What are all the courses that all the instructors who are in the Physics department teach?*\n",
    "$$I \\gets instructor$$\n",
    "$$T \\gets teaches$$\n",
    "$$\\prod_{name, courseId}\\left( \\sigma_{I.instructorId = T.instructorId}\\left( \\sigma_{deptName = 'Physics'}(I \\times T) \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename Operation\n",
    "\n",
    "- **Notation**: $\\rho_{relation(attribute_1, attribute_2, ..., attribute_k)}(r)$\n",
    "- **Definition**: Output the relation with a new relation name and a set of new attribute names. \n",
    "- **Example**: *What is the largest salary in the university?*\n",
    "$$\\prod_{salary} - \\prod_{instructor.salary}\\left( \\sigma_{instructor.salary < d.salary}\\left( instructor \\times \\rho_d(instructor) \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Intersection Operation\n",
    "\n",
    "- **Notation**: $r \\cap s$\n",
    "- **Definition**: Output the tuples that are contained in the first relation and in the second relation.\n",
    "$$r \\cap s = r - (r - s)$$\n",
    "- **Example**: *What are all the courses that are taught in Fall 2009 and in Spring 2010?*\n",
    "$$\\prod_{courseId}\\left( \\sigma_{semester = 'Fall' \\wedge year = 2009}(section) \\right) \\cap \\prod_{courseId}\\left( \\sigma_{semester = 'Spring' \\wedge year = 2010}(section) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Division Operation\n",
    "\n",
    "- **Requirement**: Every attribute of schema $S$ is in schema $R$.\n",
    "- **Notation**: $r \\div s$\n",
    "- **Definition**: Outputs the largest relation $t(R - S)$ such that $t \\times s \\subseteq r$.\n",
    "$$r \\div s = \\prod_{R - S}(r) - \\prod_{R - S}\\left( \\left( \\prod_{R - S}(r) \\times s \\right) - r \\right)$$\n",
    "    - Relation $r \\div s$ is a relation on schema $R - S$.\n",
    "    - A tuple $t$ is in $r \\div s$ if and only if both conditions hold:\n",
    "        1. $t$ is in $\\prod_{R - S}(r)$\n",
    "        2. For every typle $t_s$ in $s$, there is a tuple $t_r$ in $r$ satisfying both of the following:\n",
    "            - $t_r[S] = t_s[S]$\n",
    "            - $t_r[R - S] = t$\n",
    "- **Example**: *What are all the students who have taken all courses in the Biology department?*\n",
    "$$\\prod_{studentId, courseId}(takes) \\div \\prod_{courseId}\\left( \\sigma_{deptName = 'Biology'}(course) \\right)$$\n",
    "\n",
    "##### Advice\n",
    "\n",
    "1. The set division operation is suited to queries that include the phrase \"for all\".\n",
    "2. The set division operation is analogous to the following:\n",
    "    1. Key $r$ by $R - S$ for groups of $t_r[R - S] \\rightarrow g$.\n",
    "    2. Output $t_r[R - S]$ for each $t_r[R - S] \\rightarrow g$ where $s \\subseteq g$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Join Operation\n",
    "\n",
    "- **Notation**: $r \\Join s$\n",
    "    - *Theta Join*: $\\Join_\\theta$\n",
    "    - *Left Outer Join*: $⟕$\n",
    "    - *Right Outer Join*: $⟖$\n",
    "    - *Full Outer Join*: $⟗$\n",
    "- **Definition**: Output all pairs of rows from the two input relations that have the same value on each of the attributes in $R \\cap S$.\n",
    "$$r \\Join s = \\prod_{r.A, r.B, r.C, r.D, s.E}\\left( \\sigma_{r.B = s.B \\wedge r.D = s.D}(r \\times s) \\right)$$\n",
    "- **Example**: *What are all the names of all instructors in the Physics department and all the courses that they teach?*\n",
    "$$\\prod_{name, title}\\left( \\sigma_{deptName = 'Physics'}(instructor \\Join teaches \\Join course) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8: Relational Database Design <a name=\"chapter8\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Features of Good Relational Designs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad Relational Database Design\n",
    "\n",
    "##### Repetition of Information\n",
    "\n",
    "- A condition where the values of one attribute are determined by the values of another attribute in the same relation, and both values are repeated throughout the relation.\n",
    "- **Problem**: Increases the storage required for the relation.\n",
    "- **Problem**: Makes updating the relation more difficult.\n",
    "\n",
    "##### Inability to Represent Information\n",
    "\n",
    "- A condition where a relationship exists among only a proper subset of the attributes in a relation.\n",
    "- **Problem**: All the unrelated attributes must be filled with null values otherwise a tuple without the unrelated information cannot be inserted into the relation.\n",
    "\n",
    "##### Loss of Information\n",
    "\n",
    "- A condition which results from the decomposition of one relation into two relations and which cannot be combined to recreate the original relation.\n",
    "- **Problem**: Certain queries cannot be answered using the reconstructed relation that could have been answered using the original relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lossless-Join Decomposition\n",
    "\n",
    "- A decomposition of relational schema $R$ into relational schemas $R_1$ and $R_2$ such that for every instance $r(R)$ corresponding with instances $r_1(R_1)$ and $r_2(R_2)$, $r = r_1 \\Join r_2$ holds.\n",
    "- A decomposition $\\{ R_1, R_2 \\}$ is a lossless-join decomposition if $R_1 \\cap R_2 \\rightarrow R_1$ or $R_1 \\cap R_2 \\rightarrow R_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Atomic Domains and First Normal Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A domain is **atomic** if elements of the domain are considered to be indivisible units.\n",
    "- A relation schema $R$ is in **first normal form** (1NF) if the domains of all attributes of $R$ are atomic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Decomposition Using Functional Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legal Instance and Superkey\n",
    "\n",
    "- A **legal instance** is an instance of a relation that satisfies all such real-world constraints.\n",
    "- A **superkey** $K$ of $r(R)$ is a subset of $R$ if, in any legal instance of $r(R)$, for all pairs $t_1$ and $t_2$ of tuples in the instance of $r$ if $t_1 \\neq t_2$, then $t_1[K] \\neq t_2[K]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of Functional Dependency\n",
    "\n",
    "- A **functional dependency** expresses constraints that uniquely identify the values of certain attributes.\n",
    "$$\\alpha \\rightarrow \\beta$$\n",
    "- Given an instance of $r(R)$, the instance **satisfies** the functional dependency $\\alpha \\rightarrow \\beta$ if for all pairs of tuples $t_1$ and $t_2$ in the instance such that $t_1[\\alpha]$ and $t_2[\\alpha]$, it is also the case that $t_1[\\beta]$ and $t_2[\\beta]$.\n",
    "- The functional dependency $\\alpha \\rightarrow \\beta$ **holds** on schema $r(R)$ if, in every legal instance of $r(R)$ it satisfies the functional dependency.\n",
    "- A functional dependency is **trivial** if it is satisfied by all instances of a relation.\n",
    "    - If $\\beta \\subseteq \\alpha$, then $\\alpha \\rightarrow \\beta$ is trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uses of Functional Dependencies\n",
    "\n",
    "1. Test relations to see if they are legal under a given set of functional dependencies.\n",
    "2. Specify constraints on the set of legal relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closure of a Set of Functional Dependencies\n",
    "\n",
    "- Given a relational schema $r(R)$, a functional dependency $f$ on $R$ is **logically implied** by a set of functional dependencies $F$ on $r$ if every instance of $r(R)$ that satisfies $F$ also satisfies $f$.\n",
    "- The **closure** of $F$, denoted $F^+$, is the set of all functional dependencies logically implied by $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency Preservation\n",
    "\n",
    "- A decomposition is **dependency preserving** if and only if $(F_1 \\cup F_2 \\cup ... \\cup F_n)^+ = F^+$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boyce-Codd Normal Form\n",
    "\n",
    "- A relation schema $R$ is in **Boyce-Codd normal form** (BCNF) with respect to a set $F$ of functional dependencies if for every dependency $\\alpha \\rightarrow \\beta$ in $F^+$ such that $\\alpha, \\beta \\subseteq R$, at least one of the following holds:\n",
    "    - $\\alpha \\rightarrow \\beta$ is trivial.\n",
    "    - $\\alpha$ is a superkey for $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Normal Form\n",
    "\n",
    "- A relation schema $R$ is in **third normal form** (3NF) with respect to a set $F$ of functional dependencies if for every dependency $\\alpha \\rightarrow \\beta$ in $F^+$ such that $\\alpha, \\beta \\subseteq R$, at least one of the following holds\n",
    "    - $\\alpha \\rightarrow \\beta$ is trivial.\n",
    "    - $\\alpha$ is a superkey for $R$.\n",
    "    - Each attribute $B$ in $\\beta - \\alpha$ is contained in a candidate key for $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Normal Form\n",
    "\n",
    "- A **non-prime attribute** of a relation schema $R$ is an attribute that is not a part of any candidate key of $R$.\n",
    "- A relation schema $R$ is in **second normal form** (2NF) with respect to a set $F$ of functional dependencies if:\n",
    "    - $R$ is in 1NF.\n",
    "    - $R$ depends on the whole of every candidate key.\n",
    "- If every candidate key in $R$ has only one attribute, then $R$ is automatically in 2NF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Functional-Dependency Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armstrong's Axioms\n",
    "\n",
    "- **Reflexivity**: If $\\beta \\subseteq \\alpha$, then $\\alpha \\rightarrow \\beta$.\n",
    "- **Augmentation**: If $\\alpha \\rightarrow \\beta$, then $\\gamma\\alpha \\rightarrow \\gamma\\beta$.\n",
    "- **Transitivity**: If $\\alpha \\rightarrow \\beta$ and $\\beta \\rightarrow \\gamma$, then $\\alpha \\rightarrow \\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Inference Rules\n",
    "\n",
    "- **Union**: If $\\alpha \\rightarrow \\beta$ and $\\alpha \\rightarrow \\gamma$, then $\\alpha \\rightarrow \\beta\\gamma$.\n",
    "- **Decomposition**: If $\\alpha \\rightarrow \\beta\\gamma$, then $\\alpha \\rightarrow \\beta$ and $\\alpha \\rightarrow \\gamma$.\n",
    "- **Pseudotransitivity**: If $\\alpha \\rightarrow \\beta$ and $\\gamma\\beta \\rightarrow \\delta$, then $\\gamma\\alpha \\rightarrow \\delta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing $F^+$\n",
    "\n",
    "![Computing $F^+$](images/Figure_8_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closure of Attribute Sets\n",
    "\n",
    "- Given a set of attributes $\\alpha$, the **closure** of $\\alpha$ under $F$, denoted $\\alpha^+$, is the set of attributes that are functionally determined by $\\alpha$ under $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uses of Attribute Set Closure\n",
    "\n",
    "1. Test whether $\\alpha$ is a superkey of $R$ by computing $\\alpha^+$ and checking that $\\alpha^+$ contains all attributes of $R$.\n",
    "2. Test whether a functional dependency $\\alpha \\rightarrow \\beta$ holds on $R$, compute $\\alpha^+$ and check that $\\beta \\subseteq \\alpha^+$.\n",
    "3. Computing $F^+$:\n",
    "    1. For each $\\gamma \\subseteq R$,\n",
    "        1. Find the closure $\\gamma^+$.\n",
    "        2. For each $S \\subseteq \\gamma^+$, output the functional dependency $\\gamma \\rightarrow S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing $\\alpha^+$\n",
    "\n",
    "![Computing $\\alpha^+$](images/Figure_8_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canonical Cover\n",
    "\n",
    "- A **canonical cover** of $F$ is a minimal set of functional dependencies equivalent to $F$, having no redundant dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraneous Attributes\n",
    "\n",
    "- Given a set $F$ of functional dependencies and a functional dependency $\\alpha \\rightarrow \\beta$ in $F$,\n",
    "- Attribute $A$ is **extraneous** in $\\alpha$ if $A \\in \\alpha$ and $F$ logically implies $\\left( F - \\{ \\alpha \\rightarrow \\beta \\} \\right) \\cup \\left\\{ (\\alpha - A) \\rightarrow \\beta \\right\\}$.\n",
    "    - Compute $(\\{ \\alpha \\} - A)^+$ using the functional dependencies in $F$.\n",
    "    - $A$ is extraneous in $\\alpha$ if and only if $(\\{ \\alpha \\} - A)^+$ contains $\\beta$.\n",
    "- Attribute $B$ is **extraneous** in $\\beta$ if $B \\in \\beta$ and $\\left( F - \\{ \\alpha \\rightarrow \\beta \\} \\right) \\cup \\left\\{ \\alpha \\rightarrow (\\beta - B) \\right\\}$ logically implies $F$.\n",
    "    - Compute $\\alpha^+$ using the functional dependencies in $\\left( F - \\{ \\alpha \\rightarrow \\beta \\} \\right) \\cup \\left\\{ \\alpha \\rightarrow (\\beta - B) \\right\\}$.\n",
    "    - $B$ is extraneous in $\\beta$ if and only if $\\alpha^+$ contains $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing $F^C$\n",
    "\n",
    "![Computing $F^C$](images/Figure_8_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Algorithms for Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Test for BCNF\n",
    "\n",
    "1. Given a relation schema $R$ and a set of functional dependencies $F$,\n",
    "2. Compute attribute closures for all subsets of attributes of $R$ with respect to $F$.\n",
    "3. Examine the attribute closures and look for a dependency $\\alpha \\rightarrow \\beta$ that violates BCNF.\n",
    "4. If no such dependency exists, then conclude that $R$ is in BCNF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Test for BCNF\n",
    "\n",
    "1. If $F$ is a set of functional dependencies over **ONLY** the attributes of $R$,\n",
    "2. Examine each functional dependency $\\alpha \\rightarrow \\beta$ and check whether that violates BCNF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BCNF Decomposition\n",
    "\n",
    "![BCNF Decomposition](images/Figure_8_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Test for 3NF\n",
    "\n",
    "1. Given a relation schema $R$ and a set of functional dependencies $F$,\n",
    "2. Compute attribute closures for all subsets of attributes of $R$ with respect to $F$.\n",
    "3. Identify all candidate keys.\n",
    "4. Examine the attribute closures and look for a dependency $\\alpha \\rightarrow \\beta$ that violates 3NF.\n",
    "5. If no such dependency exists, then conclude that $R$ is in 3NF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Test for 3NF\n",
    "\n",
    "1. If $F$ is a set of functional dependencies over **ONLY** the attributes of $R$,\n",
    "2. Identify all candidate keys.\n",
    "3. Examine each functional dependency $\\alpha \\rightarrow \\beta$ and check whether that violates 3NF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3NF Decomposition\n",
    "\n",
    "![3NF Decomposition](images/Figure_8_12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10: Storage and File Structure <a name=\"chapter10\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Overview of Physical Storage Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage Device Hierarchy\n",
    "\n",
    "1. Cache\n",
    "2. Main Memory\n",
    "3. Flash Memory\n",
    "4. Magnetic-Disk Storage\n",
    "5. Optical Storage\n",
    "6. Tape Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage Types\n",
    "\n",
    "- **Primary Storage**: Cache, Main Memory\n",
    "- **Secondary Storage** (*Online Storage*): Flash Memory, Magnetic-Disk Storage\n",
    "- **Tertiary Storage** (*Offline Storage*): Optical Storage, Tape Storage\n",
    "- **Volatile Storage**: Losses Data without Power\n",
    "- **Nonvolatile Storage**: Preserves Data without Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Magnetic Disk and Flash Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magnetic Disk\n",
    "\n",
    "![Magnetic Disk](images/Figure_10_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Measures of Disks\n",
    "\n",
    "- **Access Time**: Time from when a read or write request is issued to when data transfer begins.\n",
    "- **Seek Time**: Time for repositioning the arm.\n",
    "- **Rotational Latency Time**: Time spent waiting for the sector to be accessed to appear under the head.\n",
    "- **Average Latency Time**: One-half the time for a full rotation of the disk.\n",
    "- **Data-Transfer Rate**: Rate at which data can be retrieved from or stored to the disk.\n",
    "- **Mean Time to Failure** (*MTTF*): Average time expected of the system to run continuously without any failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization of Disk-Block Access\n",
    "\n",
    "- **Block**: A logical unit consisting of a fixed number of contiguous sectors, typically ~KBs.\n",
    "- **Sequential Access**: Successive Requests for Successive Block.\n",
    "    - $1 \\times Seek Time + N \\times Transfer Time$\n",
    "- **Random Access**: Successive Requests for Random Blocks.\n",
    "    - $N \\times Seek Time + N \\times Transfer Time$\n",
    "\n",
    "##### Techniques\n",
    "\n",
    "- Buffering\n",
    "- Read-Ahead\n",
    "- Disk-Arm-Scheduling Algorithms (Elevator Algorithm)\n",
    "- File Organization & Fragmentation\n",
    "- Nonvolatile Write Buffers (NVRAM)\n",
    "- Log Disk (Journaling File Systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 RAID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RAID**: Redundant Arrays of Independent Disks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement of Reliability via Redundancy\n",
    "\n",
    "- **Mirroring**: Duplicate Disks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement in Performance via Parallelism\n",
    "\n",
    "- **Data Striping**: Write Data Across Multiple Disks\n",
    "- **Bit-Level Striping**: Bit $i$ to Disk $i$\n",
    "- **Block-Level Striping** Block $i$ to Disk $(i \\mod n) + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAID Levels\n",
    "\n",
    "- **RAID Level 5**\n",
    "    - *Small Write Performance*: $\\frac{N}{N - 1} \\times$\n",
    "    - *Large Write Performance*: $(N - 1) \\times$\n",
    "    - *Small Read Performance*: $N \\times$\n",
    "    - *Large Read Performance*: $(N - 1) \\times$\n",
    "- **RAID Level 10**: RAID Level 1 + RAID Level 0\n",
    "    - *Write Performance*: $\\frac{N}{2} \\times$\n",
    "    - *Read Performance*: $N \\times$\n",
    "\n",
    "![RAID Levels](images/Figure_10_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 File Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **File**: Sequence of Records\n",
    "- **Block**: $\\text{File} \\rightarrow \\text{Fixed-Length Blocks}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed-Length Records\n",
    "\n",
    "- Record $i$ to Bytes $n \\times (i - 1)$\n",
    "- **File Header**: Stores Address of First Deleted Record\n",
    "- **Free List**: Deleted Record $i$ $\\rightarrow$ Deleted Record $(i + 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable-Length Records\n",
    "\n",
    "- **Record** = &lt; Fixed Length Attributes, **Null Bitmap**, Variable Length Attributes &gt;\n",
    "    - *Variable Length Attributes*: Fixed Size (Offset, Length)\n",
    "- **Slotted-Page Structure**: Organizes Variable-Length Records via Header:\n",
    "    1. Number of Record Entries\n",
    "    2. End of Free Space in Block\n",
    "    3. Location & Size of Each Record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 Organization of Records in Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Heap File Organization**: Any record can be placed anywhere in the file where there is space for the record. There is no ordering of records.\n",
    "- **Sequential File Organization**: Records are stored in sequential order, according to the value of a \"search key\" of each record.\n",
    "- **Hashing File Organization**: A hash function is computed on some attribute of each record. The result of the hash function specifies in which block of the file the record should be placed.\n",
    "- **Multitable Clustering File Organization**: Records of several different relations are stored in the same file; further, related records of the different relations are stored on the same block, so that one I/O operation fetches related records from all the relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential File Organization\n",
    "\n",
    "- **Search Key**: Any set of attributes by which a sequential file is sorted.\n",
    "- **Insertion**:\n",
    "    1. Locate the position where the record is to be inserted.\n",
    "        1. If free space, insert.\n",
    "        2. If no free space, insert into an **overflow block**.\n",
    "    2. Update the pointer chain.\n",
    "- **Deletion**: Pointer Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.7 Data-Dictionary Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **data dictionary** (**system catalog**) keeps track of **metadata**, that is data about data, such as relation names, attribute names and types, storage information, integrity constraints, and user information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.8 Database Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Buffer**: A part of main memory available for storage of copies of disk blocks.\n",
    "- **Buffer Manager**: Subsystem responsible for the allocation of buffer space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buffer Manager\n",
    "\n",
    "- *Buffer Replacement Strategy*:\n",
    "    - Least Recently Used (LRU) for Sorting\n",
    "    - Most Recently Used (MRU) for Nested-Loop Joins\n",
    "- *Pinned Blocks*: No Write-Back During Updates\n",
    "- *Forced Output of Block*: Write-Back for Resiliency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 11: Indexing and Hashing <a name=\"chapter11\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Basic Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ordered Indices**: Based on a sorted ordering of the values.\n",
    "- **Hash Indices**: Based on a uniform distribution of values across a range of buckets to which values are assigned by a hash function.\n",
    "- **Range Query**: Find records with a range of attribute values.\n",
    "- **Point Query**: Find records with a specific attribute value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Ordered Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Primary Index** (*Clustering Index*): An index on a search key where the sort order of the search key matches the sort order of a relation.\n",
    "- **Secondary Index** (*Nonclustering Index*): An index on a search key where the sort order of the search key is different than the sort order of a relation.\n",
    "    - *Advantage*: Improves Performance.\n",
    "    - *Disadvantage*: Expensive Sequential Scan + Maintenance Overhead.\n",
    "- **Index-Sequential File**: A sequential file with a clustering index on the search key.\n",
    "    - *Disadvantage*: Performance Degradation $\\propto$ File Growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense and Sparse Indices\n",
    "\n",
    "- **Dense Indices**: Contain entries for every search-key value.\n",
    "    - *Advantage*: Faster Lookups Than Sparse Indices\n",
    "    - *Secondary Indices Always Dense*\n",
    "- **Sparse Indices**: Contain entries only for some search-key values.\n",
    "    - *Advantage*: Less Maintenance Overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 $B^+$-Tree Index Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **$B^+$-tree index** takes the form of a balanced tree, in which every path from the root of the tree to a leaf of the tree is of the same length.\n",
    "- The height of a $B^+$-tree is proportional to the logarithm to the base $N$ of the number of records in the relation, where each nonleaf node stores $N$ pointers.\n",
    "    - The value of $N$ is often around 50 or 100.\n",
    "- $B^+$-trees are much shorter than other balanced binary-tree structures such as AVL trees, and therefore require fewer disk accesses to locate records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of $B^+$-Tree\n",
    "\n",
    "![Example of $B^+$-Tree](images/Figure_11_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $B^+$-Tree File Organization\n",
    "\n",
    "- $B^+$-trees for indexing a file containing records, can also organize records into a file.\n",
    "- *Advantage*: Cheaper Point Queries\n",
    "- *Disadvantage*: Pricier Table Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 Multiple-Key Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indices on Multiple Keys\n",
    "\n",
    "- Composite Search Keys use Lexicographic Ordering:\n",
    "$$(a_1, a_2) < (b_1, b_2) \\implies a_1 < b_1 \\vee (a_1 = b_1 \\wedge a_2 < b_2)$$\n",
    "- *Efficient*: $a_1 = b_1 \\wedge a_2 = b_2$, $a_1 = b_1 \\wedge a_2 < b_2$\n",
    "- *Inefficient*: $a_1 < b_1 \\wedge a_2 = b_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6 Static Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Hash File Organization**: Obtain the address of the disk block containing a desired record directly by computing a function on the search-key value of the record.\n",
    "- **Hash Index Organization**: Organize the search keys, with their associated pointers into a hash file structure.\n",
    "- At design time, it is unknown precisely which search-key values will be stored in the file, a good hash function to choose is one that assigns search-key values to buckets such that the distribution is both uniform and random.\n",
    "- **Static Hashing**: Uses hash functions in which the set of bucket addresses is fixed.\n",
    "    - *Disadvantage*: Cannot Accommodate Data Growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling of Bucket Overflows\n",
    "\n",
    "- Bucket Overflow $\\leftarrow$ Insufficient Buckets + Skew\n",
    "- **Closed Hashing**: Handle Bucket Overflows with *Overflow Chaining*\n",
    "    - *Overflow Chaining*: A linked list of all the overflow buckets of a given bucket.\n",
    "- **Open Hashing**: Fixed Number of Buckets but Linear/Quadratic Probing, Double Hashing, Cuckoo Hashing for Reassignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.7 Dynamic Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dynamic Hashing**: Allow hash functions to be modified dynamically to accommodate the growth or shrinkage of the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extendable Hashing\n",
    "\n",
    "- Choose a uniform and random hash function $h$ that generates relatively large values ($b = 32$).\n",
    "- Use $0 \\leq i \\leq b$ prefix bits as the offset into a **bucket address table**.\n",
    "- Grow or shrink $i$ to split or coalesce buckets dynamically.\n",
    "- Allow multiple entries in the bucket address table to point to the same bucket,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Extendable Hashing\n",
    "\n",
    "![Example of Extendable Hashing](images/Figure_11_34.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lookups in Extendable Hashing\n",
    "\n",
    "1. Compute $h(K_j) = X$.\n",
    "2. Use $i$ most significant bits as an offset into the bucket address table to lookup bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insertions in Extendable Hashing\n",
    "\n",
    "1. If bucket $j$ has free space, insert record.\n",
    "2. Else,\n",
    "    - If $\\geq 1$ pointers to bucket $j$,\n",
    "        1. Split bucket $j$ into 2 buckets.\n",
    "        2. Divide the data and pointers between the 2 buckets.\n",
    "    - If $1$ pointers to bucket $j$,\n",
    "        - If too many splits,\n",
    "            1. Create an overflow bucket.\n",
    "        - Else,\n",
    "            1. Increment $i$.\n",
    "            2. Double the size of the bucket address table.\n",
    "            3. Replace each entry in the bucket address table with 2 entries that point to the same bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deletions in Extendable Hashing\n",
    "\n",
    "1. Remove record from bucket $j$.\n",
    "2. If bucket $j$ is empty, remove it from the bucket address table.\n",
    "3. If possible, coalesce a bucket with a neighbouring bucket that has the same hash prefix.\n",
    "4. Rarely, decrease the size of the bucket address table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 12: Query Processing <a name=\"chapter12\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Steps in Query Processing](images/Figure_12_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Measures of Query Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Cost Measure*:\n",
    "    - Number of Block Transfers ($t_T$ - Transfer Time for 1 Block)\n",
    "    - Number of Disk Seeks ($t_S$ - Seek Time for 1 Block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Selection Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Process simple selection operations by performing a linear scan, or by making use of indices.\n",
    "- Process complex selections by computing unions and intersections of the results of simple selections.\n",
    "\n",
    "![Cost Estimates for Selection Algorithms](images/Figure_12_3.png)\n",
    "\n",
    "##### Fixes\n",
    "\n",
    "- **A3**: $h_i * (t_T + t_S) + t_S + b * t_T$\n",
    "- **A5**: $h_i * (t_T + t_S) + t_S + b * t_T$\n",
    "- **A6**: $(h_i + k + n) * (t_T + t_S)$\n",
    "    - $k$ block transfers and seeks to find other matching index entries in leaf level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 Sorting (Not Mandatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort relations larger than memory by the **external sort–merge algorithm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Sort-Merge Algorithm\n",
    "\n",
    "1. A number of sorted runs are created; each run is sorted, but contains only some of the records of the relation.\n",
    "\n",
    "![External Sort-Merge 1](images/Figure_12_ESM_1.png)\n",
    "\n",
    "2. The runs are merged.\n",
    "\n",
    "![External Sort-Merge 2](images/Figure_12_ESM_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Analysis of External Sort-Merge\n",
    "\n",
    "- Let $M$ be the number of blocks in the main memory buffer available for sorting.\n",
    "- Let $b_r$ be the number of blocks containing records of relation $r$.\n",
    "- Let $b_b$ be the number of blocks allocated to each run.\n",
    "- **Number of Transfers**: $b_r \\left( 2 \\left\\lceil \\log_{M - 1}(b_r / M) \\right\\rceil + 1 \\right)$\n",
    "- **Number of Seeks**: $2 \\lceil b_r / M \\rceil + \\lceil b_r / b_b \\rceil \\left( 2 \\left\\lceil \\log_{M - 1}(b_r / M) \\right\\rceil + 1 \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.5 Join Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested-Loop Join\n",
    "\n",
    "![Nested-Loop Join](images/Figure_12_5.png)\n",
    "\n",
    "- If the buffer can hold only one block of each relation,\n",
    "    - **Number of Transfers**: $n_r * b_s + b_r$\n",
    "    - **Number of Seeks**: $n_r + b_r$\n",
    "- If the buffer can hold the smaller relation or both relations,\n",
    "    - **Number of Transfers**: $b_r + b_s$\n",
    "    - **Number of Seeks**: $2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block Nested-Loop Join\n",
    "\n",
    "![Block Nested-Loop Join](images/Figure_12_6.png)\n",
    "\n",
    "- If the buffer can hold only one block of each relation,\n",
    "    - **Number of Transfers**: $b_r * b_s + b_r$\n",
    "    - **Number of Seeks**: $2 * b_r$\n",
    "- If the buffer can hold the smaller relation or both relations,\n",
    "    - **Number of Transfers**: $b_r + b_s$\n",
    "    - **Number of Seeks**: $2$\n",
    "- If the buffer can hold $M$ blocks,\n",
    "    - Read $M - 2$ blocks for the outer relation.\n",
    "    - Read 1 block for the inner relaiton.\n",
    "    - **Number of Transfers**: $\\lceil b_r / (M - 2) \\rceil * b_s + b_r$\n",
    "    - **Number of Seeks**: $2 * \\lceil b_r / (M - 2) \\rceil$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexed Nested-Loop Join\n",
    "\n",
    "![Indexed Nested-Loop Join](images/Figure_12_INLJ_1.png)\n",
    "\n",
    "- If the buffer can hold only one block of each relation,\n",
    "    - **Cost**: $b_r (t_T + t_S) + n_r * c$\n",
    "        - Let $c$ be the average cost of traversing the index and fetching all the matching $s$ tuples for one tuple $t_r$ of $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort-Merge Join (Not Mandatory)\n",
    "\n",
    "![Sort-Merge Join](images/Figure_12_7.png)\n",
    "\n",
    "- If input relations $r$ and $s$ are already sorted on the join attributes,\n",
    "    - **Number of Transfers**: $b_r + b_s$\n",
    "    - **Number of Seeks**: $\\lceil b_r / b_b \\rceil + \\lceil b_s / b_b \\rceil$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hash Join (Not Mandatory)\n",
    "\n",
    "![Hash Join](images/Figure_12_10.png)\n",
    "\n",
    "- **Recursive Partitioning**: With a new hash function, each bucket generated by one pass is separately read and partitioned again in the next pass, to create smaller partitions.\n",
    "    - *Required*: $M \\leq n_h + 1$ or $M \\leq (b_s / M) + 1$, approximately $M \\leq \\sqrt(b_s)$\n",
    "- If recursive partitioning is not required,\n",
    "    - Let $n_h$ be the number of partition pairs.\n",
    "    - **Number of Transfers**: $3(b_r + b_s) + 4n_h$\n",
    "    - **Number of Seeks**: $2\\left( \\lceil b_r / b_b \\rceil + \\lceil b_s / b_b \\rceil \\right) + 2n_h$\n",
    "- If the value of $n_h$ is greater than or equal to the number of blocks of memory, recursive partitioning is required,\n",
    "    - **Number of Transfers**: $2(b_r + b_s)\\lceil \\log_{M - 1}(b_s) - 1 \\rceil + b_r + b_s$\n",
    "    - **Number of Seeks**: $2\\left( \\lceil b_r / b_b \\rceil + \\lceil b_s / b_b \\rceil \\right)\\lceil \\log_{M - 1}(b_s) - 1 \\rceil$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.6 Other Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Duplicate elimination, projection, set operations (union, intersection, and difference), and aggregation can be done by sorting or by hashing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 13: Query Optimization (Not Mandatory) <a name=\"chapter13\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given a query, there are generally a variety of methods for computing the answer. It is the responsibility of the system to transform the query as entered by the user into an equivalent query that can be computed more efficiently.\n",
    "- The process of finding a good strategy for processing a query is called **query optimization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Transformation of Relational Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Conjunctive selection operations can be deconstructed into a sequence of individual selections. This transformation is referred to as a cascade of $\\sigma$.\n",
    "$$\\sigma_{\\theta_1 \\wedge \\theta_2}(E) = \\sigma_{\\theta_1}\\left( \\sigma_{\\theta_2}(E) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Selection operations are commutative.\n",
    "$$\\sigma_{\\theta_1}\\left( \\sigma_{\\theta_2}(E) \\right) = \\sigma_{\\theta_2}\\left( \\sigma_{\\theta_1}(E) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Only the final operations in a sequence of projection operations are needed; the others can be omitted. This transformation can also be referred to as a cascade of $\\prod$.\n",
    "$$\\prod_{L_1}\\left( \\prod_{L_2}\\left( ... \\left( \\prod_{L_n}\\left( E \\right) \\right) ...  \\right) \\right) = \\prod_{L_1}(E)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Selections can be combined with Cartesian products and theta joins.\n",
    "    1. $\\sigma_{\\theta}(E_1 \\times E_2) = E_1 \\Join_{\\theta} E_2$\n",
    "    2. $\\sigma_{\\theta_1}(E_1 \\Join_{\\theta_2} E_2) = E_1 \\Join_{\\theta_1 \\wedge \\theta_2} E_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Theta-join operations are commutative.\n",
    "$$E_1 \\Join_{\\theta} E_2 = E_2 \\Join_{\\theta} E_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Natural-join operations are associative.\n",
    "$$(E_1 \\Join E_2) \\Join E_3 = E_1 \\Join (E_2 \\Join E_3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Theta joins are associative.\n",
    "$$(E_1 \\Join_{\\theta_1} E_2) \\Join_{\\theta_2 \\wedge \\theta_3} E_3 = E_1 \\Join_{\\theta_1 \\wedge \\theta_3} (E_2 \\Join_{\\theta_2} E_3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. The selection operation distributes over the theta-join operation under the following two conditions:\n",
    "    1. It distributes when all the attributes in selection condition $\\theta_0$ involve only the attributes of one of the expressions (say, $E_1$) being joined.\n",
    "$$\\sigma_{\\theta_0}(E_1 \\Join_{\\theta} E_2) = \\left( \\sigma_{\\theta_0}(E_1) \\right) \\Join_{\\theta} E_2$$\n",
    "    2. It distributes when selection condition $\\theta_1$ involves only the attributes of $E_1$ and $\\theta_2$ involves only the attributes of $E_2$.\n",
    "$$\\sigma_{\\theta_1 \\wedge \\theta_2}(E_1 \\Join_{\\theta} E_2) = \\left( \\sigma_{\\theta_1}(E_1) \\right) \\Join_{\\theta} \\left( \\sigma_{\\theta_2}(E_2) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. The projection operation distributes over the theta-join operation under the following conditions.\n",
    "    1. Let $L_1$ and $L_2$ be attributes of $E_1$ and $E_2$, respectively. Suppose that the join condition $\\theta$ involves only attributes in $L_1 \\cup L_2$. Then,\n",
    "$$\\prod_{L_1 \\cup L_2}(E_1 \\Join_{\\theta} E_2) = \\left( \\prod_{L_1}(E_1) \\right) \\Join_{\\theta} \\left( \\prod_{L_2}(E_2) \\right)$$\n",
    "    2. Consider a join $E_1 \\Join_{\\theta} E_2$. Let $L_1$ and $L_2$ be sets of attributes from $E_1$ and $E_2$, respectively. Let $L_3$ be attributes of $E_1$ that are involved in join condition $\\theta$, but are not in $L_1 \\cup L_2$, and let $L_4$ be attributes of $E_2$ that are involved in join condition $\\theta$, but are not in $L_1 \\cup L_2$. Then,\n",
    "$$\\prod_{L_1 \\cup L_2}(E_1 \\Join_{\\theta} E_2) = \\prod_{L_1 \\cup L_2}\\left( \\left( \\prod_{L_1 \\cup L_3}(E_1) \\right) \\Join_{\\theta} \\left( \\prod_{L_2 \\cup L_4}(E_2) \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. The set operations union and intersection are commutative.\n",
    "$$E_1 \\cup E_2 = E_2 \\cup E_1$$\n",
    "$$E_1 \\cap E_2 = E_2 \\cap E_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Set union and intersection are associative.\n",
    "$$(E_1 \\cup E_2) \\cup E_3 = E_1 \\cup (E_2 \\cup E_3)$$\n",
    "$$(E_1 \\cap E_2) \\cap E_3 = E_1 \\cap (E_2 \\cap E_3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. The selection operation distributes over the union, intersection, and set-difference operations.\n",
    "$$\\sigma_{p}(E_1 - E_2) = \\sigma_{p}(E_1) - \\sigma_{p}(E_2)$$\n",
    "$$\\sigma_{p}(E_1 \\cup E_2) = \\sigma_{p}(E_1) \\cup \\sigma_{p}(E_2)$$\n",
    "$$\\sigma_{p}(E_1 \\cap E_2) = \\sigma_{p}(E_1) \\cap \\sigma_{p}(E_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. The projection operation distributes over the union operation.\n",
    "$$\\prod_{L}(E_1 \\cup E_2) = \\left( \\prod_{L}(E_1) \\right) \\cup \\left( \\prod_{L}(E_2) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 14: Transactions <a name=\"chapter14\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Transaction Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **transaction** is an atomic unit of program that accesses and possibly updates various data items.\n",
    "- **Atomicity**: Either all operations of the transactions are reflected properly in the database, or none are.\n",
    "- **Consistency**: Execution of a transaction in isolation preserves the consistency of the database.\n",
    "- **Isolation**: Even though multiple transactions may execute concurrently, the system guarantees that, for every pair of transactions $T_i$ and $T_j$, it appears to $T_i$ that either $T_j$ finished execution before $T_i$ started or $T_j$ started execution after $T_i$ finished. Thus, each transaction is unaware of other transactions executing concurrently in the system.\n",
    "- **Durability**: After a transaction completes successfully, the changes it has made to the database persist, even if there are system failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4 Transaction Atomicity and Durability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction States\n",
    "\n",
    "- **Active**: The initial state; the transaction stays in this state while executing.\n",
    "- **Partially Committed**: After the final statement has been executed.\n",
    "- **Failed**: After the discovery that normal execution can no longer proceed.\n",
    "- **Aborted**: After the transaction has been rolled back and the database has been restored to its state prior to the start of the transaction.\n",
    "    1. Restart Transaction.\n",
    "    2. Kill Transaction.\n",
    "- **Committed**: After successful completion.\n",
    "\n",
    "![State Diagram of a Transaction](images/Figure_14_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5 Transaction Isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **schedule** is a sequence of instructions that specify the chronological order in which instructions of concurrent transactions are executed.\n",
    "- A **serial schedule** is one in which a transaction that has been started runs to completion before another transaction may start.\n",
    "- A transaction that successfully completes its execution ends with a **commit instruction**.\n",
    "- A transcation that fails to successfully complete its execution ends with an **abort instruction**.\n",
    "\n",
    "![Schedule 1](images/Figure_14_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6 Serializability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A schedule is **serializable** if it is equivalent to a serial schedule, so it preserves consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conflict\n",
    "\n",
    "- Given a schedule $S$ in which there are 2 consecutive instructions $I$ and $J$, of transactions $T_i$ and $T_j$, respectively ($i \\neq j$),\n",
    "- If $I$ and $J$ refer to different data items, then we can swap $I$ and $J$ without affecting the results of any instruction in the schedule.\n",
    "- Else, $I$ and $J$ **conflict** if they are operations by different transactions on the same data item, and at least one of these instructions is a write operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conflict Serializability\n",
    "\n",
    "- Let $S$ and $S'$ be schedules for some set $R$ of transactions.\n",
    "- If schedule $S$ can be transformed into schedule $S'$ by a series of swaps of **NON-CONFLICTING INSTRUCTIONS**, then we say that $S$ and$S'$ are **conflict equivalent**.\n",
    "- A schedule $S$ is **conflict serializable** if it is *conflict equivalent* to a *serial schedule*.\n",
    "\n",
    "![Conflict Serializability of Schedule 3 into Schedule 6](images/Figure_14_CS_1.png)\n",
    "\n",
    "- $T_1$'s $\\text{read}(B), \\text{write}(B)$ do not conflict with $T_2$'s $\\text{read}(A), \\text{write}(A)$, so they can be swapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for Conflict Serializability\n",
    "\n",
    "- **Precedence Graph**: A directed graph where the vertices are transactions and edges are conflicting operations.\n",
    "- $T_i \\rightarrow T_j$,\n",
    "    1. $T_i$ executes $\\text{write}(Q)$ before $T_j$ executes $\\text{read}(Q)$.\n",
    "    2. $T_i$ executes $\\text{read}(Q)$ before $T_j$ executes $\\text{write}(Q)$.\n",
    "    3. $T_i$ executes $\\text{write}(Q)$ before $T_j$ executes $\\text{write}(Q)$.\n",
    "- If the precedence graph for $S$ has a cycle, then schedule $S$ is not conflict serializable.\n",
    "- Else, a **serializability order** of the transactions can be obtained by finding a linear order consistent with the partial order of the precedence graph by performing **topological sort**.\n",
    "\n",
    "![Topological Sort](images/Figure_14_12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7 Transaction Isolation and Atomicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recoverable Schedules\n",
    "\n",
    "- A **recoverable schedule** is one where, for each pair of transactions $T_i$ and $T_j$ such that $T_j$ reads a data item previously written by $T_i$, the commit operation of $T_i$ appears before the commit operation of $T_j$.\n",
    "\n",
    "![Nonrecoverable Schedule](images/Figure_14_14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cascading Rollback\n",
    "\n",
    "- A **cascading rollback** occurs when a single transaction failure leads to a series of transaction rollbacks.\n",
    "\n",
    "![Cascading Rollback](images/Figure_14_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cascadeless Schedules\n",
    "\n",
    "- A **cascadeless schedule** is one where, for each pair of transactions $T_i$ and $T_j$ such that $T_j$ reads a data item previously written by $T_i$, the commit operation of $T_i$ appears before the read operation of $T_j$.\n",
    "- Every cascadeless schedule is a recoverable schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8 Transaction Isolation Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction Isolation Anomalies\n",
    "\n",
    "- **Phantom Read**: The results of a query in one transaction are changed by another transaction before the former commits.\n",
    "- **Non-Repeatable Read**: Repeated reads of the same record in one transaction return different values because of an update made by another transaction.\n",
    "- **Dirty Read**: One transaction reads a value written by another transaction that has not yet committed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction Isolation Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Isolation Level  | Allow Phantom Reads? | Allow Non-Repeatable Reads? | Allow Dirty Reads? |\n",
    "| ---------------- |:--------------------:|:---------------------------:|:------------------:|\n",
    "| Serializable     | No                   | No                          | No                 |\n",
    "| Repeatable Read  | Yes                  | No                          | No                 |\n",
    "| Read Committed   | Yes                  | Yes                         | No                 |\n",
    "| Read Uncommitted | Yes                  | Yes                         | Yes                | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 15: Concurrency Control <a name=\"chapter15\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When several transactions execute concurrently in the database, the consistency of data may no longer be preserved.\n",
    "- It is necessary for the system to control the interaction among the concurrent transactions, and this control is achieved through one of a variety of mechanisms called **concurrency-control schemes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1 Lock-Based Protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locks\n",
    "\n",
    "- **Shared Lock**: If a transaction $T_i$ has obtained a **shared-mode lock** (denoted by $S$) on item $Q$, then $T_i$ can read, but cannot write, $Q$.\n",
    "- **Exclusive Lock**: If a transaction $T_i$ has obtained an **exclusive-mode lock** (denoted by $X$) on item $Q$, then $T_i$ can both read and write $Q$.\n",
    "- A transaction may be granted a lock on an item if the requested lock is **compatible** with all locks already held on that item by other transactions.\n",
    "- A **lock manager** grants locks requested by a transaction, force a transaction to wait, or force a transaction to abort to avoid a **deadlock**.\n",
    "- A **locking protocol** is a set of rules indicating when a transaction may lock and unlock each of the data items.\n",
    "    - *Allow Only Conflict-Serializable Schedules*\n",
    "\n",
    "![Lock-Compatibility Matrix Group](images/Figure_15_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Granting of Locks\n",
    "\n",
    "- When a transaction $T_i$ requests a lock on a data item $Q$ in a particular mode $M$, the concurrency-control manager grants the lock provided that:\n",
    "    1. There is no other transaction holding a lock on $Q$ in a mode that conflicts with $M$.\n",
    "    2. There is no other transaction that is waiting for a lock on $Q$ and that made its lock request before $T_i$.\n",
    "- A lock request will never get blocked by a lock request that is made later to prevent **starvation**.\n",
    "\n",
    "![Schedule with Concurrency-Control Manager](images/Figure_15_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Phase Locking Protocol\n",
    "\n",
    "- The **two-phase locking protocol** allows a transaction to lock a new data item only if that transaction has not yet unlocked any data item.\n",
    "- The protocol ensures *serializability*, but not *deadlock freedom*.\n",
    "- In the absence of information concerning the manner in which data items are accessed, the two-phase locking protocol is both necessary and sufficient for ensuring serializability.\n",
    "\n",
    "##### Phases\n",
    "\n",
    "1. **Growing Phase**: A transaction may obtain locks, but may not release any lock.\n",
    "    - A shared lock can be **upgraded** into an exclusive lock without releasing the lock.\n",
    "2. **Shrinking Phase**: A transaction may release locks, but may not obtain new locks.\n",
    "    - An exclusive lock can be **downgraded** into a shared lock without obtaining a new lock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strict Two-Phase Locking Protocol\n",
    "\n",
    "- The **strict two-phase locking protocol permits** release of exclusive locks only at the end of transaction, in order to ensure *recoverability* and *cascadelessness* of the resulting schedules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rigorous Two-Phase Locking Protocol\n",
    "\n",
    "- The **rigorous two-phase locking protocol** releases all locks only at the end of the transaction, for simplicity at the cost of reduced parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic Acquisition of Locks\n",
    "\n",
    "- When a transaction $T_i$ issues a $\\text{read}(Q)$ operation, the system issues a $\\text{lock-s}(Q)$ instruction before the operation.\n",
    "- When a transaction $T_i$ issues a $\\text{write}(Q)$ operation, the system checks to see whether $T_i$ already holds a shared lock on $Q$.\n",
    "    - If it does, then the system issues an $\\text{upgrade}(Q)$ instruction before the operation.\n",
    "    - Else, the system issues a $\\text{lock-x}(Q)$ instruction before the operation.\n",
    "- All locks obtained by a transaction are unlocked after that transaction commits or aborts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Locking\n",
    "\n",
    "![Lock Table](images/Figure_15_10.png)\n",
    "\n",
    "- When a lock request arrives, add a record to the end of the linked list for the data item.\n",
    "    - Always grant a lock request on a data item that is not currently locked.\n",
    "    - If it is compatible with the locks that are currently held, and all earlier requests have been granted already, grant the lock request.\n",
    "    - Else, the lock request has to wait.\n",
    "- When an unlock request arrives, delete the record for the corresponding data item.\n",
    "    - Try to grant any waiting lock request.\n",
    "- If a transaction aborts, delete any waiting requests made by the transaction and release all locks held by the transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2 Deadlock Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **deadlock prevention** protocol ensures that the system will never enter a deadlock state.\n",
    "- A **deadlock detection** and a **deadlock recovery** scheme allow the system to enter a deadlock state and then try to recover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deadlock Prevention\n",
    "\n",
    "- **Pre-Declaration**: Each transaction locks all its data items before it begins execution.\n",
    "- **Lock Ordering**: Impose a partial order on all data items and require that a transaction lock data items in the order specified.\n",
    "- **Timeout-Based**: A transaction waits for a lock only for a specified amount of time, and then rolls back if the lock is not granted.\n",
    "- **Wait-Die** (*Non-Preemptive*)(*Elders are Selfless*):\n",
    "    - When transaction $T_i$ requests a data item currently held by $T_j$, $T_i$ is allowed to wait only if it is older than $T_j$.\n",
    "    - Else, younger $T_i$ rolls back (*died*).\n",
    "    - *Avoids Starvation*\n",
    "\n",
    "- **Wound-Wait** (*Preemptive*)(*Elders are Selfish*):\n",
    "    - When transaction $T_i$ requests a data item currently held by $T_j$, $T_i$ is allowed to wait only if it is younger than $T_j$.\n",
    "    - Else, younger $T_j$ rolls back (*wounded*).\n",
    "    - *Avoids Starvation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deadlock Detection\n",
    "\n",
    "- **Wait-For Graph**: A directed graph where the vertices are transactions and edges are *wait-for* dependencies.\n",
    "- A deadlock exists in the system if and only if the wait-for graph contains a cycle.\n",
    "- The system can recover from the deadlock by,\n",
    "    1. Selecting a victim in the cycle who starved the least.\n",
    "    2. Performing a **total rollback** or a **partial rollback** on the victim to break the cycle.\n",
    "    \n",
    "![Wait-For Graph](images/Figure_15_WFG_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3 Multiple Granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are circumstances where it would be advantageous to group several data items, and to treat them as one aggregate data item for purposes of working, resulting in multiple levels of **granularity**.\n",
    "- When a transaction locks a node in the granularity hierarchy tree *explicitly*, it *implicitly* locks all the descendants in the **SAME** mode.\n",
    "- **Fine Granularity** (*Lower in Hierarchy*): Greater Concurrency, Higher Locking Overhead\n",
    "- **Coarse Granularity** (*Higher in Hierarchy*): Lesser Concurrency, Lower Locking Overhead\n",
    "\n",
    "![Granular Hierarchy](images/Figure_15_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intention Lock Modes\n",
    "\n",
    "- If a node is locked in an **intention mode**, explicit locking is done at a lower level of the tree (that is, at a finer granularity).\n",
    "- Intention locks are put on all the ancestors of a node before that node is locked explicitly.\n",
    "- Thus, a transaction does not need to search the entire tree to determine whether it can lock a node successfully.\n",
    "- **Intention-Shared** ($IS$): Indicates intent to lock explicitly at a lower level of the tree but only with shared locks.\n",
    "- **Intention-Exclusive** ($IX$): Indicates intent to lock explicitly at a lower level of the tree with exclusive or shared locks.\n",
    "- **Shared and Intention-Exclusive** ($SIX$): Locks the subtree rooted at a given node explicitly in the shared mode, and indicates intent to lock explicitly at a lower level with exclusive locks.\n",
    "\n",
    "![Compatibility Matrix](images/Figure_15_16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple-Granularity Locking Protocol\n",
    "\n",
    "- *Ensures Serializability; No Deadlock Freedom*\n",
    "- Locks must be acquired in top-down (root-to-leaf) order.\n",
    "- Locks must be released in bottom-up (leaf-to-root) order.\n",
    "\n",
    "##### Rules\n",
    "\n",
    "1. Transaction $T_i$ must observe the lock-compatibility matrix.\n",
    "2. Transaction $T_i$ must lock the root of tree first and can lock it in any mode.\n",
    "3. Transaction $T_i$ can lock a node $Q$ in $S$ or $IS$ mode only if $T_i$ currently has the parent of $Q$ locked in either $IX$ or $IS$ mode.\n",
    "4. Transaction $T_i$ can lock a node $Q$ in $X$, $SIX$, or $IX$ mode only if $T_i$ currently has the parent locked in either $IX$ or $SIX$ mode.\n",
    "5. Transaction $T_i$ can lock a node only if $T_i$ has not previously unlocked any node (that is, $T_i$ is two phase).\n",
    "6. Transaction $T_i$ can unlock a node $Q$ only if $T_i$ currently has none of the children $Q$ locked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4 Timestamp-Based Protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A timestamp-ordering scheme ensures *conflict serializability* by selecting an ordering in advance between every pair of transactions.\n",
    "- The timestamps of the transactions determine the serializability order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamps\n",
    "\n",
    "- **$W$-timestamp($Q$)**: Largest timestamp of any transaction that executed $\\text{write}(Q)$ successfully.\n",
    "- **$R$-timestamp($Q$)**: Largest timestamp of any transaction that executed $\\text{read}(Q)$ successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp Ordering Protocol\n",
    "\n",
    "- Suppose that transaction $T_i$ issues $\\text{read}(Q)$.\n",
    "    1. If $\\text{TS}(T_i) < W\\text{-timestamp}(Q)$, then $T_i$ is attempting to read a value of $Q$ that has already been overwritten.\n",
    "        1. Reject the $\\text{read}(Q)$ operation.\n",
    "        2. Rollback $T_i$.\n",
    "    2. If $\\text{TS}(T_i) \\geq W\\text{-timestamp}(Q)$, then $T_i$ is attempting to read the latest value of $Q$.\n",
    "        1. Return the value of $Q$.\n",
    "        2. Set $R\\text{-timestamp}(Q)$ to $\\max(R\\text{-timestamp}(Q), \\text{TS}(T_i))$.\n",
    "- Suppose that transaction $T_i$ issues $\\text{write}(Q)$.\n",
    "    1. If $\\text{TS}(T_i) < R\\text{-timestamp}(Q)$, then the value of $Q$ that $T_i$ is producing was needed previously, and the system assumed that the value would never be produced.\n",
    "        1. Reject the $\\text{write}(Q)$ operation.\n",
    "        2. Rollback $T_i$.\n",
    "    2. If $\\text{TS}(T_i) < W\\text{-timestamp}(Q)$, then $T_i$ is attempting to write an obsolete value of $Q$.\n",
    "        1. Reject the $\\text{write}(Q)$ operation.\n",
    "        2. Rollback $T_i$.\n",
    "    3. Else,\n",
    "        1. Update the value of $Q$.\n",
    "        2. Set $W\\text{-timestamp}(Q)$ to $\\text{TS}(T_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thomas' Write Rule\n",
    "\n",
    "- Allows some view-serializable schedules that are not conflict serializable to improve concurrency.\n",
    "- Suppose that transaction $T_i$ issues $\\text{write}(Q)$.\n",
    "    1. ...*Unchanged*...\n",
    "    2. If $\\text{TS}(T_i) < W\\text{-timestamp}(Q)$, then $T_i$ is attempting to write an obsolete value of $Q$.\n",
    "        1. **Ignore the $\\text{write}(Q)$ operation.**\n",
    "    3. ...*Unchanged*..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.6 Multiversion Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **multiversion concurrency-control scheme** is based on the creation of a new version of a data item for each transaction that writes that item.\n",
    "- When a read operation is issued, the system selects one of the versions to be read.\n",
    "- The concurrency-control scheme ensures that the version to be read is selected in a manner that ensures *serializability*, by using timestamps. A read operation always succeeds.\n",
    "    - In multiversion timestamp ordering, a write operation may result in the rollback of the transaction.\n",
    "    - In multiversion two-phase locking, write operations may result in a lock wait or, possibly, in deadlock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 16: Recovery System <a name=\"chapter16\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1 Failure Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Logical Error**: Transaction can no longer continue with its normal execution because of some internal condition, such as bad input, data not found, overflow, or resource limit exceeded.\n",
    "- **System Error**: The system has entered an undesirable state, as a result of which a transaction cannot continue with its normal execution. The transaction, however, can be reexecuted at a later time.\n",
    "- **System Crash**: There is a hardware or a software malfunction that brings transaction processing to a halt.\n",
    "    - **Fail-Stop Assumption**: When a system halts, it does not corrupt the nonvolatile storage contents.\n",
    "- **Disk Failure**: A disk block loses its content as a result of either a head crash or failure during  a data-transfer operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.2 Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Volatile Storage*: Lose Data @ Crash\n",
    "- *Nonvolatile Storage*: Keep Data @ Crash; Lose Data @ Disk Failure\n",
    "- *Stable Storage*: Never Lose Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Access\n",
    "\n",
    "- **Physical Blocks** = Disk Blocks\n",
    "- **Buffer Blocks** = Memory Blocks\n",
    "- Each transaction $T_i$ has a private **work area** in which it keeps local copies of all data items it accesses and updates.\n",
    "    - $\\text{read}(X)$ is always executed before accessing for the first time.\n",
    "    - $\\text{write}(X)$ may be executed at any time before the transaction commits.\n",
    "\n",
    "##### Transfer between Disk and Main Memory\n",
    "\n",
    "1. $\\text{input}(B)$: Physical Block $B$ to Main Memory\n",
    "2. $\\text{output}(B)$: Buffer Block $B$ to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.3 Recovery and Atomicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Records\n",
    "\n",
    "- A **log** is a sequence of **log records**, recording all the update activities in the database.\n",
    "- *Transaction Start Record*: &lt; $T_i$ **start** &gt;\n",
    "- *Transaction Update Record*: &lt; $T_i$, $X$, $V_1$, $V_2$ &gt;\n",
    "- *Transaction Compensation Record*: &lt; $T_i$, $X$, $V_1$ &gt;\n",
    "- *Transaction Commit Record*: &lt; $T_i$ **commit** &gt;\n",
    "- *Transaction Abort Record*: &lt; $T_i$ **abort** &gt;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database Modification\n",
    "\n",
    "- **Immediate-Modification Scheme**: Allow updates of an uncommitted transaction to be made to the buffer or the disk before the transaction commits.\n",
    "    - **Write-Ahead Logging Rule**: An *Update Record* must be outputted to stable storage before the database item is written to disk.\n",
    "- **Deferred-Modification Scheme**: Writes to buffer or the disk only at the time of transaction commit.\n",
    "    - *Advantage*: Simple Recovery\n",
    "    - *Disadvantage*: Overhead of Work Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undo and Redo Transactions\n",
    "\n",
    "- **Undo**: Using a log record, sets the data item specified in the log record to the old value.\n",
    "    - Undo transaction $T_i$ by going *backwards* from the *last* log record of $T_i$ and appending a *Compensation Record* with a final *Abort Record*.\n",
    "    - **Recovery Required**: If the log contains a *Start Record* but no *Commit Record* or *Abort Record*.\n",
    "- **Redo**: Using a log record, sets the data item specified in the log record to the new value.\n",
    "    - Redo transaction $T_i$ by going *forward* from the *first* log record of $T_i$.\n",
    "    - **Recovery Required**: If the log contains a *Start Record* and a *Commit Record* or an *Abort Record*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeating History\n",
    "\n",
    "- Modern recovery algorithms are based on the concept of **repeating history**, whereby all actions taken during normal operation (since the last completed checkpoint) are replayed during the redo pass of recovery.\n",
    "- Repeating history restores the system state to what it was at the time the last log record was output to stable storage before the system crashed.\n",
    "- Undo is then performed from this state, by executing an undo pass that processes log records of incomplete transactions in reverse order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoints\n",
    "\n",
    "- To reduce the overhead of searching the log and redoing transactions, we can use **checkpointing** techniques.\n",
    "- Transactions are not allowed to perform any update actions while a checkpoint is in progress.\n",
    "- The $\\text{redo}$ or $\\text{undo}$ operations need to be applied only to transactions in $L$, and to all transactions that started execution after the &lt; **checkpoint** $L$ &gt; record was written to the log.\n",
    "\n",
    "##### Procedure\n",
    "\n",
    "1. Output onto stable storage all records currently residing in main memory.\n",
    "2. Output to the disk all modified buffer blocks.\n",
    "3. Output onto stable storage a log record of the form &lt; **checkpoint** $L$ &gt;, where $L$ is a list of transactions active at the time of the checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy Checkpoint\n",
    "\n",
    "- A **fuzzy checkpoint** is a checkpoint where transactions are allowed to perform updates even while buffer blocks are being written out.\n",
    "\n",
    "##### Procedure\n",
    "\n",
    "1. Stop all updates by transactions.\n",
    "2. Write a &lt; **checkpoint** $L$ &gt; record.\n",
    "3. Flush the log to stable storage.\n",
    "4. Resume updates by transactions.\n",
    "5. Output to disk all modified buffer blocks.\n",
    "    - Buffer blocks should not be updated while being outputted.\n",
    "    - *WAL Rule*: All log records pertaining to a block must be output before the block is outputted.\n",
    "6. Store a pointer to the &lt; **checkpoint** $L$ &gt; record in a fixed position *last_checkpoint* on disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.4 Recovery Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example of Logged Actions During Recovery](images/Figure_16_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.5 Buffer Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Efficient implementation of a recovery scheme requires that the number of writes to the database and to stable storage be minimized.\n",
    "- Log records may be kept in volatile log buffer initially, but must be written to stable storage when one of the following conditions occurs:\n",
    "    - Before the &lt; $T_i$ **commit** &gt; log record may be output to stable storage, all log records pertaining to transaction Ti must have been output to stable storage.\n",
    "    - Before a block of data in main memory is output to the database (in nonvolatile storage), all log records pertaining to data in that block must have been output to stable storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.8 ARIES (Not Mandatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Major Features\n",
    "\n",
    "1. Uses a **log sequence number** (LSN) to identify log records, and stores LSNs in database pages to identify which operations have been applied to a database page.\n",
    "2. Support **physiological redo** operations, which are physical in that the affected page is physically identified,but can be logical within the page.\n",
    "3. Uses a **dirty page table** to minimize unnecessary redos during recovery.\n",
    "    - **Dirty pages** are those that have been updated inmemory, and the disk version is not up-to-date.\n",
    "4. Uses a fuzzy-checkpointing scheme that records only information about dirty pages and associated information and does not even require writing of dirty pages to disk. It flushes dirty pages in the background, continuously, instead of writing them during checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "\n",
    ">Mohan, C., et al. \"ARIES: a transaction recovery method supporting fine-granularity locking and partial rollbacks using write-ahead logging.\" ACM Transactions on Database Systems (TODS) 17.1 (1992): 94-162."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 20: Data Warehousing and Mining <a name=\"chapter20\"></a>([TOC](#toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1 Decision-Support Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Decision-support systems** analyze online data collected by transaction-processing systems, to help people make business decisions.\n",
    "    - *Data Analysis*\n",
    "    - *Statistical Analysis*\n",
    "    - *Data Warehouses*\n",
    "    - *Data Mining*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2 Data Warehousing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **data warehouse** is a repository (or archive) of information gathered from multiple sources, stored under a unified schema, at a single site.\n",
    "    - *Advantage*:\n",
    "        1. Simple Consolidated Interface\n",
    "        2. Access to Historical Data\n",
    "        3. OLTP Not Affected by Analytics\n",
    "- **ETL**: Extract, Transform, Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components of a Data Warehouse\n",
    "\n",
    "![Data-Warehouse Architecture](images/Figure_20_1.png)\n",
    "\n",
    "1. *When and How to Gather Data*:\n",
    "    - **Source-Driven Architecture**: Data sources transmit new information, either continually or periodically.\n",
    "    - **Destination-Driven Architecture**: Data warehouse periodically sends requests for new data to the sources.\n",
    "    - *Observation*: Data Warehouses = Slightly Out-of-Date Data\n",
    "2. *What Schema to Use*:\n",
    "    - **Schema Integration**: Convert data to the integrated schema before storage.\n",
    "3. *Data Transformation and Cleansing*:\n",
    "    - **Data Cleansing**: Task of correcting and preprocessing data.\n",
    "    - **Fuzzy Lookup**: Approximate matching of incorrect data.\n",
    "    - **Merge-Purge Operation**: Deduplication\n",
    "    - **Householding**: Grouping\n",
    "4. *How to Propagate Updates*:\n",
    "    - A schema can be a materialized view of schema from various data sources, so the data warehouse is always partially updated.\n",
    "5. *What Data to Summarize*:\n",
    "    - If raw data sets are too large to store online, aggregate values are often sufficient to query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warehouse Schemas\n",
    "\n",
    "![Star Schema](images/Figure_20_2.png)\n",
    "\n",
    "- **Fact Tables**: Tables that contain multidimensional data, with dimension attributes and measure attributes.\n",
    "- **Dimension Tables**: Tables that are referenced by dimension attributes.\n",
    "- **Star Schema**: A fact table with multiple dimension tables and foreign keys from the fact table to the dimension tables.\n",
    "- **Snowflake Schema**: A multi-leveled star schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.3 Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data Mining**: The process of semiautomatically analyzing large databases to find useful patterns.\n",
    "- **Rules**: Represents Knowledge $\\rightarrow$ Predict Outcome\n",
    "- **Prediction**: Based on History\n",
    "    - **Classification**: Given an unknown item, predict to which class it belongs.\n",
    "    - **Regression**: Given a set of mappings for an unknown function, predict the function result for a new parameter value.\n",
    "- **Associations**: Find Similarities $\\rightarrow$ Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.4 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Classification**: Given that items belong to one of several classes, and given past **training instances** of items along with the classes to which they belong, the problem is to predict the class to which a new item belongs.\n",
    "    - Find Rules $\\rightarrow$ Partition Data $\\rightarrow$ Disjoint Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision-Tree\n",
    "\n",
    "![Decision-Tree](images/Figure_20_3.png)\n",
    "\n",
    "- **Decision-Tree**: A tree in which each leaf node has an associated class, and each internal node has a predicate associated with it.\n",
    "- **Overfitting**: A decision-tree is overfitted if it has been so highly tuned to the specifics of the training data that it makes classification errors on other data.\n",
    "\n",
    "##### Classifying\n",
    "\n",
    "1. Start at the root and traverse the tree to reach a leaf.\n",
    "2. At an internal node, evaluate the predicate on the data, to decide which child to traverse.\n",
    "3. Repeat Step 2 until a leaf node is reached.\n",
    "\n",
    "##### Construction\n",
    "\n",
    "![Recursive Construction of Decision Tree](images/Figure_20_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Splits for Decision Trees\n",
    "\n",
    "- *Impure*: When a training set contains instances from many classes.\n",
    "- **Gini Measure**: Suppose there are $k$ classes, and of the instances in training set $S$ the fraction of instances in class $i$ is $p_i$, then the purity of $S$ is defined as the following.\n",
    "$$\\text{Impurity}(S) = \\text{Gini}(S) = 1 - \\sum_{i = 1}^{k} p_i^2$$\n",
    "    - When all instances are in a single class, the Gini value is 0, while it reaches its maximum of $1 - 1/k$ if each class hast the same number of instances.\n",
    "- **Entropy Measure**:\n",
    "$$\\text{Impurity}(S) = \\text{Entropy}(S) = - \\sum_{i = 1}^{k} p_i \\log_{2} p_i$$\n",
    "- **Classification Error**:\n",
    "$$\\text{Impurity}(S) = \\text{Classification Error}(S) = 1 - \\max(p_i)$$\n",
    "\n",
    "##### Best Splits and Information\n",
    "- When a set $S$ is split into multiple sets $S_i$, the impurity of the resultant set of sets is the following.\n",
    "$$\\text{Impurity}(S_1, S_2, ..., S_r) = \\sum_{i = 1}^{r} \\frac{\\lvert S_i \\rvert}{\\lvert S \\rvert} \\text{Impurity}(S_i)$$\n",
    "- **Information Gain**: *Benefit of a Split*\n",
    "$$\\text{InformationGain}(S, \\{S_1, S_2, ..., S_r\\}) = \\text{Impurity}(S) - \\text{Impurity}(S_1, S_2, ..., S_r)$$\n",
    "- **Information Content**: *Cost of a Split*\n",
    "$$\\text{InformationContent}(S, \\{S_1, S_2, ..., S_r\\}) = - \\sum_{i = 1}^{r} \\frac{\\lvert S_i \\rvert}{\\lvert S \\rvert} \\log_{2} \\frac{\\lvert S_i \\rvert}{\\lvert S \\rvert}$$\n",
    "- **Information Gain Ratio**: *Maximize for Best Split*\n",
    "$$\\text{InformationGainRatio} = \\frac{\\text{InformationGain}(S, \\{S_1, S_2, ..., S_r\\})}{\\text{InformationContent}(S, \\{S_1, S_2, ..., S_r\\})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Best Splits\n",
    "\n",
    "##### Continuous Valued Attributes\n",
    "\n",
    "- *Binary Split*:\n",
    "    1. Sort training set.\n",
    "    2. Consider each value as the split point.\n",
    "    3. Choose the best split.\n",
    "- *Multi-Way Split*:\n",
    "    - A series of binary splits on the same attribute has roughly the equivalent effect.\n",
    "\n",
    "##### Categorical Valued Attributes\n",
    "\n",
    "- *Binary Split*:\n",
    "    1. Consider each value as the split point.\n",
    "    2. Choose the best split.\n",
    "- *Multi-Way Split*:\n",
    "    - A child for each value of the attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Types of Classifiers\n",
    "\n",
    "- **Bayesian Classifiers**: Find the distribution of attribute values for each class in the training data.\n",
    "    - When given a new instance $d$, they use the distribution information to estimate, for each class $c_j$, the probability that instance $d$ belongs to class $c_j$, denoted by $p(c_j \\vert d)$.\n",
    "    - The class with the maximum probability becomes the predicted class for instance $d$.\n",
    "$$p(c_j \\vert d) = \\frac{p(d \\vert c_j)p(c_j)}{p(d)}$$\n",
    "- **Naive Bayesian Classifiers**: Assume attributes have independent distributions.\n",
    "$$p(d \\vert c_j) = p(d_1 \\vert c_j) * p(d_2 \\vert c_j) * ... * p(d_n \\vert c_j)$$\n",
    "    - $p(d_i \\vert c_j)$ can be estimated from a histogram on $d_i$ values for each class $c_j$ computed from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "\n",
    "- **Regression**: Predict Values\n",
    "$$Y = a_0 + a_1 * X_1 + a_2 * X_2 + ... + a_n * X_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5 Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Antecedent} \\implies \\text{Consequent}$$\n",
    "\n",
    "- An association rule must have an associated **population**; the population consists of a set of **instances**.\n",
    "    - *Example*: $bread \\implies milk$\n",
    "        - People who buy bread tend to buy milk.\n",
    "- **Support**: A measure of what fraction of the population satisfies both the antecedent and the consequent of the rule.\n",
    "- **Confidence**: A measure of how often the consequent is true when the antecedent is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discovering Association Rules\n",
    "\n",
    "$$i_1, i_2, ..., i_n \\implies i_0$$\n",
    "\n",
    "1. Find the set of items with sufficient support, called **large itemsets** ($\\ge 2\\%$).\n",
    "2. For each large itemset $S$, output a rule $S - s \\implies s$ for every subset $s \\subset S$, provided $S - s \\implies s$ has sufficient confidence.\n",
    "    - $\\text{Confidence} = \\frac{\\text{Support}(S)}{\\text{Support}(S - s)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discovering Large Itemsets\n",
    "\n",
    "- *Sufficient Memory*: Single Pass\n",
    "- *Insufficient Memory*: Multiple Passes\n",
    "- *Optimization*: Once an itemset is eliminated because its support is too low, none of its supersets needs to be considered.\n",
    "\n",
    "##### A Priori Technique\n",
    "\n",
    "1. *Pass 1*: Calculate the support of all sets with just 1 item. Eliminate the sets with low support.\n",
    "2. *Pass $i$*: For every set of $i$ items, check that all their $i - 1$ subsets are large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.6 Other Types of Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Correlations** look for **deviations** from expected levels of association."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.7 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Clustering**: *Group Similar Points $\\rightarrow$ Single Set*\n",
    "- **Hierarchical Clustering**:\n",
    "    - **Agglomerative Clustering**: *Bottom-Up with Small Clusters*\n",
    "    - **Divisive Clustering**: *Top-Down with Large Clusters*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SQL",
   "language": "SQL",
   "name": "sql"
  },
  "language_info": {
   "codemirror_mode": "sql",
   "file_extension": ".sql",
   "mimetype": "",
   "name": "SQL",
   "nbconverter_exporter": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
