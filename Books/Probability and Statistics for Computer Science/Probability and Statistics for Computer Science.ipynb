{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Statistics for Computer Science\n",
    "\n",
    "*Authors: David Forsyth*\n",
    "\n",
    "**ISBN: 978-3-319-64410-3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\{x\\}$ - **Dataset**\n",
    "- $x_i$ -***i*th Data Item**\n",
    "- $x_i^{(j)}$ - ***j*th Component of *i*th Data Item**\n",
    "- $\\text{mean}(\\{x\\})$ - **Mean**\n",
    "- $\\text{std}(\\{x\\})$ - **Standard Deviation**\n",
    "- $\\text{var}(\\{x\\})$ - **Variance**\n",
    "- $\\text{median}(\\{x\\})$ - **Median**\n",
    "- $\\text{percentile}(\\{x\\}, k)$ - **$k\\%$ Percentile**\n",
    "- $\\text{iqr}(\\{x\\})$ - **Interquartile Range**\n",
    "- $\\{\\hat{x}\\}$ - **Dataset Transformed to Standard Coordinates**\n",
    "- $\\text{corr}(\\{(x, y)\\})$ - **Correlation**\n",
    "- $\\emptyset$ - **Empty Set**\n",
    "- $\\Omega$ - **Set of All Possible Experiment Outcomes**\n",
    "- $\\mathcal{A}$ - **Set**\n",
    "- $\\mathcal{A}^c = \\Omega - \\mathcal{A}$ - **Set Complement**\n",
    "- $\\mathcal{E}$ - **Event**\n",
    "- $P(\\mathcal{E})$ - **Probability of Event $\\mathcal{E}$**\n",
    "- $P(\\mathcal{E} \\vert \\mathcal{F})$ - **Probability of Event $\\mathcal{E}$, Conditioned on Event $\\mathcal{F}$**\n",
    "- $p(x)$ - **Probability That Random Variable $X$ Equals Value $x$**\n",
    "- $p(x, y)$ - **Probability That Random Variable $X$ Equals Value $x$ And Random Variable $Y$ Equals Value $y$**\n",
    "- $\\max_{x} f(x)$ - **Value of $x$ That Maximizes $f(x)$**\n",
    "- $\\min_{x} f(x)$ - **Value of $x$ That Minimizes $f(x)$**\n",
    "- $\\hat{\\theta}$ - **Estimated Value of $\\theta$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First Tools for Looking at Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "- **Dataset**: A collection of descriptions (or $d$-tuples) of different instances of the same phenomenon.\n",
    "    - *Categorical*\n",
    "    - *Continuous*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing 1D Data\n",
    "\n",
    "- A **location parameter** tells where the data lies along a number line.\n",
    "- A **scale parameter** tells how wide the spread of data is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean\n",
    "\n",
    "- Assume we have a dataset $\\{x\\}$ of $N$ data items, $x_1, ..., x_N$. The mean of this dataset is:\n",
    "$$\\text{mean}(\\{x\\}) = \\frac{1}{N} \\sum_{i = 1}^{N} x_i$$\n",
    "\n",
    "#### Properties of Mean\n",
    "\n",
    "- **Scaling**: $\\text{mean}(\\{k \\cdot x_i\\}) = k \\cdot \\text{mean}(\\{x_i\\})$\n",
    "    - *Yes Effect*\n",
    "- **Translation**: $\\text{mean}(\\{x_i + c\\}) = \\text{mean}(\\{x_i\\}) + c$\n",
    "    - *Yes Effect*\n",
    "- **Sum of Signed Differences**: $\\sum_{i = 1}^{N} \\left( x_i - \\text{mean}(\\{x_i\\}) \\right) = 0$\n",
    "- **Sum of Squared Distances to $\\mu$**: $\\min_{\\mu} \\sum_{i} \\left( x_i - \\mu \\right)^2 = \\text{mean}(\\{x_i\\})$\n",
    "    - *Mean*: $\\mu$\n",
    "\n",
    "#### Interpretation of Mean\n",
    "\n",
    "- The mean is a *location parameter* that summarizes the dataset with a value that is as close as possible to each datum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation\n",
    "\n",
    "- Assume we have a dataset $\\{x\\}$ of $N$ data items, $x_1, ..., x_N$. The standard deviation of this dataset is:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{std}(\\{x\\}) \n",
    "& = \\sqrt{\\frac{1}{N} \\sum_{i = 1}^{N} \\left(x_i - \\text{mean}(\\{x\\}) \\right)^2} \\\\\n",
    "& = \\sqrt{\\text{mean}\\left( \\{ \\left( x_i - \\text{mean}(\\{x\\}) \\right)^2 \\} \\right)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Properties of Standard Deviation\n",
    "\n",
    "- **Scaling**: $\\text{std}(\\{k \\cdot x_i\\}) = k \\cdot \\text{std}(\\{x_i\\})$\n",
    "    - *Yes Effect*\n",
    "- **Translation**: $\\text{std}(\\{x_i + c\\}) = \\text{std}(\\{x_i\\})$\n",
    "    - *No Effect*\n",
    "- For any dataset, there can be only a few items that are many standard deviations away from the mean. For $N$ data items, $x_i$, whose standard deviation is $\\sigma$, there are at most $\\frac{1}{k^2}$ data points lying $k$ or more standard deviations away from the mean.\n",
    "- For any dataset, there must be at least one data item that is at least one standard deviation away from the mean.\n",
    "\n",
    "#### Interpretation of Standard Deviation\n",
    "\n",
    "- The standard deviation is the root mean square of the offsets from the mean.\n",
    "- The standard deviation is a *scale parameter* that measures the size of the average deviation from the mean for a dataset.\n",
    "- When the standard deviation is large, there are many items with values much larger than, or much smaller than, the mean.\n",
    "- When the standard deviation is small, most data items have values close to the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "\n",
    "- Assume we have a dataset $\\{x\\}$ of $N$ data items, $x_1, ..., x_N$. The variance of this dataset is:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{var}(\\{x\\}) \n",
    "& = \\frac{1}{N} \\sum_{i = 1}^{N} \\left( x_i - \\text{mean}(\\{x\\}) \\right)^2 \\\\\n",
    "& = \\text{mean}\\left( \\{ \\left( x_i - \\text{mean}(\\{x\\}) \\right)^2 \\} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Properties of Variance\n",
    "\n",
    "- **Scaling**: $\\text{var}(\\{k \\cdot x_i\\}) = k^2 \\cdot \\text{var}(\\{x_i\\})$\n",
    "    - *Yes Effect*\n",
    "- **Translation**: $\\text{var}(\\{x_i + c\\}) = \\text{var}(\\{x_i\\})$\n",
    "    - *No Effect*\n",
    "    \n",
    "#### Interpretation of Variance\n",
    "\n",
    "- Variance is the mean-square error you would incur if you replaced each data item with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median\n",
    "\n",
    "- Assume we have a dataset $\\{x\\}$ of $N$ data items, $x_1, ..., x_N$.\n",
    "    - If $N$ is odd, the median of this dataset is:\n",
    "$$\\text{median}(\\{x\\}) = \\text{sort}(\\{x\\})\\left[ \\frac{N}{2} \\right]$$\n",
    "    - If $N$ is even, the median of this dataset is:\n",
    "$$\\text{median}(\\{x\\}) = \\frac{1}{2} \\left( \\text{sort}(\\{x\\})\\left\\lceil \\frac{N}{2} \\right\\rceil + \\text{sort}(\\{x\\})\\left\\lfloor \\frac{N}{2} \\right\\rfloor \\right)$$\n",
    "\n",
    "#### Properties of Median\n",
    "\n",
    "- **Scaling**: $\\text{median}(\\{k \\cdot x_i\\}) = k \\cdot \\text{median}(\\{x_i\\})$\n",
    "    - *Yes Effect*\n",
    "- **Translation**: $\\text{median}(\\{x_i + c\\}) = \\text{median}(\\{x_i\\}) + c$\n",
    "    - *Yes Effect*\n",
    "\n",
    "#### Interpretation of Median\n",
    "\n",
    "- Generally, approximately half the data is smaller than the median, and approximately half the data is larger than the median.\n",
    "- The median is an alternative to the mean because it is also a *location parameter*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interquartile Range\n",
    "\n",
    "- **Percentile**: The $k$'th percentile is the value such hat $k\\%$ of the data is less than or equal to that value.\n",
    "    - $\\text{percentile}(\\{x\\}, k)$\n",
    "- **Quartile**:\n",
    "    - The first quartile is the value such that $25\\%$ of the data is less than or equal to that value: $\\text{percentile}(\\{x\\}, 25)$.\n",
    "    - The second quartile is the value such that $50\\%$ of the data is less than or equal to that value: $\\text{percentile}(\\{x\\}, 50)$.\n",
    "    - The third quartile is the value such that $75\\%$ of the data is less than or equal to that value: $\\text{percentile}(\\{x\\}, 75)$.\n",
    "- **Interquartile Range**: The interquartile range of a dataset $\\{x\\}$ is:\n",
    "$$\\text{iqr}(\\{x\\}) = \\text{percentile}(\\{x\\}, 75) - \\text{percentile}(\\{x\\}, 25)$$\n",
    "\n",
    "#### Properties of Interquartile Range\n",
    "\n",
    "- **Scaling**: $\\text{iqr}(\\{k \\cdot x_i\\}) = k \\cdot \\text{iqr}(\\{x_i\\})$\n",
    "    - *Yes Effect*\n",
    "- **Translation**: $\\text{iqr}(\\{x_i + c\\}) = \\text{iqr}(\\{x_i\\})$\n",
    "    - *No Effect*\n",
    "    \n",
    "#### Interpretation of Interquartile Range\n",
    "\n",
    "- The interquartile range is an alternative to the standard deviation because it is also a *scale parameter*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Algorithms for Mean and Standard Deviation\n",
    "\n",
    "#### Mean\n",
    "\n",
    "- Let $\\hat{\\mu}_{k}$ be an estimate for the mean of the dataset after seeing $k$ elements.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\mu}_{1} &= x_1 \\\\\n",
    "\\hat{\\mu}_{k + 1} &= \\frac{k \\cdot \\hat{\\mu}_{k} + x_{k + 1}}{k + 1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Standard Deviation\n",
    "\n",
    "- Let $\\hat{\\sigma}_{k}$ be an estimate for the standard deviation of the dataset after seeing $k$ elements.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\sigma}_{1} &= 0 \\\\\n",
    "\\hat{\\sigma}_{k + 1} &= \\sqrt{\\frac{(k \\cdot \\hat{\\sigma}_{k}^2) + (x_{k + 1} - \\hat{\\mu}_{k + 1})^2}{k + 1}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean vs. Median and Standard Deviation vs. Interquartile Range\n",
    "\n",
    "#### Mean and Standard Deviation\n",
    "\n",
    "- The mean and the standard deviation are strongly affected by **outliers**.\n",
    "- The mean and the standard deviation are inexpensive to exactly calculate.\n",
    "- Generally, The mean and the standard deviation are sensible for continuous data.\n",
    "\n",
    "#### Median and Interquartile Range\n",
    "\n",
    "- The median and the interquartile range are weakly affected by **outliers**.\n",
    "- The median and the interquartile range are expensive to exactly calculate.\n",
    "- Generally, The median and the interquartile range are sensible for categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "- **Bar Chart**: A set of bars, one per category, where the height of each bar is proportional to the number of items in that category.\n",
    "- **Histogram**: A generalization of a bar chart for continuous-valued data.\n",
    "    1. Divide the range of data into even or uneven intervals.\n",
    "    2. Associate each interval with a pigeonhole.\n",
    "    3. Associate each datum with a pigeonhole.\n",
    "    4. Visualize the histogram as a set of boxes, one per interval, in which each box sits on its interval on the horizontal axis, and its height is determined by the amount of data in the corresponding pigeonhole.\n",
    "- **Conditional Histogram**: A histogram that only plots part of a data set.\n",
    "\n",
    "#### Modes and Histograms\n",
    "\n",
    "- A histogram is **unimodal** if there is only one peak.\n",
    "- A histogram is **bimodal** if there is only two peaks.\n",
    "- A histogram is **multimodal** if there are many peaks.\n",
    "\n",
    "![Modes of Histogram](images/Figure_1_4.png)\n",
    "\n",
    "#### Skew and Histograms\n",
    "\n",
    "- The **tails** of a histogram are the relative uncommon values that are significantly larger or smaller than the value at the peak.\n",
    "- If the histogram is not symmetric, then the histogram is **skewed**.\n",
    "\n",
    "![Skew of Histogram](images/Figure_1_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Coordinates and Normal Data\n",
    "\n",
    "- Assume we have a dataset $\\{x\\}$ of $N$ data items, $x_1, ..., x_N$, The standard coordinates of this dataset is:\n",
    "$$\\hat{x}_i = \\frac{x_i - \\text{mean}(\\{x\\})}{\\text{std}(\\{x\\})}$$\n",
    "- Data is **standard normal data** if, when we have a lot of data, the histogram of the data in standard coordinates is a close approximation to the **standard normal curve**:\n",
    "$$y(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-x^2 / 2}$$\n",
    "- Data is **normal data** if, when we subtract the mean and divide by the standard deviation, it becomes the standard normal data.\n",
    "\n",
    "#### Interpretation of Standard Coordinates\n",
    "\n",
    "- A dataset expressed in standard coordinates is unitless with a mean of $0$ and a standard deviation of $1$.\n",
    "    - This allows different datasets to be compared if they are expressed in standard coordinates.\n",
    "- Many datasets expressed in standard coordinates are symmetric and unimodal, so they tend to be normal data.\n",
    "    \n",
    "#### Standard Normal Curve\n",
    "\n",
    "![Standard Normal Curve](images/Figure_1_7.png)\n",
    "\n",
    "#### Properties of Normal Data\n",
    "\n",
    "- Approximately 68% of data lie within one standard deviations of the mean.\n",
    "- Approximately 95% of data lie within two standard deviations of the mean.\n",
    "- Approximately 99% of data lie within three standard deviations of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots\n",
    "\n",
    "- A **box plot** is a way to plot data that simplifies comparison.\n",
    "    - Dataset = Vertical Display.\n",
    "    - Vertical Box = Interquartile Range.\n",
    "    - Horizontal Line = Median.\n",
    "    - Whiskers = Range of Non-Outlier Data.\n",
    "    - Crosses = Outliers.\n",
    "    \n",
    "![Box Plot](images/Figure_1_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Looking at Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting 2D Data\n",
    "\n",
    "- Pie Chart\n",
    "- Heat Map\n",
    "- Stacked Bar Chart\n",
    "- 3D Bar Chart\n",
    "- Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots\n",
    "\n",
    "- **Scatter Plots**: A most effective tool for geographic and 2D data in general.\n",
    "    - A scatter plot should be your first step with a new 2D dataset.\n",
    "    - The plot scale can mask effects in scatter plots, and it's usually a good idea to plot in standard coordinates.\n",
    "    - Any $d$-dimensional vector can be projected into 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "- **Correlation**: Relationship\n",
    "    - *Positive*: When larger $\\hat{x}$ values tend to appear with larger $\\hat{y}$ values, and vice versa.\n",
    "    - *Negative*: When larger $\\hat{x}$ values tend to appear with smaller $\\hat{y}$ values, and vice versa.\n",
    "    - *Zero*: When there is no relationship between $\\hat{x}$ values and $\\hat{y}$ values.\n",
    "        - *Mean in Standard Coordinates*: $\\text{mean}(\\{\\hat{x}\\}) = 0$ and $\\text{mean}(\\{\\hat{y}\\}) = 0$\n",
    "        - *Variance in Standard Coordinates*: $\\text{var}(\\{\\hat{x}\\}) = 1$ and $\\text{var}(\\{\\hat{y}\\}) = 1$\n",
    "\n",
    "![Correlations](images/Figure_2_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficient\n",
    "\n",
    "- Assume we have $N$ data items which are $2$-vectors $(x_1, y_1), ..., (x_N, y_N)$. The correlation coefficient is the mean value of $\\hat{x} \\hat{y}$:\n",
    "$$\\text{corr}(\\{(x, y)\\}) = \\frac{\\sum_{i} \\hat{x}_i \\hat{y}_i}{N}$$\n",
    "    - Where $\\hat{x}_i$ and $\\hat{y}_i$ are in standard coordinates.\n",
    "    \n",
    "#### Properties of Correlation Coefficient\n",
    "\n",
    "- **Symmetric**: $\\text{corr}(\\{(x, y)\\}) = \\text{corr}(\\{(y, x)\\})$\n",
    "- **Scaling and Translation**: $\\text{corr}(\\{(ax + b, cy + d)\\}) = \\text{sign}(ab)\\text{corr}(\\{(x, y)\\})$\n",
    "    - *Scaling*: Changes Sign.\n",
    "    - *Translation*: No Effect.\n",
    "- **Maximum Value**: $1$ when $\\hat{x} = \\hat{y}$.\n",
    "- **Minimum Value**: $-1$ when $\\hat{x} = -\\hat{y}$.\n",
    "- If $\\hat{y}$ tends to be large for large values of $\\hat{x}$, then the correlation coefficient will be positive, and vice versa.\n",
    "- If $\\hat{y}$ tends to be small for large values of $\\hat{x}$, then the correlation coefficient will be negative, and vice versa.\n",
    "- If $\\hat{y}$ does not depend on $\\hat{x}$, then the correlation coefficient is close to zero.\n",
    "\n",
    "#### Interpretation of Correlation Coefficient\n",
    "\n",
    "- The correlation coefficient is a measure of the ability to predict a $x$ given a $y$ and vice versa.\n",
    "- The correlation coefficient ranges from $-1$ to $1$.\n",
    "- *Large Correlation Coefficient ($1.0$)*: Strong Predictions.\n",
    "- *Small Correlation Coefficient ($<0.5$)*: Weak Predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a Value Using Correlation\n",
    "\n",
    "- Assume we have $N$ data items which are $2$-vectors $(x_1, y_1), ..., (x_N, y_N)$.\n",
    "\n",
    "#### Predicting $y_0$ Given $x_0$\n",
    "\n",
    "1. Transform the dataset into standard coordinates: $\\hat{x}_i$, $\\hat{y}_i$, and $\\hat{x}_0$.\n",
    "2. Compute the correlation coefficient: $r = \\text{corr}(\\{(x, y)\\}) = \\text{mean}(\\{\\hat{x} \\hat{y}\\})$\n",
    "3. Predict $\\hat{y}_0 = r \\cdot \\hat{x}_0$.\n",
    "4. Transform this prediction into the original coordinate system: $y_0 = \\text{std}(\\{y\\}) \\cdot r \\cdot \\hat{x}_0 + \\text{mean}(\\{y\\})$\n",
    "\n",
    "#### Predicting $x_0$ Given $y_0$\n",
    "\n",
    "1. Transform the dataset into standard coordinates: $\\hat{x}_i$, $\\hat{y}_i$, and $\\hat{y}_0$.\n",
    "2. Compute the correlation coefficient: $r = \\text{corr}(\\{(x, y)\\}) = \\text{mean}(\\{\\hat{x} \\hat{y}\\})$\n",
    "3. Predict $\\hat{x}_0 = r \\cdot \\hat{y}_0$.\n",
    "4. Transform this prediction into the original coordinate system: $x_0 = \\text{std}(\\{x\\}) \\cdot r \\cdot \\hat{y}_0 + \\text{mean}(\\{x\\})$\n",
    "\n",
    "#### Notes on Predictions with Correlation\n",
    "\n",
    "- **Root Mean Square Error**: $\\sqrt{1 - r^2}$.\n",
    "- If $x_0$ is $k$ standard deviations from the mean of $x$, then the predicted value of $y$ will be $rk$ standard deviations away from the mean of $y$, and the sign of $r$ tells whether $y$ increases or decreases.\n",
    "- The predicted value of $y$ increases by $r$ standard deviations when the value of $x$ increases by one standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Ideas in Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting\n",
    "\n",
    "#### Product Rule\n",
    "\n",
    "- Suppose that a procedure can be broken down into a sequence of two tasks.\n",
    "- If there are $n_1$ ways to do the first task and for each of these ways of doing the first task, there are $n_2$ ways to do the second task, then there are $n_1 \\cdot n_2$ ways to do the procedure.\n",
    "\n",
    "#### Sum Rule\n",
    "\n",
    "- If a task can be done in either one of $n_1$ ways or in one of $n_2$ ways such that the set of $n_1$ ways and the set of $n_2$ ways are disjoint, then there are $n_1 + n_2$ ways to do the task.\n",
    "\n",
    "#### Permutations (Ordering)\n",
    "\n",
    "- **Elements without Repetition**: $\\text{permutation}(n, r) = \\frac{n!}{(n - r)!}$\n",
    "- **Elements with Repetition**: $\\text{permutation}(n, r) = n^r$\n",
    "\n",
    "#### Combinations (No Ordering)\n",
    "\n",
    "- $\\text{combinations}(n, r) = \\frac{n!}{r! (n - r)!}$\n",
    "- $\\text{combinations}(n, r) = \\text{combinations}(n, n - r)$\n",
    "- $\\text{combinations}(n, r) = \\text{combinations}(n - 1, r - 1) + \\text{combinations}(n - 1, r)$\n",
    "\n",
    "#### Binomial Theorem\n",
    "\n",
    "- $(x + y)^n = \\sum_{i = 0}^{n} \\text{combinations}(n, i) \\cdot x^{n - i} \\cdot y^i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcomes\n",
    "\n",
    "- **Outcome**: The result from a run of an experiment.\n",
    "- **Sample Space**: The set of all outcomes, denoted by $\\Omega$.\n",
    "- Sample spaces are required, and need not be finite.\n",
    "- The probability of an outcome is the frequency of that outcome in a very large number of repeated experiments. The sum of probabilities over all outcomes must be one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events and Probability\n",
    "\n",
    "- **Event**: A set of outcomes, denoted by $\\mathcal{E}$.\n",
    "$$P(\\mathcal{E}) = \\frac{\\lvert \\mathcal{E} \\rvert}{\\lvert \\Omega \\rvert}$$\n",
    "\n",
    "#### Properties of Events\n",
    "\n",
    "- **Union**: $\\mathcal{E} \\cup \\mathcal{F}$\n",
    "- **Intersection**: $\\mathcal{E} \\cap \\mathcal{F}$\n",
    "- **Compliment**: $\\mathcal{E}^c$\n",
    "- **Subset**: $\\mathcal{E} \\subset \\mathcal{F}$\n",
    "- **Commutative**: $\\mathcal{E} \\cup \\mathcal{F} = \\mathcal{F} \\cup \\mathcal{E}$ and $\\mathcal{E} \\cap \\mathcal{F} = \\mathcal{F} \\cap \\mathcal{E}$\n",
    "- **Associative**: $(\\mathcal{E} \\cup \\mathcal{F}) \\cup \\mathcal{G} = \\mathcal{E} \\cup (\\mathcal{F} \\cup \\mathcal{G})$ and $(\\mathcal{E} \\cap \\mathcal{F}) \\cap \\mathcal{G} = \\mathcal{E} \\cap (\\mathcal{F} \\cap \\mathcal{G})$\n",
    "- **Distributive**: $(\\mathcal{E} \\cup \\mathcal{F}) \\cap \\mathcal{G} = (\\mathcal{E} \\cap \\mathcal{G}) \\cup (\\mathcal{F} \\cap \\mathcal{G})$ and $(\\mathcal{E} \\cap \\mathcal{F}) \\cup \\mathcal{G} = (\\mathcal{E} \\cup \\mathcal{G}) \\cap (\\mathcal{F} \\cup \\mathcal{G})$\n",
    "- **De Morgan's Laws**: $(\\cup_{i = 1}^{n} \\mathcal{E}_i)^c = \\cap_{i = 1}^{n} E_i^c$ and $(\\cap_{i = 1}^{n} \\mathcal{E}_i)^c = \\cup_{i = 1}^{n} E_i^c$\n",
    "\n",
    "#### Properties of the Probability of Events\n",
    "\n",
    "- The probability of every event is between zero and one: $0 \\le P(\\mathcal{A}) \\le 1$\n",
    "- Every experiment has an outcome: $P(\\Omega) = 1$\n",
    "- The probability of disjoint events is additive: $P(\\cup_{i} \\mathcal{A}_i) = \\sum_{i} P(\\mathcal{A}_i)$\n",
    "- **Complement**: $P(\\mathcal{A}^c) = 1 - P(\\mathcal{A})$\n",
    "- **Empty Set**: $P(\\emptyset) = 0$\n",
    "- **Set Difference**: $P(\\mathcal{A} - \\mathcal{B}) = P(\\mathcal{A}) - P(\\mathcal{A} \\cap \\mathcal{B})$\n",
    "- **Set Union**: $P(\\mathcal{A} \\cup \\mathcal{B}) = P(\\mathcal{A}) + P(\\mathcal{B}) - P(\\mathcal{A} \\cap \\mathcal{B})$\n",
    "- **Generic Union**: $P(\\cup_{i} \\mathcal{A}_i) = \\sum_{i} P(\\mathcal{A}_i) - \\sum_{i < j} P(\\mathcal{A}_i \\cap \\mathcal{A}_j) + \\sum_{i < j < k} P(\\mathcal{A}_i \\cap \\mathcal{A}_j \\cap \\mathcal{A}_k) + ... (-1)^{n + 1} P(\\mathcal{A}_1 \\cap \\mathcal{A}_2 \\cap ... \\cap \\mathcal{A}_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability\n",
    "\n",
    "- Assume we have a space of outcomes and a collection of events. The conditional probability of $\\mathcal{B}$, conditioned on $\\mathcal{A}$, is the probability that $\\mathcal{B}$ occurs given that $\\mathcal{A}$ has definitely occured.\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\mathcal{B} \\vert \\mathcal{A}) \n",
    "&= \\frac{P(\\mathcal{B} \\cap \\mathcal{A})}{P(\\mathcal{A})} \\\\\n",
    "&= \\frac{P(\\mathcal{A} \\vert \\mathcal{B}) \\cdot P(\\mathcal{B})}{P(\\mathcal{A})}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Conditional Probability Formulas\n",
    "\n",
    "- $P(\\mathcal{A}) = P(\\mathcal{A} \\cap \\mathcal{B}) + P(\\mathcal{A} \\cap \\mathcal{B}^c)$\n",
    "- $P(\\mathcal{A}) = P(\\mathcal{A} \\vert \\mathcal{B}) \\cdot P(\\mathcal{B}) + P(\\mathcal{A} \\vert \\mathcal{B}^c) \\cdot P(\\mathcal{B}^c)$\n",
    "- If $\\mathcal{B}_1, \\mathcal{B}_2, ..., \\mathcal{B}_n$ are mutually exclusive events and $\\mathcal{A} = \\cup_{i = 1}^{n} (\\mathcal{A} \\cap \\mathcal{B}_i)$,\n",
    "    - $P(\\mathcal{A}) = \\sum_{i = 1}^{n} P(\\mathcal{A} \\vert \\mathcal{B}_i) \\cdot P(\\mathcal{B}_i)$\n",
    "    - $P(\\mathcal{B}_i \\vert \\mathcal{A}) = \\frac{P(\\mathcal{A} \\vert \\mathcal{B}_i) \\cdot P(\\mathcal{B}_i)}{\\sum_{i = 1}^{n} P(\\mathcal{A} \\vert \\mathcal{B}_i) \\cdot P(\\mathcal{B}_i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independence\n",
    "\n",
    "- Two events $\\mathcal{A}$ and $\\mathcal{B}$ are independent if and only if\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\mathcal{A} \\cap \\mathcal{B}) &= P(\\mathcal{A})P(\\mathcal{B}) \\\\\n",
    "P(\\mathcal{A} \\vert \\mathcal{B}) &= P(\\mathcal{A}) \\\\\n",
    "P(\\mathcal{B} \\vert \\mathcal{A}) &= P(\\mathcal{B})\n",
    "\\end{align}\n",
    "$$\n",
    "- Generally, the probability of a sequence of independent events can become very small, very quickly.\n",
    "- Therefore, modelling events that are not independent as independent can be a mistake.\n",
    "\n",
    "#### Pairwise Independence\n",
    "\n",
    "- Events $\\mathcal{A}_1, ..., \\mathcal{A}_n$ are pairwise independent if each pair is independent.\n",
    "\n",
    "#### Conditional Independence\n",
    "\n",
    "- Events $\\mathcal{A}_1, ..., \\mathcal{A}_n$ are conditionally independent conditioned on event $\\mathcal{B}$ if\n",
    "$$P(\\mathcal{A}_1 \\cap ... \\cap \\mathcal{A}_n \\vert \\mathcal{B}) = P(\\mathcal{A}_1 \\vert \\mathcal{B}) ... P(\\mathcal{A}_n \\vert \\mathcal{B})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallacies\n",
    "\n",
    "#### Gambler's Fallacy\n",
    "\n",
    "- When you reason that the probability of an independent event has been changed by previous outcomes.\n",
    "    - e.g., If a fair coin is tossed $25$ times, and the $25$ outcomes are heads, the probability that the next toss will result in a head has not changed at all.\n",
    "    \n",
    "#### Prosecutor's Fallacy\n",
    "\n",
    "1. A prosecutor has evidence $\\mathcal{E}$ against a suspect.\n",
    "2. Let $\\mathcal{I}$ be the event that the suspect is innocent.\n",
    "3. When $P(\\mathcal{E} \\vert \\mathcal{I})$ is small, the prosecutor argues, incorrectly, that the suspect must be guilty, because $P(\\mathcal{E} \\vert \\mathcal{I})$ is so small.\n",
    "\n",
    "\n",
    "- The argument is incorrect because $P(\\mathcal{E} \\vert \\mathcal{I})$ is irrelevant to the issue; instead, $P(\\mathcal{I} \\vert \\mathcal{E})$ is relevant.\n",
    "- *Note*: $P(\\mathcal{I} \\vert \\mathcal{E})$ can be large even if $P(\\mathcal{E} \\vert \\mathcal{I})$ is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Variables and Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Variables\n",
    "\n",
    "- Given a sample space $\\Omega$, a set of events $\\mathcal{F}$, a probability function $P$, and a countable set of real numbers $D$, a discrete random variable is a function with domain $\\Omega$ and range $D$.\n",
    "- A function whose argument is a discrete random variable to a set of numbers is also a discrete random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Distribution of a Discrete Random Variable\n",
    "\n",
    "- The probability distribution (or **probability mass function**) of a discrete random variable is the set of numbers $P(\\{X = x\\})$ for each value $x$ that $X$ can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Distribution of a Discrete Random Variable\n",
    "\n",
    "- The cumulative distribution (or **probability cumulative distribution function**) of a discrete random variable is the set of numbers $P(\\{X \\le x\\})$ for each value $x$ that $X$ can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint and Conditional Probability for Random Variables\n",
    "\n",
    "- Assume we have two random variables $X$ and $Y$. The probability that $X$ takes the value $x$ and $Y$ takes the value $y$,the **joint probability distribution** is $P(x, y) = P(\\{X = x\\} \\cap \\{Y = y\\})$.\n",
    "    - *i.e., Table of Probabilities per $x$ and $y$ Pairs*\n",
    "\n",
    "#### Bayes' Rule\n",
    "\n",
    "$$P(x \\vert y) = \\frac{P(y \\vert x) \\cdot P(x)}{P(y)}$$\n",
    "\n",
    "#### Marginal Probability of a Random Variable\n",
    "\n",
    "$$P(x) = \\sum_{y} P(x, y) = \\sum_{y} P(\\{X = x\\} \\cap \\{Y = y\\}) = P(\\{X = x\\})$$\n",
    "\n",
    "#### Independent Random Variables\n",
    "\n",
    "- The random variables $X$ and $Y$ are independent if the events $\\{X = x\\}$ and $\\{Y = y\\}$ are independent for all values $x$ and $y$.\n",
    "$$P(x, y) = P(x)P(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Probability\n",
    "\n",
    "- A continuous random variable has a **probability density function**: $p(x)$.\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\{X \\in [a, b]\\}) &= \\int_{a}^{b} p(x) dx \\\\\n",
    "P(\\{X \\in [-\\infty, +\\infty]\\}) &= \\int_{-\\infty}^{+\\infty} p(x) dx = 1\n",
    "\\end{align}\n",
    "$$\n",
    "- If $g(x)$ is a non-negative function that is proportional to the probability density function $p(x)$, $p(x)$ can be recovered by **normalization**:\n",
    "$$p(x) = \\frac{1}{\\int_{-\\infty}^{+\\infty} g(x) dx} g(x)$$\n",
    "\n",
    "#### Interpretation of Continuous Probability\n",
    "\n",
    "- A probability density function can be interpreted as the limites of a histogram whose intervals are arbitrarily narrow and whose area is one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Values\n",
    "\n",
    "#### Discrete Expected Value\n",
    "\n",
    "- Given a discrete random variable $X$ which takes values in the set $\\mathcal{D}$ and which has probability distribution $P$, the expected value is:\n",
    "$$\\mathbb{E}[X] = \\sum_{x \\in \\mathcal{D}} x \\cdot P(X = x)$$\n",
    "\n",
    "#### Discrete Expectation\n",
    "\n",
    "- Assume we have a function $f$ that maps a discrete random variable $X$ into a set of numbers $\\mathcal{D}_f$. Then $F = f(X)$ is a discrete random variable. The expected value of $F$ is:\n",
    "$$\\mathbb{E}[f] = \\sum_{u \\in \\mathcal{D}_f} u \\cdot P(F = u) = \\sum_{x \\in \\mathcal{D}} f(x) \\cdot P(X = x)$$\n",
    "\n",
    "#### Continuous Expected Value\n",
    "\n",
    "- Given a continuous random variable $X$ which takes values in the set $\\mathcal{D}$ and which has probability distribution $P$, the expected value is:\n",
    "$$\\mathbb{E}[X] = \\int_{x \\in \\mathcal{D}} x \\cdot p(x) dx$$\n",
    "\n",
    "#### Continuous Expectation\n",
    "\n",
    "- Assume we have a function $f$ that maps a continuous random variable $X$ into a set of numbers $\\mathcal{D}_f$. Then $F = f(X)$ is a discrete random variable. The expected value of $F$ is:\n",
    "$$\\mathbb{E}[f] = \\int_{x \\in \\mathcal{D}} f(x) \\cdot p(x) dx$$\n",
    "\n",
    "\n",
    "#### Properties of Expectations\n",
    "\n",
    "- Let $f$ and $g$ be functions of random variables, and $k$ be a constant. Expectations have linearity.\n",
    "    - $\\mathbb{E}[0] = 0$\n",
    "    - $\\mathbb{E}[k \\cdot f] = k \\cdot \\mathbb{E}[f]$\n",
    "    - $\\mathbb{E}[f + g] = \\mathbb{E}[f] + \\mathbb{E}[g]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectations with Mean, Variance and Covariance\n",
    "\n",
    "- **Mean**: $\\text{mean}(X) = \\mathbb{E}[X]$\n",
    "- **Variance**: $\\text{var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$\n",
    "- **Standard Deviation**: $\\text{std}(X) = \\sqrt{\\text{var}(X)}$\n",
    "- **Covariance**: $\\text{cov}(X, Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$\n",
    "\n",
    "#### Properties of Variance\n",
    "\n",
    "- For any constant $k$, $\\text{var}(k) = 0$\n",
    "- $\\text{var}(X) \\ge 0$\n",
    "- $\\text{var}(k \\cdot X) = k^2 \\cdot \\text{var}(X)$\n",
    "- If $X$ and $Y$ are independent, then $\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)$\n",
    "\n",
    "#### Facts of Covariance\n",
    "\n",
    "- If $X$ and $Y$ are independent, then $\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y]$\n",
    "- If $X$ and $Y$ are independent, then $\\text{cov}(X, Y) = 0$\n",
    "- $\\text{var}(X) = \\text{cov}(X, X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IID Samples\n",
    "\n",
    "- Assume we have a set of data items $x_i$ such that:\n",
    "    1. They are independent;\n",
    "    2. The histogram of a very large set of data items looks increasingly like the probability distribution $P(X)$ as the number of data items increases.\n",
    "- Then, these data items are **independent identically distributed samples** of $P(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov's Inequality\n",
    "\n",
    "$$P(\\{\\lvert X \\rvert \\ge a\\}) \\le \\frac{\\mathbb{E}[\\lvert X \\rvert]}{a}$$\n",
    "\n",
    "#### Interpretation of Markov's Inequality\n",
    "\n",
    "- Markov's Inequality relates probability cumulative distribution functions to expectations by establishing an upper bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebyshev's Inequality\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\{\\lvert X - \\mathbb{E}[X] \\rvert \\ge a\\}) &\\le \\frac{\\text{var}(X)}{a^2} \\\\\n",
    "P(\\{\\lvert X - \\mathbb{E}[X] \\rvert \\ge k\\sigma\\}) &\\le \\frac{1}{k^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Interpretation of Chebyshev's Inequality\n",
    "\n",
    "- Chebyshev's Inequality states that the probability of a random variable being at least $k$ standard deviations from the mean must be at most $\\frac{1}{k^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator Functions\n",
    "\n",
    "- An indicator function for an event is a function that takes the value zero for values of $x$ where the event does not occur, and one where the event occurs.\n",
    "$$\\mathbb{I}_{\\lvert \\mathcal{E} \\rvert}$$\n",
    "- An indicator function for an event has an expectation equivalent to the probability of the event.\n",
    "$$\\mathbb{E}[\\mathbb{I}_{\\lvert \\mathcal{E} \\rvert}] = P(\\mathcal{E})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Law of Large Numbers\n",
    "\n",
    "- Assume a set of $N$ IID samples $x_i$ of a probability distribution $P(X)$. $X_N$ is a random variable of the IID samples.\n",
    "$$\\mathbb{E}[X_N] = \\frac{\\sum_{i = 1}^{N} x_i}{N}$$\n",
    "- If $P(X)$ has finite variance, then for any positive number $\\epsilon$,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\lim_{N \\to \\infty} P(\\{\\lvert X_N - \\mathbb{E}[X] \\rvert \\ge \\epsilon \\}) &= 0 \\\\\n",
    "\\lim_{N \\to \\infty} P(\\{\\lvert X_N - \\mathbb{E}[X] \\rvert < \\epsilon \\}) &= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Implications of Weak Law of Large Numbers\n",
    "\n",
    "- Assume a random variable $X$. Then, the weak law of large numbers state that if a large number of IID samples of the random variable is observed, the average of these IID samples should be very close to $\\mathbb{E}[X]$.\n",
    "- As the weak law of large numbers allow expectations to be estimated, **PROBABILITIES** follow as they are expectations of indicator functions.\n",
    "- **THUS, EXPECTATIONS CAN BE USED IN BUILDING A THEORY OF DECISION MAKING!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Useful Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivations of Probability Distributions\n",
    "\n",
    "- Model Building\n",
    "    1. What process produced the data?\n",
    "    2. What sort of data can we expect in the future?\n",
    "    3. What labels should we attach to unlabelled data?\n",
    "    4. Is an effect easily explained by chance variations, or is it real?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Uniform Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Discrete_uniform_distribution)*\n",
    "\n",
    "- A discrete uniform random variable, $X$, takes values from $a$ until $b$ with the same probability $\\frac{1}{b - a}$.\n",
    "\n",
    "#### Properties of Discrete Uniform Distribution\n",
    "\n",
    "- **Parameters**: $a$, $b$\n",
    "    - Where $a < b$\n",
    "- **PMF**:\n",
    "$$P(\\{X = x\\}) = \\frac{1}{b - a}$$\n",
    "- **CDF**:\n",
    "$$P(\\{X \\le x\\}) = \\frac{x - a}{b - a}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\frac{a + b}{2}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\frac{(b - a)^2}{12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Bernoulli Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_distribution)*\n",
    "\n",
    "- A discrete Bernoulli random variable, $X$, is the outcome from a single experiment from which this outcome is classified as either a success, $X = 1$ with probability $p$, or a failure, $X = 0$ with probability $1 - p$.\n",
    "\n",
    "#### Properties of Discrete Bernoulli Distribution\n",
    "\n",
    "- **Parameters**: $p$\n",
    "    - Where $0 \\le p \\le 1$\n",
    "    - Where $p$ is the probability of the trial's success\n",
    "- **PMF**:\n",
    "$$\n",
    "P(\\{X = x\\}) = \n",
    "\\begin{cases}\n",
    "1 - p & \\text{if } x = 0 \\\\\n",
    "p     & \\text{if } x = 1\n",
    "\\end{cases}\n",
    "$$\n",
    "- **CDF**:\n",
    "$$\n",
    "P(\\{X \\le x\\}) = \n",
    "\\begin{cases}\n",
    "0     & \\text{if } x < 0\\\\\n",
    "1 - p & \\text{if } 0 \\le x < 0 \\\\\n",
    "p     & \\text{if } x \\ge 1\n",
    "\\end{cases}\n",
    "$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = p$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = p(1 - p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Binomial Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution)*\n",
    "\n",
    "- A discrete binomial random variable, $X$, is the number of successful outcomes from a sequence of $n$ independent experiments in which each experiment has  an outcome classified as either a success with probability $p$ or a failure with probability $1 - p$\n",
    "\n",
    "#### Properties of Discrete Binomial Distribution\n",
    "\n",
    "- **Parameters**: $n$, $p$\n",
    "    - Where $n \\ge 0$\n",
    "    - Where $0 \\le p \\le 1$\n",
    "    - Where $n$ is the number of trials\n",
    "    - Where $p$ is the probability of each trial's success\n",
    "- **PMF**:\n",
    "$$P(\\{X = x\\}) = \\binom{n}{x} p^x (1 - p)^{n - x}$$\n",
    "- **CDF**:\n",
    "$$P(\\{X \\le x\\}) = \\sum_{i = 0}^{x} \\binom{n}{i} p^i (1 - p)^{n - i}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = np$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = np(1 - p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Poisson Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Poisson_distribution)*\n",
    "\n",
    "- A discrete Poisson random variable, $X$, is the number of events occuring in a fixed interval of time or at a fixed rate.\n",
    "- A discrete random variable is approximated by a discrete binomial random variable where $n$ is large and $p$ is small such that $\\lambda = np$ is moderate.\n",
    "\n",
    "#### Properties of Discrete Poisson Distribution\n",
    "\n",
    "- **Parameters**: $\\lambda$\n",
    "    - Where $\\lambda > 0, \\lambda \\in \\mathbb{R}$\n",
    "    - Where $\\lambda$ is the occurrence rate\n",
    "- **PMF**:\n",
    "$$P(\\{X = x\\}) = e^{-\\lambda} \\frac{\\lambda^x}{x!}$$\n",
    "- **CDF**:\n",
    "$$P(\\{X \\le x\\}) = e^{-\\lambda} \\sum_{i = 0}^{x} \\frac{\\lambda^i}{i!}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\lambda$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\lambda$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Geometric Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Geometric_distribution)*\n",
    "\n",
    "- A discrete geometric random variable, $X$, is the number of Bernoulli trials with probability $p$ needed to get one success.\n",
    "\n",
    "#### Properties of Discrete Geometric Distribution\n",
    "\n",
    "- **Parameters**: $p$\n",
    "    - Where $0 \\le p \\le 1$\n",
    "    - Where $p$ is the probability of each trial's success\n",
    "- **PMF**:\n",
    "$$P(\\{X = x\\}) = (1 - p)^{x - 1} p$$\n",
    "- **CDF**:\n",
    "$$P(\\{X \\le x\\}) = 1 - (1 - p)^x$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\frac{1}{p}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\frac{1 - p}{p^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Negative Binomial Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Negative_binomial_distribution)*\n",
    "\n",
    "- A discrete negative binomial random variable, $X$, is the number of successes in a sequence of independent and identically distributed Bernoulli trials before a specified (non-random) number of failures.\n",
    "\n",
    "#### Properties of Discrete Negative Binomial Distribution\n",
    "\n",
    "- **Parameters**: $r$, $p$\n",
    "    - Where $r > 0$\n",
    "    - Where $0 \\le p \\le 1$\n",
    "    - Where $r$ is the number of failures until the trials are stopped.\n",
    "    - Where $p$ is the probability of the trial's success\n",
    "- **PMF**:\n",
    "$$P(\\{X = x\\}) = \\binom{x + r - 1}{x} p^x (1 - p)^r$$\n",
    "- **CDF**:\n",
    "$$P(\\{X \\le x\\}) = \\sum_{i = 0}^{x} \\binom{i + r - 1}{i} p^i (1 - p)^r$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\frac{pr}{1 - p}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\frac{pr}{(1 - p)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Hypergeometric Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Hypergeometric_distribution)*\n",
    "\n",
    "- A discrete hypergeometric random variable, $X$, is the number of successes (or random draws for which the object drawn has a specified feature) in $n$ draws, without replacement, from a finite population of size $N$ that contains exactly $K$ objects wth that specified feature.\n",
    "\n",
    "#### Properties of Discrete Hypergeometric Distribution\n",
    "\n",
    "- **Parameters**: $N$, $n$, $K$\n",
    "    - Where $N \\ge 0$\n",
    "    - Where $0 \\le n \\le N$\n",
    "    - Where $0 \\le K \\le N$\n",
    "    - Where $N$ is the size of the population\n",
    "    - Where $n$ is the number of objects drawn\n",
    "    - Where $K$ is the number of objects with the specified feature\n",
    "- **PMF**:\n",
    "$$P(\\{X = x\\}) = \\frac{\\binom{K}{x} \\binom{N - K}{n - x}}{\\binom{N}{n}}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = n \\frac{K}{N}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = n \\frac{K}{N} \\frac{N - K}{N} \\frac{N - n}{N - 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Uniform Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Uniform_distribution_%28continuous%29)*\n",
    "\n",
    "![Continuous Uniform Distribution](images/Uniform_PDF.gif)\n",
    "\n",
    "#### Properties of Continuous Uniform Distribution\n",
    "\n",
    "- **Parameters**: $a$, $b$\n",
    "    - Where $a < b$\n",
    "- **PDF**:\n",
    "$$p(x) = \\frac{1}{b - a}$$\n",
    "- **CDF**:\n",
    "$$F(x) = \\frac{x - a}{b - a}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\frac{a + b}{2}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\frac{(b - a)^2}{12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Normal Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Normal_distribution)*\n",
    "\n",
    "![Continuous Normal Distribution](images/Normal_PDF.gif)\n",
    "\n",
    "#### Properties of Continuous Normal Distribution\n",
    "\n",
    "- **Parameters**: $\\mu$, $\\sigma^2$\n",
    "    - Where $\\mu$ is the mean\n",
    "    - Where $\\sigma^2$ is the variance\n",
    "- **PDF**:\n",
    "$$p(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}$$\n",
    "- **CDF**:\n",
    "$$\n",
    "\\begin{align}\n",
    "F(x) &= \\Phi\\left(\\frac{x - \\mu}{\\sigma}\\right) \\\\\n",
    "\\Phi(x) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} e^{-\\frac{y^2}{2}} dy\n",
    "\\end{align}\n",
    "$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\mu$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Exponential Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Exponential_distribution)*\n",
    "\n",
    "![Continuous Exponential Distribution](images/Exponential_PDF.gif)\n",
    "\n",
    "#### Properties of Continuous Exponential Distribution\n",
    "\n",
    "- **Parameters**: $\\lambda$\n",
    "    - Where $\\lambda > 0, \\lambda \\in \\mathbb{R}$\n",
    "    - Where $\\lambda$ is the occurrence rate\n",
    "- **PDF**:\n",
    "$$p(x) = \\lambda e^{-\\lambda x}$$\n",
    "- **CDF**:\n",
    "$$F(x) = 1 - e^{-\\lambda x}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\frac{1}{\\lambda}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\frac{1}{\\lambda^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Gamma Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Gamma_distribution)*\n",
    "\n",
    "![Continuous Gamma Distribution](images/Gamma_PDF.gif)\n",
    "\n",
    "#### Properties of Continuous Gamma Distribution\n",
    "\n",
    "- $\\Gamma(x)$ is the [gamma function](https://en.wikipedia.org/wiki/Gamma_function).\n",
    "    - The gamma function is a generalization of a factorial:\n",
    "$$\\Gamma(\\alpha) = (\\alpha - 1)\\Gamma(\\alpha - 1)$$\n",
    "- $\\gamma(s, x)$ is the [lower incomplete gamma function](https://en.wikipedia.org/wiki/Incomplete_gamma_function)\n",
    "- **Parameters**: $\\alpha$, $\\beta$\n",
    "    - Where $\\alpha > 0$\n",
    "    - Where $\\beta > 0$\n",
    "    - Where $\\alpha$ is the shape\n",
    "    - Where $\\beta$ is the rate\n",
    "- **PDF**:\n",
    "$$p(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}$$\n",
    "- **CDF**:\n",
    "$$F(x) = \\frac{1}{\\Gamma(\\alpha)} \\gamma(\\alpha, \\beta x)$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\frac{\\alpha}{\\beta}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\frac{\\alpha}{\\beta^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Weibull Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Weibull_distribution)*\n",
    "\n",
    "![Continuous Weibull Distribution](images/Weibull_PDF.gif)\n",
    "\n",
    "#### Properties of Continuous Weibull Distribution\n",
    "\n",
    "- **Parameters**: $\\lambda$, $k$\n",
    "    - Where $\\lambda > 0$\n",
    "    - Where $k > 0$\n",
    "    - Where $\\lambda$ is the scale\n",
    "    - Where $k$ is the shape\n",
    "- **PDF**:\n",
    "$$\n",
    "p(x) = \n",
    "\\begin{cases}\n",
    "\\frac{k}{\\lambda} \\left(\\frac{x}{\\lambda}\\right)^{k - 1} e^{-(x / \\lambda)^k} & \\text{if } x \\ge 0 \\\\\n",
    "0                                                                             & \\text{if } x < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "- **CDF**:\n",
    "$$\n",
    "F(x) = \n",
    "\\begin{cases}\n",
    "1 - e^{-(x / \\lambda)^k} & \\text{if } x \\ge 0 \\\\\n",
    "0                        & \\text{if } x < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\lambda \\Gamma(1 + 1 / k)$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\lambda^2 \\left[\\Gamma\\left(1 + \\frac{2}{k}\\right) - \\left(\\Gamma\\left(1 + \\frac{1}{k}\\right)\\right)^2\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Cauchy Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Cauchy_distribution)*\n",
    "\n",
    "![Continuous Cauchy Distribution](images/Cauchy_PDF.gif)\n",
    "\n",
    "#### Properties of Continuous Cauchy Distribution\n",
    "\n",
    "- **Parameters**: $x_0$, $\\gamma$\n",
    "    - Where $\\gamma > 0$\n",
    "    - Where $x_0$ is the location\n",
    "    - Where $\\gamma$ is the scale\n",
    "- **PDF**:\n",
    "$$p(x) = \\frac{1}{\\pi \\gamma \\left[1 + \\left(\\frac{x - x_0}{\\gamma}\\right)^2\\right]}$$\n",
    "- **CDF**:\n",
    "$$F(x) = \\frac{1}{\\pi} \\arctan\\left(\\frac{x - x_0}{\\gamma}\\right) + \\frac{1}{2}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\text{undefined}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\text{undefined}$$\n",
    "- **Median**:\n",
    "$$\\text{median}(X) = x_0$$\n",
    "- **IQR**:\n",
    "$$\\text{iqr}(X) = 2\\gamma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Beta Distribution\n",
    "\n",
    "*[See Also: Wikipedia](https://en.wikipedia.org/wiki/Beta_distribution)*\n",
    "\n",
    "![Continuous Beta Distribution](images/Beta_PDF.gif)\n",
    "\n",
    "#### Properties of Continuous Beta Distribution\n",
    "\n",
    "- $B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}$\n",
    "- **Parameters**: $\\alpha$, $\\beta$\n",
    "    - Where $\\alpha > 0$\n",
    "    - Where $\\beta > 0$\n",
    "    - Where $\\alpha$ is the shape\n",
    "    - Where $\\beta$ is the shape\n",
    "- **PDF**:\n",
    "$$p(x) = \\frac{x^{\\alpha - 1} (1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)}$$\n",
    "- **Mean**:\n",
    "$$\\text{mean}(X) = \\frac{\\alpha}{\\alpha + \\beta}$$\n",
    "- **Variance**:\n",
    "$$\\text{var}(X) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Approximation to Binomial Distribution\n",
    "\n",
    "- The **DeMoivre-Laplace limit theorem** (a special case of the *central limit theorem*) states that if the discrete binomial random variable is expressed in standard coordinates, then this standard coordinates distribution will converge to the standard normal distribution ($X \\sim N(0, 1)$).\n",
    "- Accordingly, if $X$ is a discrete binomial random variable with $n$ number of trials and $p$ probability of each trial's success, then for any $a < b$, as $n \\to \\infty$:\n",
    "$$P\\left(\\left\\{a \\le \\frac{X - \\mu}{\\sigma} \\le b\\right\\}\\right) \\to \\Phi(b) - \\Phi(a)$$\n",
    "    - Where $\\mu = np$\n",
    "    - Where $\\sigma^2 = np(1 - p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Often a Normal Random Variable is How Far from the Mean\n",
    "\n",
    "- About $68\\%$ of the time, a normal random variable takes a value within one standard deviation of the mean.\n",
    "- About $95\\%$ of the time, a normal random variable takes a value within two standard deviations of the mean.\n",
    "- About $99\\%$ of the time, a normal random variable takes a value within three standard deviations of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Samples and Populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Mean\n",
    "\n",
    "- *Assumption: Sampling with Replacement*\n",
    "\n",
    "#### Properties of Sample and Population Mean\n",
    "\n",
    "- The sample mean is a random variable. It is random, because different samples from the population will have different values of the sample mean.\n",
    "- The expected value of this random variable is the population mean.\n",
    "\n",
    "#### Expressions for Mean and Variance of the Sample Mean\n",
    "\n",
    "- Let $X^{(N)}$ be a random variable for the mean of $N$ samples $x_i$.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}[X^{(N)}] &= \\text{popmean}(\\{X\\}) \\\\\n",
    "\\text{var}(X^{(N)}) &= \\frac{\\text{popstd}(\\{X\\})^2}{N} \\\\\n",
    "\\text{std}(X^{(N)}) &= \\frac{\\text{popstd}(\\{X\\})}{\\sqrt{N}}\n",
    "\\end{align}\n",
    "$$\n",
    "- If you draw $N$ samples, because the standard deviation of your estimate of the mean is $\\frac{\\text{popstd}(\\{X\\})}{\\sqrt{N}}$,\n",
    "    1. The more samples you draw, the better your estimate becomes.\n",
    "    2. The estimate improves rather slowly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Mean and Distributions\n",
    "\n",
    "- A population and the sampling process can be replaced by a probability distribution and the drawing of IID samples.\n",
    "- Assume a set of $N$ data items $x_i$ drawn as IID samples from some probability distribution $P(X)$,\n",
    "$$\n",
    "\\begin{align}\n",
    "X^{(N)} &= \\frac{\\sum_{i} x_i}{N} \\\\\n",
    "\\mathbb{E}[X^{(N)}] &= \\mathbb{E}_{P(X)}[X] \\\\\n",
    "\\text{var}(X^{(N)}) &= \\frac{\\text{var}(P(X)}{N}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval for a Population Mean\n",
    "\n",
    "- Choose some fraction $f$; a $f$ confidence interval for a population mean is an interval constructed using the sample mean.\n",
    "- It has the property that for that fraction $f$ of all samples, the population mean will lie inside the interval constructed from each sample's mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centered Confidence Interval for a Population Mean\n",
    "\n",
    "- Choose some $0 < \\alpha < 0.5$. A $1 - 2\\alpha$ centered confidence interval for a population mean is an interval $[a, b]$ constructed using the sample mean.\n",
    "- It has the property that for $\\alpha$ of all samples, the population mean is greater than $b$, and for another $\\alpha$ of all samples, the population is less than $a$. For all other samples, the population mean will lie inside the interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Variance of the Sample Mean\n",
    "\n",
    "![Variances of Sample Means](images/Figure_6_1.png)\n",
    "\n",
    "- If $N$ is large,\n",
    "$$\\text{popstd}(\\{x\\}) = \\text{std}(\\{x\\}) = \\sqrt{\\frac{1}{N} \\sum_{i = 1}^{N} \\left(x_i - \\text{mean}(\\{x\\}) \\right)^2}$$\n",
    "- If $N$ is small,\n",
    "$$\\text{popstd}(\\{x\\}) = \\text{stdunbiased}(\\{x\\}) = \\sqrt{\\frac{1}{N - 1} \\sum_{i = 1}^{N} \\left(x_i - \\text{mean}(\\{x\\}) \\right)^2}$$\n",
    "- Let $X^{(N)}$ be a random variable for the mean of $N$ samples $x_i$. An estimate of the standard deviation of $X^{(N)}$ is:\n",
    "$$\\text{stderr}(\\{x\\}) = \\frac{\\text{stdunbiased}(\\{x\\})}{\\sqrt{N}}$$\n",
    "- A $\\text{popstd}(\\{x\\}) \\approx \\text{std}(\\{x\\})$ approximation is biased because the approximation tends to be slightly too small. $N - 1$ replaces $N$ because $\\sum_{i = 1}^{N} \\left(x_i - \\text{mean}(\\{x\\}) \\right)$ has only $N - 1$ independent numbers (i.e., **degrees of freedom**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Distribution of the Sample Mean\n",
    "\n",
    "- Student's t-distribution is a probability distribution taken from a family, indexed by a number (the degrees of freedom of the distribution).\n",
    "    - If the number of degrees of freedom is large, the distribution is very similar to a normal distribution.\n",
    "    - Else, the tails are somewhat heavier than those of a normal distribution.\n",
    "- The sample mean yields the value of a t-random variable with $N - 1$ degrees of freedom:\n",
    "$$T = \\frac{\\text{mean}(\\{x\\}) - \\text{popmean}(\\{X\\})}{\\text{stderr}(\\{x\\})}$$\n",
    "- If $N$ is large enough ($N \\ge 30$), the sample mean yields the value of a standard normal random variable, $Z$:\n",
    "$$Z = \\frac{\\text{mean}(\\{x\\}) - \\text{popmean}(\\{X\\})}{\\text{stderr}(\\{x\\})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals for Population Means\n",
    "\n",
    "- Assume the sample is large enough so that $\\frac{\\text{mean}(\\{x\\}) - \\text{popmean}(\\{X\\})}{\\text{stderr}(\\{x\\})}$ is a standard normal random variable.\n",
    "- For about $68\\%$ of samples:\n",
    "$$\\text{mean}(\\{x\\}) - \\text{stderr}(\\{x\\}) \\le \\text{popmean}(\\{X\\}) \\le \\text{mean}(\\{x\\}) + \\text{stderr}(\\{x\\})$$\n",
    "- For about $95\\%$ of samples:\n",
    "$$\\text{mean}(\\{x\\}) - 2\\cdot\\text{stderr}(\\{x\\}) \\le \\text{popmean}(\\{X\\}) \\le \\text{mean}(\\{x\\}) + 2\\cdot\\text{stderr}(\\{x\\})$$\n",
    "- For about $99\\%$ of samples:\n",
    "$$\\text{mean}(\\{x\\}) - 3\\cdot\\text{stderr}(\\{x\\}) \\le \\text{popmean}(\\{X\\}) \\le \\text{mean}(\\{x\\}) + 3\\cdot\\text{stderr}(\\{x\\})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Centered $1 - 2\\alpha$ Confidence Interval for a Population Mean for a Large Sample\n",
    "\n",
    "1. Draw a sample $\\{x\\}$ of $N$ items from a population.\n",
    "$$\\text{stdunbiased}(\\{x\\}) = \\sqrt{\\frac{1}{N - 1} \\sum_{i = 1}^{N} \\left(x_i - \\text{mean}(\\{x\\}) \\right)^2}$$\n",
    "2. Estimate the standard error.\n",
    "$$\\text{stderr}(\\{x\\}) = \\frac{\\text{stdunbiased}(\\{x\\})}{\\sqrt{N}}$$\n",
    "3. If $N$ is large enough, $T$ is a standard normal variable.\n",
    "$$T = \\frac{\\text{mean}(\\{x\\}) - \\text{popmean}(\\{X\\})}{\\text{stderr}(\\{x\\})}$$\n",
    "4. Compute $b$ such that for a standard normal variable, $P(\\{T \\ge b\\}) = a$.\n",
    "\n",
    "#### Confidence Interval\n",
    "\n",
    "$$[\\text{mean}(\\{x\\}) - b\\cdot\\text{stderr}(\\{x\\}), \\text{mean}(\\{x\\}) + b\\cdot\\text{stderr}(\\{x\\})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Centered $1 - 2\\alpha$ Confidence Interval for a Population Mean for a Small Sample\n",
    "\n",
    "1. Draw a sample $\\{x\\}$ of $N$ items from a population.\n",
    "$$\\text{stdunbiased}(\\{x\\}) = \\sqrt{\\frac{1}{N - 1} \\sum_{i = 1}^{N} \\left(x_i - \\text{mean}(\\{x\\}) \\right)^2}$$\n",
    "2. Estimate the standard error.\n",
    "$$\\text{stderr}(\\{x\\}) = \\frac{\\text{stdunbiased}(\\{x\\})}{\\sqrt{N}}$$\n",
    "3. If $N$ is small, $T$ is a t-random variable.\n",
    "$$T = \\frac{\\text{mean}(\\{x\\}) - \\text{popmean}(\\{X\\})}{\\text{stderr}(\\{x\\})}$$\n",
    "4. Compute $b$ such that for a t-random variable, $P(\\{T \\ge b\\}) = a$.\n",
    "\n",
    "#### Confidence Interval\n",
    "\n",
    "$$[\\text{mean}(\\{x\\}) - b\\cdot\\text{stderr}(\\{x\\}), \\text{mean}(\\{x\\}) + b\\cdot\\text{stderr}(\\{x\\})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Standard Error of Any Statistic - The Bootstrap\n",
    "\n",
    "\n",
    "- **Goal**: Estimate the standard error for a statistic $S$ evaluated on a dataset of $N$ items $\\{x\\}$.\n",
    "\n",
    "\n",
    "1. Compute $r$ bootstrap replicates of the dataset. Write the $i$'th replicate $\\{x\\}_i$. Obtain each by:\n",
    "    1. Building a uniform probability distribution on the numbers $1, ..., N$.\n",
    "    2. Drawing $N$ independent samples from this distribution. Write $s(i)$ for the $i$'th such sample.\n",
    "    3. Building a new dataset $\\{x_{s(1)}, ..., x_{s(N)}\\}$.\n",
    "2. For each replicate, compute $S(\\{x\\}_i)$.\n",
    "3. Compute the statistic $\\bar{S}$.\n",
    "$$\\bar{S} = \\frac{\\sum_{i} S(\\{x\\}_i)}{r}$$\n",
    "4. Estimate the standard error for $S$.\n",
    "$$\\text{stderr}(\\{S\\}) = \\sqrt{\\frac{\\sum_{i} \\left[ S(\\{x\\}_i) - \\bar{S} \\right]^2}{r - 1}}$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
