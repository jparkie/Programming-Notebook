{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Principles and Algorithms\n",
    "\n",
    "*Authors: Kishan G. Mehrotra, Chilukuri K. Mohan, and HuaMing Huang*\n",
    "\n",
    "**ISBN: 978-3-319-67526-8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 What's an Anomaly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definition\n",
    "\n",
    "- An **anomaly** (**outlier**) is a substantial variation from the norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primary Assumption of Anomaly Detection\n",
    "\n",
    "- Anomaly detection approaches are based on models and predictions from past data.\n",
    "- It is primarily assumed that the underlying processes, that led to the generation of the data, are believed not to have changed significantly.\n",
    "- Hence, the statistics that characterized a system in the past continue to characterize the system in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Models/Processes and Anomaly Detection\n",
    "\n",
    "- In some cases, common-sense knowledge or a **model** of the underlying **process** is available to detect anomalies.\n",
    "- In other cases, a model or a process must be identified prior to detecting anomalies.\n",
    "- In other cases, the effects of an underlying (unknown) process must be characterized on observable data prior to detecting anomalies.\n",
    "- Hence, one can estimate the likelihood with which a particular data point could have been generated by the underlying (unknown) process, based on a characterization of what is non-anomalous from other observable data generated by the same process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inefficiency of Traditional Machine Learning and Classification Algorithms\n",
    "\n",
    "- Traditional machine learning and classification algorithms are ineffective at classifying data as anomalous or non-anomalous for the following reasons.\n",
    "    1. Anomalous data are much rarer than non-anomalous data.\n",
    "    2. Results obtained by classification algorithms will often result in too many false negatives (i.e., not recognizing anomalies).\n",
    "    3. Various anomalous cases may have very little in common.\n",
    "    4. The occurrence of an anomaly may well be within the same bounds as those characterizing non-anomalous data, and hence not distinguishable directly by attribute values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Anomaly Detection Algorithms Results\n",
    "\n",
    "- When an anomaly detection algorithm is applied, three possible cases need to be considered:\n",
    "    1. **Correct Detection**: Detected abnormalities in data do correspond exactly to abnormalities in the process.\n",
    "    2. **False Positives**: The process continues to be normal, but unexpected data values are observed, e.g., due to intrinsic system noise.\n",
    "    3. **False Negatives**: The process becomes abnormal, but the consequences are not registered in the abnormal data, e.g., due to the signal of the abnormality being insufficiently strong compared to the noise in the system.\n",
    "- It is impossible to achieve 100% correct detection. Hence, it is important to minimize and to compromise between false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision\n",
    "\n",
    "Given a data set $\\mathcal{D}$, suppose an outlier detection algorithm identifies $m > 0$ potential anomalies, of which $m_t \\leq m$ are known to be true outliers. Then **precision**, which measures the proportion of true outliers in top $m$ suspicious instances, is:\n",
    "\n",
    "$$Pr = \\frac{m_t}{m}$$\n",
    "\n",
    "and equals $1.0$ if all the points identified by the algorithm are true outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall\n",
    "\n",
    "If $\\mathcal{D}$ contains $d_t \\geq m_t$ true outliers, then **recall** is defined as:\n",
    "\n",
    "$$Re = \\frac{m_t}{d_t}$$\n",
    "\n",
    "which equals $1.0$ if all true outliers are discovered by the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RankPower\n",
    "\n",
    "If $R_i$ denotes the rank of the $i$th true outlier in the sorted list of most suspicious objects, then the **RankPower** is given by:\n",
    "\n",
    "$$RP = \\frac{m_t (m_t + 1)}{2 \\sum_{i=1}^{m_t} R_i}$$\n",
    "\n",
    "which takes the maximum value $1$ when all $d_t$ true outliers are in the top $d_t$ positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing Anomaly Detection Algorithms\n",
    "\n",
    "- When algorithms with the same $m$ are compared, the larger values of all three of precision, recall, and RankPower imply better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Old Problems vs. New Problems\n",
    "\n",
    "- Traditional machine learning and classification algorithms are effective at identifying known (old) types of anomalies, yet they are ineffective at identifying unknown (new) types of anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What Kind of Data?\n",
    "\n",
    "- **Assumption #1**: Some process exists, and that there are rules, guidelines, or principles governing the possible randomness in the data.\n",
    "- **Assumption #2**: The characteristics of this process hold in the entire set of data.\n",
    "- The choice of the anomaly detection algorithm should depend on the nature of the process generating the anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What's a Norm?\n",
    "\n",
    "- The **norm** is a set of points such that to consider a point to be abnormal, it must be substantially distant from each of the points in the norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Outliers in One-Dimensional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uniform Distribution\n",
    "\n",
    "- When data is distributed uniformly over a finite range, if the neighborhood of any data point is as richly populated as any other point, it can be argued that there are no anomalous data points.\n",
    "- However, a small neighborhood that contains substantially fewer or more data points than expected from a uniform distribution can be an indication of anomalous behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal Distribution\n",
    "\n",
    "- When data is distributed normally, the density of points decreases substantially as we move away from the mean.\n",
    "- $0.1\\%$ of the points are more than $3\\sigma$ away from the mean.\n",
    "- $5 \\times 10^{-8}\\%$ of the points are more than $6\\sigma$ away from the mean.\n",
    "- **Perspective #1**: A point beyond $3\\sigma$ from the mean is anomalous.\n",
    "- **Perspective #2**: A set of point is anomalous if and only if their number is substantially higher than the number expected if the data were to be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other Unimodal Distributions\n",
    "\n",
    "- **Perspective #1**: If the nature and characteristics of the distribution are known, one may seek to find thresholds beyond which a relatively small number of the data points are found.\n",
    "- **Perspective #2**: Otherwise, a collection of points is anomalous if their number is larger than predicted by the statistics of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multimodal Distributions\n",
    "\n",
    "- With data sets containing multiple modes, it is useful to think of the data as consisting of a collection of clusters of data points.\n",
    "- Points which do not belong to any cluster are candidates to be considered anomalous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Varying Definitions of Clustering\n",
    "\n",
    "1. If the relative number of points (per unit distance) is substantially higher in a small region than the entire data set, the points in that region can be considered a cluster.\n",
    "    - The distribution of densities can itself be analyzed, and (if unimodal) we can identify the density threshold beyond which the density is high enough to consider a region to contain a cluster.\n",
    "2. If points are substantially closer to each other (on average) than they are to the nearest points outside the cluster, then the points form a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Outliers in Multidimensional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ideas regarding outliers in one-dimensional data extend to multidimensional data with the following complications.\n",
    "    1. The choice of a distance measure can affect how the data points are clustered.\n",
    "    2. The dimensions can have varying ranges, so the choice of a normalization technique can affect how the data points are clustered.\n",
    "    3. There can exist some dimensions which require special consideration when clustering such as time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Anomaly Detection Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primary Approaches to Anomaly Detection\n",
    "\n",
    "1. **Distance-Based**: Points that are farther away from others are considered more anomalous.\n",
    "2. **Density-Based**: Points that are in relatively low density regions are considered more anomalous.\n",
    "3. **Rank-Based**: The most anomalous points are those whose nearest neighbors have others as nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nature of Data\n",
    "\n",
    "1. **Supervised**: Classification labels are known for a set of \"training\" data, and all comparisons and distances are with respect to such training data.\n",
    "2. **Unsupervised**: No such labels are known, so distances and comparisons are with respect to the entire data set.\n",
    "3. **Semi-Supervised**: Labels are known for some data, but not for most others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Characteristics of Unsupervised Anomaly Detection Algorithms\n",
    "\n",
    "1. Normal behaviors have to be dynamically defined. No prior training data set or reference data set for normal behavior is needed.\n",
    "2. Outliers must be detected effectively even if the distribution of data is unknown.\n",
    "3. The algorithm should be adaptable to different domain characteristics; it should be applicable or modifiable for outlier detection in different domains, without requiring substantial domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Evaluation Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can quantitative metrics be devised so that we can unambiguously say which of two data points in a given data set is \"more anomalous\" - without appealing to human intuition? An answer is required in order to minimize the number of false positives generated by anomaly detection algorithms, particularly in the unsupervised and semi-supervised contexts.\n",
    "2. Each anomaly detection algorithm answers the above question in a procedural way. Can this implicit choice be justified on mathematical or rational grounds?\n",
    "3. In some cases, algorithms also appeal to the desire to compute the results in a \"reasonable\" amount of time, ruling out the search for optimal solutions. In such cases, can we say anything about the quality of the obtained solutions when compared to the optimal solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distance-Based Anomaly Detection Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mathematical Notations\n",
    "\n",
    "- $\\mathfrak{D}$ is the $n$-dimensional data set, presumed to be in continuous unbounded real-valued space $\\mathfrak{R}^{n}$.\n",
    "- $p$ and $q$ are data points in $\\mathfrak{D}$.\n",
    "- $P$ and $Q$ are sets of data points in $\\mathfrak{D}$.\n",
    "- $d(p,q)$ is the distance between two points $p,q \\in \\mathfrak{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primary Questions\n",
    "\n",
    "1. **Measurement**: How anomalous is a given point? This requires transforming points into a one-dimensional scale, e.g., defining a function $\\alpha$ such that $\\alpha(p) \\in \\mathfrak{R}$ measures the anomalousness of $p \\in \\mathfrak{D}$.\n",
    "2. **Absolute**: Is a given point anomalous? This requires finding a threshold $\\theta > 0$ so that we say a point $p \\in \\mathfrak{D}$ is anomalous if $\\alpha(p) \\gt \\theta$.\n",
    "3. **Relative**: Is one point \"more anomalous\" than another? This requires comparing points, so that $\\alpha(p) \\gt \\alpha(q)$ if a point $p \\in \\mathfrak{D}$ is more anomalous than another point $q \\in \\mathfrak{D}$. We may denote this relationship with the symbol \"$\\rhd$\", i.e., $p \\rhd q$ if $\\alpha(p) \\gt \\alpha(q)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Secondary Questions\n",
    "\n",
    "1. **Subset**: What are the $m$ most anomalous points in a given data set? To answer this question, we may use the \"relative\" criterion to find the most anomalous, the secondy most anomalous, etc., perhaps by sorting if $m$ is large.\n",
    "2. **Hybrid**: What are the $m$ most anomalous points in a given data set, which are also absolutely anomalous? The answer can be obtained by applying an absolute threshold to the \"Subset\" answer above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similarity and Distance\n",
    "\n",
    "- A **similarity measure** can be obtained by essentially considering the inverse of a **distance measure**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measures\n",
    "\n",
    "- [Mahalanobis Distance](https://en.wikipedia.org/wiki/Mahalanobis_distance)\n",
    "- [Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance)\n",
    "- [Minkowski Distance](https://en.wikipedia.org/wiki/Minkowski_distance)\n",
    "- [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "- [Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mahalanobis Distance\n",
    "\n",
    "$$d(p,q) = \\sqrt{ (p - q)^{T} S^{-1} (p - q) }$$\n",
    "\n",
    "where $S$ is the covariance matrix measuring the mutual correlations between dimensions for all points in the data set $\\mathfrak{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Euclidean Distance\n",
    "\n",
    "$$d(p,q) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}$$\n",
    "\n",
    "The Euclidean Distance is the Mahalanobis Distance where $S$ is the identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Minkowski Distance (Order $l$)\n",
    "\n",
    "$$d(p,q) = \\left( \\sum_{i=1}^{n} \\left| p_i - q_i \\right|^l \\right)^{\\frac{1}{l}}$$\n",
    "\n",
    "If $l = 1$, the Minkowski Distance is equal to the Euclidean Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine Similarity\n",
    "\n",
    "$$ \\cos (\\theta) = \\frac{p \\cdot q}{\\left|\\left| p \\right|\\right| \\left|\\left| q \\right|\\right|} = \\frac{\\sum_{i=1}^{d} p_{i} q_{i}}{\\sum_{i=1}^{d} p_{i}^{2} \\sum_{i=1}^{d} q_{i}^{2}}$$\n",
    "\n",
    "The Cosine Similarity ranges from $-1$ to $1$ where $1$ implies $p$ is equivalent to $q$ and $-1$ implies $p$ is exactly opposite to $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jaccard Index\n",
    "\n",
    "$$J(A,B) = \\frac{\\left| A \\cap B \\right|}{\\left| A \\cup B \\right|}$$\n",
    "\n",
    "where $A$ and $B$ are two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Distance-Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance to All Points\n",
    "\n",
    "- The most anomalous point is the farthest from all points in the data set.\n",
    "\n",
    "$$\\alpha(p) = \\sum_{q \\in \\mathfrak{D}} d(p,q)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance to Nearest Neighbor\n",
    "\n",
    "- The most anomalous point is one whose distance to nearest neighbor is the greatest.\n",
    "\n",
    "$$\\alpha(p) = \\min_{q \\in \\mathfrak{D}, q \\neq p} d(p,q)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average Distance to $k$ Nearest Neighbors\n",
    "\n",
    "- Let $k < N = \\left| \\mathfrak{D} \\right|$ be the number of nearest neighbors to be considered.\n",
    "- Let $Near(p,j)$ be the $j$th nearest neighbor of a point $p \\in \\mathfrak{D}$, where $j < N = \\left| \\mathfrak{D} \\right|$, breaking ties arbitrarily.\n",
    "- The most anomalous point is one whose average distance to $k$ nearest neighbors is the greatest.\n",
    "\n",
    "$$\\alpha(p) = \\sum_{j = 1}^{k} d(p, Near(p,j)) / k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Distance to $k$ Nearest Neighbors\n",
    "\n",
    "- As the median is less sensitive to noise in the data than the average, the median distance to $k$ nearest neighbors can be used as the anomalousness metric.\n",
    "- If $k = 2m-1$ is odd, the median distance to $k$ nearest neighbors is $Near(p,m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clustering-Based Anomaly Detection Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model-Based Anomaly Detection Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Distance and Density Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Rank Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Algorithms for Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
