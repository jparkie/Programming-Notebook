{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 493 - Probabilistic Reasoning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of Probability Theory <span name=\"S01\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *See [Stanford CS228 - Probability Review](https://ermongroup.github.io/cs228-notes/preliminaries/probabilityreview/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation <span name=\"S02\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Problem**: *How do we express a probability distribution $p(x_{1}, x_{2}, ..., x_{n})$ that models some real-world phenomenon?*\n",
    "    - *Naive Complexity*: $O(d^{n})$\n",
    "- **Solution**: *Representation with Probabilistic Graphical Models + Verifying Independence Assumptions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Networks (Directed Probabilistic Graphical Model) <span name=\"S03\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition - What is a Bayesian network?\n",
    "\n",
    "- A **Bayesian network** is a directed graph $G$ with the following:\n",
    "    - *Nodes*: A random variable $x_{i}$.\n",
    "    - *Edges*: A conditional probability distribution (CPD) $p(x_{i} \\mid x_{A_{i}})$ per node, specifying the probability of $x_i$ conditioned on its parent's values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation - How does a Bayesian network express a probability distribution?\n",
    "\n",
    "1. Let $p$ be a probability distribution.\n",
    "2. A naive representation of $p$ can be derived using the chain rule:\n",
    "$$p(x_{1}, x_{2}, ..., x_{n}) = p(x_{1}) p(x_{2} \\mid x_{1}) \\cdots p(x_{n} \\mid x_{n - 1}, ..., x_{2}, x_{1})$$\n",
    "3. A Bayesian network representation of $p$ compacts the naive representation by having each factor in the right hand side depend only on a small number of **ancestor variables** $x_{A_{i}}$:\n",
    "$$p(x_{i} \\mid x_{i - 1}, ..., x_{2}, x_{1}) = p(x_{i} \\mid x_{A_{i}})$$\n",
    "    - e.g., Approximate $p(x_{5} \\mid x_{4}, x_{3}, x_{2}, x_{1})$ with $p(x_{5} \\mid x_{A_{5}})$ where $x_{A_{5}} = \\{x_{4}, x_{3}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Space Complexity - How compact is a Bayesian network?\n",
    "\n",
    "- Consider each of the factors $p(x_{i} \\mid x_{A_{i}})$ as a **probability table**:\n",
    "    - *Rows*: Values of $x_{i}$\n",
    "    - *Columns*: Values of $x_{A_{i}}$\n",
    "    - *Cells*: Values of $p(x_{i} \\mid x_{A_{i}})$\n",
    "- If each discrete random variable takes $d$ possible values and has at most $k$ ancestors, then each probability table has at most $O(d^{k + 1})$ entries.\n",
    "- **Naive Representation Space Complexity**: $O(d^n)$\n",
    "- **Bayesian Networks Representation Space Complexity**: $O(n \\cdot d^{k + 1})$\n",
    "$$\\approx \\text{Bayesian Networks Representation} \\le \\text{Naive Representation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence Assumptions - Why are the independence assumptions of a Bayesian network important to identify?\n",
    "\n",
    "- A Bayesian network expresses a probability distribution $p$ via products of smaller, local conditional probability distributions (one for each variable).\n",
    "- These smaller, local conditional probability distributions introduces assumptions into the model of $p$ that certain variables are independent.\n",
    "- **Important Note**: Which independence assumptions are we exactly making by using a Bayesian network?\n",
    "    - *Correctness: Are these independence assumptions correct?*\n",
    "    - *Efficiency: Do these independence assumptions efficiently compact the representation?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $3$-Variable Independencies in Directed Graphs - How do you identify independent variables in a $3$-variable Bayesian network?\n",
    "\n",
    "- Let $x \\perp y$ indicate that variables $x$ and $y$ are independent.\n",
    "- Let $G$ be a Bayesian network with three nodes: $A$, $B$, and $C$.\n",
    "\n",
    "##### Common Parent\n",
    "\n",
    "- If $G$ is of the form $A \\leftarrow B \\rightarrow C$,\n",
    "    - If $B$ is observed, then $A \\perp C \\mid B$\n",
    "    - If $B$ is unobserved, then $A \\not\\perp C$\n",
    "- **Intuition**: $B$ contains all the information that determines the outcomes of $A$ and $C$; once it is observed, there is nothing else that affects $A$'s and $C$s' outcomes.\n",
    "\n",
    "##### Cascade\n",
    "\n",
    "- If $G$ equals $A \\rightarrow B \\rightarrow C$,\n",
    "    - If $B$ is observed, then $A \\perp C \\mid B$\n",
    "    - If $B$ is unobserved, then $A \\not\\perp C$\n",
    "- **Intuition**: $B$ contains all the information that determines the outcomes of $C$; once it is observed, there is nothing else that affects $C$'s outcomes.\n",
    "\n",
    "##### V-Structure\n",
    "\n",
    "- If $G$ is $A \\rightarrow C \\leftarrow B$, then knowing $C$ couples $A$ and $B$.\n",
    "    - If $C$ is unobserved, then $A \\perp B$\n",
    "    - If $C$ is observed, then $A \\not\\perp B \\mid C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $n$-Variable Independencies in Directed Graphs - How do you identify independent variables in a $n$-variable Bayesian network?\n",
    "\n",
    "- Let $I(p)$ be the set of all independencies that hold for a probability distribution $p$.\n",
    "- Let $I(G) = \\{(X \\perp Y \\mid Z) : X, Y \\text{ are } d\\text{-sep given } Z\\}$ be a set of variables that are $d$-separated in $G$.\n",
    "- If the probability distribution $p$ factorizes over $G$, then $I(G) \\subseteq I(p)$ and $G$ is an $I$-map (**independence map**) for $p$.\n",
    "- **Important Note 1**: Thus, variables that are $d$-separated in $G$ are independent in $p$.\n",
    "- **Important Note 2**: However, a probability distribution $q$ can factorize over $G$, yet have independencies that are not captured in $G$.\n",
    "- **Important Caveat**: A Bayesian network cannot perfectly represent all probability distributions.\n",
    "\n",
    "##### $d$-separation (a.k.a. Directed Separation)\n",
    "\n",
    "- $Q$ and $W$ are **$d$-separated** when variables $O$ are observed if they are **NOT CONNECTED** by an active path.\n",
    "\n",
    "##### Active Path\n",
    "\n",
    "- An undirected path in the Bayesian Network structure $G$ is called **active** given observed variables $O$ if for **EVERY CONSECUTIVE TRIPLE** of variables $X$, $Y$, $Z$ on the path, one of the following holds:\n",
    "    - **Evidential Trail**: $X \\leftarrow Y \\leftarrow Z$, and $Y$ is unobserved $Y \\not\\in O$\n",
    "    - **Causal Trail**: $X \\rightarrow Y \\rightarrow Z$, and $Y$ is unobserved $Y \\not\\in O$\n",
    "    - **Common Cause**: $X \\leftarrow Y \\rightarrow Z$, and $Y$ is unobserved $Y \\not\\in O$\n",
    "    - **Common Effect**: $X \\rightarrow Y \\leftarrow Z$, and $Y$ or any of its descendants are observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalence - When are two Bayesian networks $I$-equivalent?\n",
    "\n",
    "- $G_1$ and $G_2$ are **$I$-equivalent**...\n",
    "    - If they encode the same dependencies: $I(G_1) = I(G_2)$.\n",
    "    - If they have the same skeleton and the same v-structures.\n",
    "    - If the $d$-separation between variables is the same.\n",
    "    \n",
    "##### Skeleton\n",
    "\n",
    "![Skeleton](images/BN_1.png)\n",
    "\n",
    "- A **skeleton** is an undirected graph obtained by dropping the directionality of the arrows.\n",
    "    - (a) is Cascade\n",
    "    - (b) is Cascade\n",
    "    - (c) is Common Parent\n",
    "    - (d) is V-Structure\n",
    "    - (a), (b), (c), and (d) have the same skeleton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Problem 1 - $d$-separation\n",
    "\n",
    "![Problem 1 - $d$-separation](images/BN_P1.png)\n",
    "\n",
    "##### Question\n",
    "\n",
    "- Are $X_{1}$ and $X_{6}$ $d$-separated given $\\{X_{2}, X_{3}\\}$?\n",
    "\n",
    "##### Solution\n",
    "\n",
    "1. **Path**: $X_{1} \\rightarrow X_{2} \\rightarrow X_{6}$\n",
    "    1. *Consecutive Triple*: $X_{1} \\rightarrow X_{2} \\rightarrow X_{6}$\n",
    "        - Although $X_{2}$ is observed, the *common effect* does not hold.\n",
    "    2. As not all the consecutive triples hold, this path is not *active*.\n",
    "2. **Path**: $X_{1} \\rightarrow X_{3} \\rightarrow X_{5} \\rightarrow X_{6}$\n",
    "    1. *Consecutive Triple*: $X_{1} \\rightarrow X_{3} \\rightarrow X_{5}$\n",
    "        - Although $X_{3}$ is observed, the *common effect* does not hold.\n",
    "    2. *Consecutive Triple*: $X_{3} \\rightarrow X_{5} \\rightarrow X_{6}$\n",
    "        - As $X_{5}$ is unobserved, the *causal trail* does hold.\n",
    "    3. As not all the consecutive triples hold, this path is not *active*.\n",
    "3. As there are no active paths between $X_{1}$ and $X_{6}$, they are $d$-separated given $\\{X_{2}, X_{3}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Problem 2 - $d$-separation\n",
    "\n",
    "![Problem 2 - $d$-separation](images/BN_P2.png)\n",
    "\n",
    "##### Question\n",
    "\n",
    "- Are $X_{2}$ and $X_{3}$ $d$-separated given $\\{X_{1}, X_{6}\\}$?\n",
    "\n",
    "##### Solution\n",
    "\n",
    "1. **Path**: $X_{2} \\leftarrow X_{1} \\rightarrow X_{3}$\n",
    "    1. *Consecutive Triple*: $X_{2} \\leftarrow X_{1} \\rightarrow X_{3}$\n",
    "        - Although $X_{1}$ is observed, the *common effect* does not hold.\n",
    "    2. As not all the consecutive triples hold, this path is not *active*.\n",
    "2. **Path**: $X_{2} \\rightarrow X_{6} \\leftarrow X_{5} \\leftarrow X_{3}$\n",
    "    1. *Consecutive Triple*: $X_{2} \\rightarrow X_{6} \\leftarrow X_{5}$\n",
    "        - As $X_{6}$ is observed, the *common effect* does hold.\n",
    "    2. *Consecutive Triple*: $X_{6} \\leftarrow X_{5} \\leftarrow X_{3}$\n",
    "        - As $X_{5}$ is unobserved. the *causal trail* does hold.\n",
    "    3. As all the consecutive triples hold, this path is *active*.\n",
    "3. As there exists an active path between $X_{2}$ and $X_{3}$, they are not $d$-separated given $\\{X_{1}, X_{6}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Random Fields (Undirected Probabilistic Graphical Model) <span name=\"S04\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition - What is a Markov random field?\n",
    "\n",
    "- A **Markov random field** is an undirected graph $G$ with the following:\n",
    "    - *Nodes*: A random variable $x_{i}$.\n",
    "    - *Fully Connected Subgraphs*: An optional factor $\\phi_{c}(x_{c})$ per clique, specifying the level of coupling (**potentials**) between all the dependent variables within the clique.\n",
    "- **Important Note**:\n",
    ">...SPECIFYING THE LEVEL OF COUPLING BETWEEN ALL THE DEPENDENT VARIABLES WITHIN THE CLIQUE..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation - How does a Markov random field express a probability distribution?\n",
    "\n",
    "1. Let $p$ be a probability distribution.\n",
    "2. A Markov random field representation of $p$ is the following:\n",
    "$$p(x_{1}, x_{2}, ..., x_{n}) = \\frac{1}{Z} \\prod_{c \\in C} \\phi_{c}(x_{c})$$\n",
    "    - Where $C$ is the set of cliques of $G$.\n",
    "    - Where $\\phi_{c}$ is a **factor** (nonnegative function) over the variables in a clique.\n",
    "    - Where $Z$ is a **normalizing constant** that ensures that $p$ sums to one.\n",
    "$$Z = \\sum_{x_{1}, x_{2}, ..., x_{n}} \\prod_{c \\in C} \\phi_{c}(x_{c})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Space Complexity - How compact is a Markov random field?\n",
    "\n",
    "##### Factor Product\n",
    "\n",
    "- Let $A$, $B$, and $C$ be three disjoint sets of variables.\n",
    "- Let $\\phi_{1}(A, B)$ and $\\phi_{2}(B, C)$ be two factors.\n",
    "- Let $\\phi_{3}(A, B, C)$ be the **factor product**.\n",
    "$$\\phi_{3}(A, B, C) = \\phi_{1}(A, B) \\cdot \\phi_{2}(B, C)$$\n",
    "    - Where the two factors are multiplied for common values of $B$.\n",
    "\n",
    "##### Binary Factor Tables\n",
    "\n",
    "- Each of the optional factors $\\phi_{c}(x_{c})$ can be expressed as a product of **binary factor tables** $\\phi(X, Y)$:\n",
    "    - *Rows*: Values of $X$\n",
    "    - *Columns*: Values of $Y$\n",
    "    - *Cells*: Values of $\\phi(X, Y)$\n",
    "- If each variable takes $d$ values, each binary factor table has at most $O(d^{2})$ entries.\n",
    "- **Markov Random Fields Representation Space Complexity**: $O(E \\cdot d^{2})$\n",
    "    - Where $E$ is the number of edges in a Markov random field.\n",
    "$$\\approx \\text{Markov Random Field Representation} \\le \\text{Naive Representation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markov Random Fields vs. Bayesian Networks - What are the advantages and disadvantages of Markov random fields?\n",
    "\n",
    "##### Advantages\n",
    "\n",
    "- *Applicable for Variable Dependencies Without Natural Directionality*\n",
    "- *Succinctly Express Dependencies Not Easily Expressible in Bayesian Networks*\n",
    "\n",
    "##### Disadvantages\n",
    "\n",
    "- *Cannot Express Dependencies Easily Expressible in Bayesian Networks*\n",
    "    - *e.g., V-Structures*\n",
    "- *Computing Normalization Constant $Z$ Is NP-Hard*\n",
    "- *Generally Require Approximation Techniques*\n",
    "- *Difficult to Interpret*\n",
    "- *Easier to Construct Bayesian Networks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moralization - What is moralization?\n",
    "\n",
    "![Moralization](images/MRF_1.png)\n",
    "\n",
    "- Bayesian networks are a special case of Markov random fields with factors corresponding to conditional probability distributions and a normalizing constant of one.\n",
    "- **Moralization**: Bayesian Network $\\to$ Markov Random Field\n",
    "    1. Add side edges to all parents of a given node.\n",
    "    2. Remove the directionality of all the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $n$-Variable Independencies in Undirected Graphs - How do you identify independent variables in a $n$-variable Markov random field?\n",
    "\n",
    "1. If variables $X$ and $Y$ are connected by a path of unobserved variables, then $X$ and $Y$ are dependent.\n",
    "2. If variable $X$'s neighbors are all observed, then $X$ is independent of all the other variables.\n",
    "3. If a set of observed variables forms a cut-set between two halves of the graph, then variables in one half are independent from ones in the other.\n",
    "\n",
    "##### Cut-Set Variable Independencies\n",
    "\n",
    "![Cut-Set Variable Independencies](images/MRF_2.png)\n",
    "\n",
    "##### Markov Blanket\n",
    "\n",
    "- The **Markov blanket** $U$ of a variable $X$ is the minimal set of nodes such that $X$ is independent from the rest of the graph if $U$ is observed.\n",
    "$$X \\perp (\\mathcal{X} - \\{X\\} - U) \\mid U$$\n",
    "- In an undirected graph, the Markov blanket is a node's neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Random Fields - What are conditional random fields?\n",
    "\n",
    "##### Definition\n",
    "\n",
    "- A **conditional random field** is a Markov random field over variables $\\mathcal{X} \\cup \\mathcal{Y}$ which specifies a conditional distribution:\n",
    "$$\n",
    "\\begin{align}\n",
    "P(y \\mid x) &= \\frac{1}{Z(x)} \\prod_{c \\in C} \\phi_{c}(x_{c}, y_{c}) \\\\\n",
    "Z(x) &= \\sum_{y \\in \\mathcal{Y}} \\prod_{c \\in C} \\phi_{c}(x_{c}, y_{c})\n",
    "\\end{align}\n",
    "$$\n",
    "    - Where $x \\in \\mathcal{X}$ and $y \\in \\mathcal{Y}$ are **VECTOR-VALUED** variables.\n",
    "    - Where $Z(x)$ is the partition function.\n",
    "- **Important Note 1**: A conditional random field results in an instantiation of a new Markov random field for each input $x$.\n",
    "- **Important Note 2**: A conditional random field is useful for structured prediction in which the output labels are predicted considering the neighboring input samples.\n",
    "    - *See [Stanford CS228 - Markov Random Fields: Conditional Random Fields (OCR Example)](https://ermongroup.github.io/cs228-notes/representation/undirected/#conditional-random-fields).*\n",
    "\n",
    "##### Features\n",
    "\n",
    "- Assume the factors $\\phi_{c}(x_{c}, y_{c})$ are of the following form:\n",
    "$$\\phi_{c}(x_{c}, y_{c}) = \\exp(w_{c}^{T} f_{c}(x_{c}, y_{c}))$$\n",
    "    - Where $f_{c}(x_{c}, y_{c})$ can be an arbitrary set of features describing the compatibility between $x_{c}$ and $y_{c}$.\n",
    "    - Where $w_{c}^{T}$ is the transposed weight matrix.\n",
    "- Accordingly, $f_{c}(x_{c}, y_{c})$ allows arbitrarily complex features.\n",
    "    - e.g., $f(x, y_{i})$ are features that depend on the entirety of input samples $x$.\n",
    "    - e.g., $f(y_{i}, y_{i + 1})$ are features that depend on successive pairs of output labels $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditonal Random Fields vs. Markov Random Fields - Why is a conditional random field a special case of Markov random fields?\n",
    "\n",
    "- If we were to model $p(x, y)$ using a Markov random field, then we need to fit two probability distributions to the data: $p(y \\mid x)$ and $p(x)$.\n",
    "    - *Remember Baye's Rule*: $p(x, y) = p(y \\mid x) \\cdot p(x)$\n",
    "- However, if all we are interested in is predicting $y$ given $x$, then modeling $p(x)$ is expensive and unnecessary.\n",
    "$$\\text{Prediction} \\implies \\text{CRF} > \\text{MRF}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor Graphs - What is a factor graph? Why does a factor graph exist?\n",
    "\n",
    "![Factor Graph](images/MRF_3.png)\n",
    "\n",
    "- A **factor graph** is a bipartite graph where one group is the variables in the distribution being modeled, and the other group is the factors defined on these variables.\n",
    "    - *Edges Between Factors and Variables*\n",
    "- **Side Note**: A **bipartite graph** is a graph whose vertices are divided into two disjoint and independent sets.\n",
    "    - *Set 1: Variables*\n",
    "    - *Set 2: Factors*\n",
    "- **Important Note**: Use a factor graph to identify what variables a factor depends on when computing probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference <span name=\"S05\"></span>\n",
    "\n",
    "- **Problem**: *Given a probabilistic model, how do we obtain answers to relevant questions about the world?*\n",
    "    - **Marginal Inference**: *What is the probability of a given variable in our model after we sum everything else out?*\n",
    "$$p(y = 1) = \\sum_{x_{1}} \\sum_{x_{2}} \\cdots \\sum_{x_{n}} p(y = 1, x_{1}, x_{2}, ..., x_{n})$$\n",
    "        - e.g., What is the overall probability that an email is spam?\n",
    "        - *Perspective*: We desire to infer the general probability of some real-world phenomenon being observed.\n",
    "            - i.e., You care more about spam as a whole than specific instances of spam.\n",
    "    - **Maximum A Posteriori**: *What is the most likely assignment of variables?*\n",
    "$$\\max_{x_{1}, ..., x_{n}} p(y = 1, x_{1}, x_{2}, ..., x_{n})$$\n",
    "        - e.g., What is the set of words such that an email has the maximum probability of being spam?\n",
    "        - *Perspective*: We desire to infer the set of conditions that maximizes the probability of some real-world phenomenon being observed.\n",
    "            - i.e., You care more about identifying indicators of spam than detecting spam.\n",
    "    - *Naive Complexity*: NP-Hard **(DIFFICULT PROBLEM)**\n",
    "- **Solution**: *Exact Inference Algorithms & Approximate Inference Algorithms*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vairable Elimination (Exact Inference Algorithm) <span name=\"S06\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation - Why does the variable elimination algorithm exist?\n",
    "\n",
    "- Let $x_{i}$ be a discrete random variable that takes $k$ possible values.\n",
    "- **Problem**: *Marginal Inference*\n",
    "$$p(y = 1) = \\sum_{x_{1}} \\sum_{x_{2}} \\cdots \\sum_{x_{n}} p(y = 1, x_{1}, x_{2}, ..., x_{n})$$\n",
    "- **Naive Solution's Time Complexity** (*Exponential*): $O(k^{n})$\n",
    "    - *See [Rule of Product in Combinatorics](https://en.wikipedia.org/wiki/Rule_of_product)*\n",
    "- **Variable Elimination Solution's Time Complexity** (*Non-Exponential*): $O(n \\cdot k^{M + 1})$\n",
    "    - *See Below*.\n",
    "$$\\therefore \\text{Variable Elimination Solution} \\ll \\text{Naive Solution}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factors - How should a probabilistic graphical model express a probability distribution?\n",
    "\n",
    "- **Assumption**: *Probabilistic Graphical Models = Product of Factors*\n",
    "$$p(x_{1}, ..., x_{n}) = \\prod_{c \\in C} \\phi_{c}(x_{c})$$\n",
    "- **Representation**: A factor can be represented as a *multi-dimensional table* with a cell for each assignment of $x_{c}$.\n",
    "- *Bayesian Networks*: $\\phi$ is Conditional Probability Distribution\n",
    "- *Markov Random Fields*: $\\phi$ is Potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor Product - What is the product operation?\n",
    "\n",
    "![Example of Factor Product](images/VE_1.png)\n",
    "\n",
    "- Let $A$, $B$, and $C$ be three disjoint sets of variables.\n",
    "- Let $\\phi_{1}(A, B)$ and $\\phi_{2}(B, C)$ be two factors.\n",
    "- Let $\\phi_{3}(A, B, C)$ be the **factor product**.\n",
    "$$\\phi_{3}(A, B, C) = \\phi_{1}(A, B) \\cdot \\phi_{2}(B, C)$$\n",
    "    - Where the two factors are multiplied for common values of $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor Marginalization - What is the marginalization operation?\n",
    "\n",
    "![Example of Factor Marginalization](images/VE_2.png)\n",
    "\n",
    "- Let $A$, and $B$ be two disjoint sets of variables.\n",
    "- Let $\\phi(A, B)$ be a factor.\n",
    "- Let $\\tau(A)$ be the **factor marginalization** of $B$ in $\\phi$.\n",
    "$$\\tau(A) = \\sum_{B} \\phi(A, B)$$\n",
    "- **Important Note**: $\\tau$ does not need necessarily correspond to a probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordering - What is an ordering?\n",
    "\n",
    "- An **ordering** $O$ is the sequence of variables by which they will be eliminated.\n",
    "- Although any ordering can be used, different orderings may dramatically alter the running time of the variable elimination algorithm.\n",
    "- **Important Note**: *Finding Best Ordering = NP-Hard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm - How does the variable elimination algorithm work?\n",
    "\n",
    "- For each variable $X_{i}$ (ordered according to $O$),\n",
    "    1. Multiply all factors $\\Phi_{i}$ containing $X_{i}$.\n",
    "    2. Marginalize out $X_{i}$ to obtain a new factor $\\tau$.\n",
    "    3. Replace the factors $\\Phi_{i}$ with $\\tau$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Complexity - What is the time complexity of variable elimination?\n",
    "\n",
    "- **Time Complexity**: $O(n \\cdot k^{M + 1})$\n",
    "    - Where $n$ is the number of variables\n",
    "    - Where $M$ is the maximum number of dimensions of any factor $\\tau$ formed during the elimination process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordering Heuristics - How should you choose an ordering for variable elimination?\n",
    "\n",
    "- **Minimum Neighbors**: Choose a variable with the fewest dependent variables.\n",
    "- **Minimum Weight**: Choose variables to minimize the product of the cardinalities of its dependent variables.\n",
    "- **Minimum Fill**: Choose vertices to minimize the size of the factor that will be added to the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evidence - How do you perform marginal inference given some evidence using variable elimination?\n",
    "\n",
    "- Given a probability distribution $P(X, Y, E)$ with unobserved variables $X$, query variables $Y$, and observed evidence variables $E$, $P(Y \\mid E = e)$ can be calculated using variable elimination.\n",
    "$$P(Y \\mid E = e) = \\frac{P(Y, E = e)}{P(E = e)}$$\n",
    "\n",
    "##### Variable Elimination with Evidence\n",
    "\n",
    "1. Set every factor $\\phi(X', Y', E')$ with values specified by $E = e$.\n",
    "2. Compute $P(Y, E = e)$ by performing variable elimination over $X$.\n",
    "3. Compute $P(E = e)$ by performing variable elimination over $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Problem 1 - Variable Elimination\n",
    "\n",
    "![Problem 1 - Variable Elimination](images/VE_P1.png)\n",
    "\n",
    "- A Bayesian network that models a student's grade on an exam:\n",
    "    - $g$ is a ternary variable of the student's grade.\n",
    "    - $d$ is a binary variable of the exam's difficulty.\n",
    "    - $i$ is a binary variable of the student's intelligence.\n",
    "    - $l$ is a binary variable of the quality of a reference letter from the professor who taught the course.\n",
    "    - $s$ is a binary variable of the student's SAT score.\n",
    "$$p(l, g, i, d, s) = p(l \\mid g) \\cdot p(s \\mid i) \\cdot p(i) \\cdot p(g \\mid i, d) \\cdot p(d)$$\n",
    "\n",
    "##### Question (Marginal Inference)\n",
    "\n",
    "- What is the probability distribution of the quality of a reference letter from the professor who taught the course?\n",
    "$$p(l) = \\sum_{g} \\sum_{i} \\sum_{d} \\sum_{s} p(l, g, i, d, s)$$\n",
    "\n",
    "##### Solution (Variable Elimination)\n",
    "\n",
    "1. Order the variables according to the topological sort of the Bayesian network.\n",
    "$$d, i, s, g$$\n",
    "2. Eliminate $d$ with a new factor $\\tau_{1}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tau_{1}(g, i) &= \\sum_{d} p(g \\mid i, d) \\cdot p(d) \\\\\n",
    "p(l, g, i, s) &= p(l \\mid g) \\cdot p(s \\mid i) \\cdot p(i) \\cdot \\tau_{1}(g, i)\n",
    "\\end{align}\n",
    "$$\n",
    "3. Eliminate $i$ with a new factor $\\tau_{2}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tau_{2}(g, s) &= \\sum_{i} p(s \\mid i) \\cdot p(i) \\cdot \\tau_{1}(g, i) \\\\\n",
    "p(l, g, s) &= p(l \\mid g) \\cdot \\tau_{2}(g, s)\n",
    "\\end{align}\n",
    "$$\n",
    "4. Eliminate $s$ with a new factor $\\tau_{3}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tau_{3}(g) &= \\sum_{s} \\tau_{2}(g, s) \\\\\n",
    "p(l, g) &= p(l \\mid g) \\cdot \\tau_{3}(g)\n",
    "\\end{align}\n",
    "$$\n",
    "5. Eliminate $g$ with a new factor $\\tau_{4}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tau_{4}(l) &= \\sum_{g} p(l \\mid g) \\cdot \\tau_{3}(g) \\\\\n",
    "p(l) &= \\tau_{4}(l)\n",
    "\\end{align}\n",
    "$$\n",
    "6. Expanding $\\tau_{i}$:\n",
    "$$p(l) = \\sum_{g} p(l \\mid g) \\cdot \\sum_{s} \\sum_{i} p(s \\mid i) \\cdot p(i) \\cdot \\sum_{d} p(g \\mid i, d) \\cdot p(d)$$\n",
    "\n",
    "##### Time Complexity\n",
    "\n",
    "- **Naive Solution**: $O(k^{4})$\n",
    "- **Variable Elimination Solution**: $O(4 \\cdot k^{3})$\n",
    "    - Step 2. takes $O(k^{3})$ steps as the factor product $p(g \\mid i, d) \\cdot p(d)$ has a $3$-dimensional table representation, and the factor marginalization of $d$ can execute concurrently with the factor product.\n",
    "    - Step 3. takes $O(k^{3})$ steps as the factor product $p(s \\mid i) \\cdot p(i) \\cdot \\tau_{1}(g, i)$ has a $3$-dimensional table representation, and the factor marginalization of $i$ can execute concurrently with the factor product.\n",
    "    - Step 4. takes $O(k)$ steps for the factor marginalization of $s$.\n",
    "    - Step 5. takes $O(k^{2})$ steps as the factor product $p(l \\mid g) \\cdot \\tau_{3}(g)$ has a $2$-dimensional table representation, and the factor marginalization of $g$ can execute concurrently with the factor product.\n",
    "    - As $O(k^{3})$ is the largest step, with $4$ steps, the time complexity is at most $O(4 \\cdot k^{3})$.\n",
    "    - **Thus, with $n = 4$ and $M = 2$, the time complexity is at most $O(n \\cdot k^{M + 1}) = O(4 \\cdot k^{3})$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP Inference <span name=\"S07\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview - What is MAP inference?\n",
    "\n",
    "- *See [Inference](#S05).*\n",
    "- Given a probabilistic graphical model $p(x_{1}, ..., x_{n}) = \\prod_{c \\in C} \\phi_{c}(x_{c})$, MAP inference corresponds to the following optimization problem:\n",
    "$$\\max_{x} \\log p(x) = \\max_{x} \\sum_{c \\in C} \\theta_{c}(x_{c}) - \\log Z$$\n",
    "    - Where $\\theta_{c}(x_{c}) = \\log \\phi_{c}(x_{c})$\n",
    "    \n",
    "##### Derivation - Why is the MAP inference optmization problem expressed the way it is?\n",
    "\n",
    "\n",
    "1. All probabilistic graphical models (as BNs and CRFs are special cases of MRFs) have the following representation:\n",
    "$$p(x) = \\frac{1}{Z} \\prod_{c \\in C} \\phi_{c}(x_{c})$$\n",
    "    - Where $Z$ is NP-Hard\n",
    "2. MAP inference desires to infer the set of conditions that maximizes the probability of some real-world phenomenon being observed.\n",
    "$$\\max_{x} p(x) = \\max_{x} \\frac{1}{Z} \\prod_{c \\in C} \\phi_{c}(x_{c})$$\n",
    "3. As $Z$ is expensive to calculate, maximize $\\log p(x)$ instead of $p(x)$.\n",
    "$$\\max_{x} \\log p(x) = \\max_{x} \\log \\left[ \\frac{1}{Z} \\prod_{c \\in C} \\phi_{c}(x_{c}) \\right]$$\n",
    "4. Simplify using logarithmic identities.\n",
    "    - $\\log(x \\times y) = \\log(x) + \\log(y)$\n",
    "    - $\\log(x \\div y) = \\log(x) - \\log(y)$\n",
    "$$\\max_{x} \\log p(x) = \\max_{x} \\left[ \\sum_{c} \\log \\phi_{c}(x_{c}) - \\log Z \\right]$$\n",
    "5. Simplify using maximum identities.\n",
    "    - $\\max_{x}(x \\pm 1) = \\max_{x}(x) \\pm 1$\n",
    "$$\\max_{x} \\log p(x) = \\max_{x} \\sum_{c} \\log \\phi_{c}(x_{c}) - \\log Z$$\n",
    "6. Let $\\theta_{c}(x_{c}) = \\log \\phi_{c}(x_{c})$.\n",
    "$$\\max_{x} \\log p(x) = \\max_{x} \\sum_{c \\in C} \\theta_{c}(x_{c}) - \\log Z$$\n",
    "\n",
    "\n",
    "- As $\\log Z$ is outside the scope of the maximization, if you desire to infer the set of conditions that maximizes the probability of some real-world phenomenon being observed, then solve the following optimization problem:\n",
    "$$\\arg \\max_{x} \\log p(x) = \\arg \\max_{x} \\sum_{c \\in C} \\theta_{c}(x_{c})$$\n",
    "- **Important Note 1**: Without $Z$, this optimization problem suggests that MAP inference is computationally cheaper than marginal inference questions.\n",
    "- **Important Note 2**: As maximization and summation both distribute over products, techniques used to solve marginal inference problems can be used to solve MAP inference problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Cuts - How can MAP inference problems be solved using graph cuts?\n",
    "\n",
    "- A **graph cut** of an undirected graph $G = (V, E)$ is a partition of $V$ into two disjoint sets $V_{s}$ and $V_{t}$.\n",
    "- The **min-cut** problem is to find the partition $V_{s}, V_{t}$ that minimize the cost of the graph cut.\n",
    "    - The cost of a graph cut is the sum of the nonnegative costs of the edges that cross between the two partitions:\n",
    "$$\\text{cost}(V_{s}, V_{t}) = \\sum_{v_{1} \\in V_{s}, v_{2} \\in V_{t}} \\text{cost}(v_{1}, v_{2})$$\n",
    "    - **Time Complexity 1**: $O(\\lvert E \\rvert \\lvert V \\rvert \\log \\lvert V \\rvert)$\n",
    "    - **Time Complexity 2**: $O({\\lvert V \\rvert}^{3})$\n",
    "- A MAP inference problem can be reduced into the min-cut problem in certain restricted cases of MRFs with binary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Programming - How can MAP inference problems be solved using linear programming?\n",
    "\n",
    "- An approximate approach to computing the MAP values is to use Integer Linear Programming by introducing:\n",
    "    - An indicator variable per variable in the PGM.\n",
    "    - An indicator variable per edge/clique in the PGM.\n",
    "    - Constraints on consistent values in cliques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Search - How can MAP inference problems be solved using local search?\n",
    "\n",
    "- A heuristic solution that starts with an arbitrary assignment and performs modifications on the joint assignment that locally increase the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Branch and Bound - How can MAP inference problems be solved using branch and bound?\n",
    "\n",
    "- An exhaustive solution that searches over the space of assignments while pruning branches that can be provably shown not to contain a MAP assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulated Annealing - How can MAP inference problems be solved using simulated annealing?\n",
    "\n",
    "- A sampling solution that expresses a probability distribution with the following:\n",
    "$$p_{t}(x) \\propto \\exp\\left( \\frac{1}{t} \\sum_{c \\in C} \\theta_{c}(x_{c}) \\right)$$\n",
    "    - Where $t$ is temperature.\n",
    "        - $t \\to \\infty$ $\\implies$ $p_{t}$ approaches a continuous uniform distribution.\n",
    "        - $t \\to 0$ $\\implies$ $p_{t}$ approaches a continuous exponential distribution with a significant peak of $\\arg \\max_{x} \\sum_{c \\in C} \\theta_{c}(x_{c})$.\n",
    "- As the peak is a MAP assignment, a sampling algorithm starting with a high temperature which gradually decreases can eventually find the peak, given a sufficiently slow cooling rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling-Based Inference <span name=\"S08\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview - Why does sampling-based inference algorithms exist?\n",
    "\n",
    "- **Exact Inference Algorithms**: Slow/NP-Hard\n",
    "- **Approximate Inference Algorithms**: Marginal Inference, MAP Inference, Expectations\n",
    "\n",
    "##### Expectations $\\mathbb{E}[f(X)]$ - Why do we want to estimate expectations of random variables?\n",
    "\n",
    "- Abstractly, approximate inference algorithms want to estimate the probability of some real-world phenomenon.\n",
    "- Mathematically, estimating a probability $p(x)$ is a **SPECIALIZATION** of estimating an expectation $\\mathbb{E}_{x \\sim p}[f(x)] = \\sum_{x} f(x)p(x)$\n",
    "- If $f(x) = \\mathbb{I}_{\\lvert x \\rvert}$, where $\\mathbb{I}_{\\lvert x \\rvert}$ is an indicator function for event $x$,\n",
    "$$\\mathbb{E}_{x \\sim p}[\\mathbb{I}_{\\lvert x \\rvert}] = p(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Sampling - How do you sample a discrete CPD?\n",
    "\n",
    "\n",
    "1. Let $p$ be a multinomial probability distribution with event values $\\{x^{1}, ..., x^{k}\\}$ and event probabilities $\\{\\theta_{1}, ..., \\theta_{k}\\}$.\n",
    "2. Generate a sample $s$ uniformly from the interval $[0, 1]$.\n",
    "3. Partition the interval into $k$ subintervals:\n",
    "$$[0, \\theta_{1}), [\\theta_{1}, \\theta_{1} + \\theta_{2}), ..., \\left[ \\sum_{j = 1}^{i - 1} \\theta_{j}, \\sum_{j = 1}^{i} \\theta_{j} \\right)$$\n",
    "4. If $s$ is in the $i$th interval, then the sampled value is $x^{i}$.\n",
    "\n",
    "\n",
    "- **Time Complexity**: $O(\\log k)$ - *Using Binary Search*\n",
    "- *Remember Baye's Rule*: $p(y \\mid x) = \\frac{p(x, y)}{p(x)}$\n",
    "    - $p(x, y)$ is a multinomial probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Sampling - How do you sample a discrete Bayesian network?\n",
    "\n",
    "\n",
    "1. Let $G$ be a Bayesian network representing a probability distribution $p(x_{1}, ..., x_{n})$.\n",
    "2. Sample the variables in a topological order.\n",
    "3. Sample the successor variables by conditioning these node's CPDs to the values sampled by their ancestors.\n",
    "4. Repeat until all $n$ variables have been sampled.\n",
    "\n",
    "\n",
    "- **Time Complexity**: $O(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte Carlo Estimation - How do you take a large number of samples and estimate expectations?\n",
    "\n",
    "- *Monte Carlo $\\approx$ Large Number of Samples*\n",
    "$$\\mathbb{E}_{x \\sim p}[f(x)] \\approx I_{T} = \\frac{1}{T} \\sum_{t = 1}^{T} f(x^{t})$$\n",
    "    - Where $x^{1}, ..., x^{T}$ are [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) samples drawn according to $p$.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{x^{1}, ..., x^{T} \\sim^{\\text{i.i.d.}} p}[I_{T}] &=  \\mathbb{E}_{x \\sim p}[f(x)] \\\\\n",
    "\\text{Var}_{x^{1}, ..., x^{T} \\sim^{\\text{i.i.d.}} p}[I_{T}] &= \\frac{1}{T} \\text{Var}_{x \\sim p}[f(x)]\n",
    "\\end{align}\n",
    "$$\n",
    "    - Where the Monte Carlo estimate $I_T$\n",
    "    \n",
    "##### Implications - What is important about Monte Carlo estimations?\n",
    "\n",
    "1. $I_{T}$ is an unbiased estimator for $\\mathbb{E}_{x \\sim p}[f(x)]$.\n",
    "2. Referencing the [Weak Law of Large Numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers), if $T \\to \\infty$, then $I_{T} \\to \\mathbb{E}_{x \\sim p}[f(x)]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rejection Sampling - How does rejection sampling work?\n",
    "\n",
    "- Compute a target probability distribution $p(x)$ by sampling a proposal probability distribution $q(x)$, rejecting samples inconsistent with $p(x)$, and applying the Monte Carlo estimation.\n",
    "    - **Examples**: *See [Rejection Sampling](https://ermongroup.github.io/cs228-notes/inference/sampling/)*\n",
    "    - **Disadvantage**: *Ignores Many Samples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance Sampling - How does importance sampling work?\n",
    "\n",
    "- Compute a target probability distribution $p(x)$ by sampling a proposal probability distribution $q(x)$, reweighing samples with $w(x) = \\frac{p(x)}{q(x)}$, and applying the Monte Carlo estimation.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{x \\sim p}[f(x)] &= \\sum_{x} f(x)p(x) \\\\\n",
    "&= \\sum_{x} f(x)\\frac{p(x)}{q(x)}q(x) \\\\\n",
    "&= \\mathbb{E}_{x \\sim q}[f(x)w(x)] \\\\\n",
    "&\\approx \\frac{1}{T} \\sum_{t = 1}^{T} f(x^{t})w(x^{t})\n",
    "\\end{align}\n",
    "$$\n",
    "    - **Examples**: *See [Importance Sampling](https://ermongroup.github.io/cs228-notes/inference/sampling/)*\n",
    "    - **Advantage**: *Uses All Samples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Importance Sampling - How does normalized importance sampling work?\n",
    "\n",
    "1. Let $p(x)$ be unknown.\n",
    "2. Let $\\tilde{p}(x) = Z \\cdot p(x)$ be known.\n",
    "3. The weight $w(x) = \\frac{\\tilde{p}(x)}{q(x)}$ is invalid for unnormalized importance sampling.\n",
    "4. The **normalizing constant** of the distribution $\\tilde{p}(x)$ is the following:\n",
    "$$\\mathbb{E}_{x \\sim q}[w(x)] = \\sum_{x} q(x)\\frac{\\tilde{p}(x)}{q(x)} = \\sum_{x} \\tilde{p}(x) = Z$$\n",
    "5. The **normalized importance sampling estimator** is the following:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{x \\sim p}[f(x)] &= \\sum_{x} f(x)p(x) \\\\\n",
    "&= \\sum_{x} f(x)\\frac{p(x)}{q(x)}q(x) \\\\\n",
    "&= \\frac{1}{Z} \\sum_{x} f(x)\\frac{\\tilde{p}(x)}{q(x)}q(x) \\\\\n",
    "&= \\frac{1}{Z} \\mathbb{E}_{x \\sim q}[f(x)w(x)] \\\\\n",
    "&= \\frac{\\mathbb{E}_{x \\sim q}[f(x)w(x)]}{\\mathbb{E}_{x \\sim q}[w(x)]}\n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
