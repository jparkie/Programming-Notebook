{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 457A - Cooperative and Adaptive Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligence\n",
    "\n",
    "- **Intelligence**: The ability to acquire and apply knowledge and skills.\n",
    "- **Artificial Intelligence**: The science of creating intelligent machines, including intelligent computer programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rational Thinking & Rational Behavior\n",
    "\n",
    "- **Rational System**: A logical system that optimizes a given set of criteria.\n",
    "- **Rational Thinking**: A logical system that achieves goals via logical inferencing.\n",
    "- **Rational Behavior**: A logical system that perceives its environment and acts to achieve goals according to some set of beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "- **Agent**: Senses its environment and acts on collected information.\n",
    "- **Rational Agent**: An agent that acts in a way that is expected to maximize performance on the basis of perceptual history and built-in knowledge.\n",
    "\n",
    "#### Types of Agents\n",
    "\n",
    "- **Simple Reflex Agents**: Follow a lookup-table approach; needs fully observable environment.\n",
    "- **Model-Based Reflex Agents**: Add state information to handle partially observable environments.\n",
    "- **Goal-Based Agents**: Add concept of goals to help choose actions.\n",
    "- **Utility-Based Agents**: Add utility to decide \"good\" or \"bad\" when face with conflicting goals.\n",
    "- **Learning Agents**: Add ability to learn from experience to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments\n",
    "\n",
    "- **Fully vs. Partially Observable**:\n",
    "    - *Fully Observable*: Sensors can detect all aspects relevant to the choice of an action.\n",
    "    - *Partially Observable*: Missing Information or Inaccurate Sensors.\n",
    "- **Deterministic vs. Stochastic**:\n",
    "    - *Deterministic*: Environments that are only influenced by their current state and the next action executed by the agent.\n",
    "    - *Stochastic*: Randomness/Noise.\n",
    "- **Episodic vs. Sequential**:\n",
    "    - *Episodic*: The choice of an action in each episode does not depend on previous episodes.\n",
    "    - *Sequential*: An agent is required to \"think ahead\".\n",
    "- **Static vs. Dynamic**: N/A.\n",
    "- **Discrete vs. Continuous**: N/A.\n",
    "- **Single Agent vs. Multi Agent**: N/A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooperative and Adaptive Algorithms\n",
    "\n",
    "- **Cooperative**: Solve Joint Problems.\n",
    "- **Adaptive**: Change Behavior While Running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of Search Problems\n",
    "\n",
    "- Large, Non-Polynomial Search Space Size\n",
    "- Large, Non-Polynomial Constraints Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-Structured vs. Ill-Structured Problems\n",
    "\n",
    "- **Well-Structured Problems**: Problems for which the existing state and desired state are clearly identified, and the methods to reach the desired state are fairly obvious.\n",
    "- **Ill-Structured Problems**: Situation in which its existing state and the desired state are unclear and, hence, methods of reaching the desired state cannot be found.\n",
    "    1. Start & Improve Guess\n",
    "    2. Search Alternatives\n",
    "    4. Forward Search from Problem to Answer\n",
    "    5. Backward Search from Goal to Problem Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Problems\n",
    "\n",
    "- **Optimization Problem**: Finding the best solutions from a set of solutions subject to a set of constraints.\n",
    "\n",
    "\n",
    "#### Types of Optimization Algorithms\n",
    "\n",
    "- **Exact Algorithms**:\n",
    "    - Find Optimal Solution\n",
    "    - High Computational Cost\n",
    "- **Approximate Algorithms**:\n",
    "    - Find Near-Optimal Solution\n",
    "    - Low Computational Cost\n",
    "    \n",
    "#### Approximate Algorithms\n",
    "\n",
    "- **Heuristics**: A solution strategy or rules by trial and error to produce acceptable (optimal or sub-optimal) solutions to complex problems in a reasonably practical time.\n",
    "- **Constructive Methods**: A solution is constructed by iteratively introducing a new component.\n",
    "- **Local Search Methods**: An initial solution is improved by iteratively applying actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal and Problem Formulation\n",
    "\n",
    "- *Requirements for Search: Goal Formulation + Problem Formulation*\n",
    "- *Closed World Assumption: All necessary information about a problem domain is available in each percept so that each state is a complete description of the world.*\n",
    "\n",
    "#### Problem Formulation Template\n",
    "\n",
    "- **State Space**: Complete/Partial Configuration of Problem\n",
    "    - *Required: Each State = **UNIQUE***\n",
    "- **Initial State**: Beginning Search State\n",
    "- **Goal State**: Ending Search State\n",
    "- **Action Set**: Set of Possible State Transitions\n",
    "- **Cost**: Comparison Function between Solutions\n",
    "\n",
    "#### Extra Terminologies\n",
    "\n",
    "- **State**: Any Possible Agent/Problem Configuration\n",
    "- **Transition Model**: Action Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Search Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Tree Terminology\n",
    "\n",
    "- **Node**: Search Problem State\n",
    "- **Edge**: Search Problem Action\n",
    "- **Fringe**: Frontier/Leaves of Search Tree\n",
    "- **Branching Factor ($b$)**: The maximum number of child nodes extending from a parent node.\n",
    "- **Maximum Depth ($m$)**: The number of edges in the shortest path from the root node to the furthest leaf node.\n",
    "- **Optimal Goal Depth ($d$)**: the number of edges in the shortest path from the root node to an optimal goal node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Search Algorithms\n",
    "\n",
    "- **Completeness**: Guarantee Find A Goal Node\n",
    "- **Optimality**: Guarantee Find Best Goal Node\n",
    "- **Time Complexity**: # of Nodes Generated\n",
    "- **Space Complexity**: # of Nodes Stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Search\n",
    "\n",
    "\n",
    "- *Fringe = Queue-Like Data Structure*\n",
    "\n",
    "\n",
    "1. Choose Node\n",
    "2. Test Node\n",
    "3. Expand Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Search Strategies\n",
    "\n",
    "- **Uninformed Strategies**: No knowledge of the direction of goal nodes.\n",
    "    - Breadth-First\n",
    "    - Depth-First\n",
    "    - Depth-Limited\n",
    "    - Uniform-Cost\n",
    "    - Depth-First Iterative Deepening\n",
    "    - Bidirectional\n",
    "- **Informed Strategies**: Domain knowledge of the direction of goal nodes.\n",
    "    - Hill Climbing\n",
    "    - Best-First\n",
    "    - Greedy Search\n",
    "    - Beam Search\n",
    "    - A\n",
    "    - A*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uninformed Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth-First Search\n",
    "\n",
    "- Expand the shallowest unexpanded nodes, storing the fringe to be expanded in a FIFO queue.\n",
    "\n",
    "#### Properties of Breadth-First Search\n",
    "\n",
    "- *Completeness*:\n",
    "    - Yes - If $b$ is Finite\n",
    "- *Optimality*:\n",
    "    - Yes - If Cost = Depth\n",
    "- *Time Complexity*: $O(b^{d + 1}) \\approx O(b^d)$\n",
    "- *Space Complexity*: $O(b^{d + 1}) \\approx O(b^d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Cost Search\n",
    "\n",
    "- Expand the lowest cost unexpanded node, storing the fringe to be expanded in a minimum priority queue.\n",
    "- **Required**: *No Zero/Negative-Cost Edges*\n",
    "\n",
    "#### Properties of Uniform Cost Search\n",
    "\n",
    "- Let $C^*$ be the path cost to the goal.\n",
    "- Let $\\epsilon$ be the minimum cost of all other actions.\n",
    "- *Completeness*:\n",
    "    - Yes - If $b$ is Finite\n",
    "- *Optimality*: Yes\n",
    "- *Time Complexity*: $O(b^{\\frac{C^*}{\\epsilon} + 1}) \\approx O(b^d)$\n",
    "- *Space Complexity*: $O(b^{\\frac{C^*}{\\epsilon} + 1}) \\approx O(b^d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth-First Search\n",
    "\n",
    "- Expand the deepest unexpanded nodes, storing the fringe to be expanded in a LIFO stack.\n",
    "\n",
    "#### Properties of Depth-First Search\n",
    "\n",
    "- *Completeness*:\n",
    "    - No - If Search Space with Infinite-Depth/Loops\n",
    "- *Optimality*: No\n",
    "- *Time Complexity*: $O(b^m)$\n",
    "- *Space Complexity*: $O(bm)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth-Limited Search\n",
    "\n",
    "- Execute DFS with a maximum search depth as a restriction.\n",
    "    - Prevents Infinite-Depth Problem\n",
    "    - Prevents Loops Problem\n",
    "\n",
    "#### Properties of Depth-Limited Search\n",
    "\n",
    "- Let $l$ be the maximum search depth.\n",
    "- *Completeness*:\n",
    "    - Yes - If Solution's Depth $d \\le l$\n",
    "- *Optimality*: No\n",
    "- *Time Complexity*: $O(b^l)$\n",
    "- *Space Complexity*: $O(bl)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Deepening Search\n",
    "\n",
    "- Iteratively, execute DLS with an increasing maximum search depth $l$ until a solution is found.\n",
    "\n",
    "#### Properties of Iterative Deepening Search\n",
    "\n",
    "- *Completeness*:\n",
    "    - Yes - If $b$ is Finite\n",
    "- *Optimality*:\n",
    "    - Yes - If Cost = Depth\n",
    "- *Time Complexity*: $O(b^d)$\n",
    "- *Space Complexity*: $O(bd)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth-First vs. Depth-First Strategies\n",
    "\n",
    "#### Breadth-First Strategies\n",
    "\n",
    "- High Memory Requirement\n",
    "- Never Stuck on Infinite Depths\n",
    "- Find Shortest Path to Goal\n",
    "\n",
    "#### Depth-First Strategies\n",
    "\n",
    "- Low Memory Requirement\n",
    "- Stuck on Infinite Depths\n",
    "- Find Any Path to Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoiding Repeated States\n",
    "\n",
    "\n",
    "- *Increasing Computational Costs*:\n",
    "\n",
    "\n",
    "1. Do not return to the state your just came from.\n",
    "2. Do not create paths with cycles in them.\n",
    "3. Do not generate any state that was ever created before."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
