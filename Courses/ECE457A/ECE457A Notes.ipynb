{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 457A - Cooperative and Adaptive Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligence\n",
    "\n",
    "- **Intelligence**: The ability to acquire and apply knowledge and skills.\n",
    "- **Artificial Intelligence**: The science of creating intelligent machines, including intelligent computer programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rational Thinking & Rational Behavior\n",
    "\n",
    "- **Rational System**: A logical system that optimizes a given set of criteria.\n",
    "- **Rational Thinking**: A logical system that achieves goals via logical inferencing.\n",
    "- **Rational Behavior**: A logical system that perceives its environment and acts to achieve goals according to some set of beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "- **Agent**: Senses its environment and acts on collected information.\n",
    "- **Rational Agent**: An agent that acts in a way that is expected to maximize performance on the basis of perceptual history and built-in knowledge.\n",
    "\n",
    "#### Types of Agents\n",
    "\n",
    "- **Simple Reflex Agents**: Follow a lookup-table approach; needs fully observable environment.\n",
    "- **Model-Based Reflex Agents**: Add state information to handle partially observable environments.\n",
    "- **Goal-Based Agents**: Add concept of goals to help choose actions.\n",
    "- **Utility-Based Agents**: Add utility to decide \"good\" or \"bad\" when face with conflicting goals.\n",
    "- **Learning Agents**: Add ability to learn from experience to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments\n",
    "\n",
    "- **Fully vs. Partially Observable**:\n",
    "    - *Fully Observable*: Sensors can detect all aspects relevant to the choice of an action.\n",
    "    - *Partially Observable*: Missing Information or Inaccurate Sensors.\n",
    "- **Deterministic vs. Stochastic**:\n",
    "    - *Deterministic*: Environments that are only influenced by their current state and the next action executed by the agent.\n",
    "    - *Stochastic*: Randomness/Noise.\n",
    "- **Episodic vs. Sequential**:\n",
    "    - *Episodic*: The choice of an action in each episode does not depend on previous episodes.\n",
    "    - *Sequential*: An agent is required to \"think ahead\".\n",
    "- **Static vs. Dynamic**: N/A.\n",
    "- **Discrete vs. Continuous**: N/A.\n",
    "- **Single Agent vs. Multi Agent**: N/A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooperative and Adaptive Algorithms\n",
    "\n",
    "- **Cooperative**: Solve Joint Problems.\n",
    "- **Adaptive**: Change Behavior While Running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of Search Problems\n",
    "\n",
    "- Large, Non-Polynomial Search Space Size\n",
    "- Large, Non-Polynomial Constraints Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-Structured vs. Ill-Structured Problems\n",
    "\n",
    "- **Well-Structured Problems**: Problems for which the existing state and desired state are clearly identified, and the methods to reach the desired state are fairly obvious.\n",
    "- **Ill-Structured Problems**: Situation in which its existing state and the desired state are unclear and, hence, methods of reaching the desired state cannot be found.\n",
    "    1. Start & Improve Guess\n",
    "    2. Search Alternatives\n",
    "    4. Forward Search from Problem to Answer\n",
    "    5. Backward Search from Goal to Problem Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Problems\n",
    "\n",
    "- **Optimization Problem**: Finding the best solutions from a set of solutions subject to a set of constraints.\n",
    "\n",
    "\n",
    "#### Types of Optimization Algorithms\n",
    "\n",
    "- **Exact Algorithms**:\n",
    "    - Find Optimal Solution\n",
    "    - High Computational Cost\n",
    "- **Approximate Algorithms**:\n",
    "    - Find Near-Optimal Solution\n",
    "    - Low Computational Cost\n",
    "    \n",
    "#### Approximate Algorithms\n",
    "\n",
    "- **Heuristics**: A solution strategy or rules by trial and error to produce acceptable (optimal or sub-optimal) solutions to complex problems in a reasonably practical time.\n",
    "- **Constructive Methods**: A solution is constructed by iteratively introducing a new component.\n",
    "- **Local Search Methods**: An initial solution is improved by iteratively applying actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal and Problem Formulation\n",
    "\n",
    "- *Requirements for Search: Goal Formulation + Problem Formulation*\n",
    "- *Closed World Assumption: All necessary information about a problem domain is available in each percept so that each state is a complete description of the world.*\n",
    "\n",
    "#### Problem Formulation Template\n",
    "\n",
    "- **State Space**: Complete/Partial Configuration of Problem\n",
    "    - *Required*: Each State = **UNIQUE**\n",
    "- **Initial State**: Beginning Search State\n",
    "- **Goal State**: Ending Search State\n",
    "- **Action Set**: Set of Possible State Transitions\n",
    "- **Cost**: Comparison Function between Solutions\n",
    "\n",
    "#### Extra Terminologies\n",
    "\n",
    "- **State**: Any Possible Agent/Problem Configuration\n",
    "- **Transition Model**: Action Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Search Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Tree Terminology\n",
    "\n",
    "- **Node**: Search Problem State\n",
    "- **Edge**: Search Problem Action\n",
    "- **Fringe**: Frontier/Leaves of Search Tree\n",
    "- **Branching Factor ($b$)**: The maximum number of child nodes extending from a parent node.\n",
    "- **Maximum Depth ($m$)**: The number of edges in the shortest path from the root node to the furthest leaf node.\n",
    "- **Optimal Goal Depth ($d$)**: the number of edges in the shortest path from the root node to an optimal goal node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Search Algorithms\n",
    "\n",
    "- **Completeness**: Guarantee Find A Goal Node\n",
    "- **Optimality**: Guarantee Find Best Goal Node\n",
    "- **Time Complexity**: # of Nodes Generated\n",
    "- **Space Complexity**: # of Nodes Stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Search\n",
    "\n",
    "\n",
    "- *Fringe = Queue-Like Data Structure*\n",
    "\n",
    "\n",
    "1. Choose Node\n",
    "2. Test Node\n",
    "3. Expand Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Search Strategies\n",
    "\n",
    "- **Uninformed Strategies**: No knowledge of the direction of goal nodes.\n",
    "    - Breadth-First\n",
    "    - Depth-First\n",
    "    - Depth-Limited\n",
    "    - Uniform-Cost\n",
    "    - Depth-First Iterative Deepening\n",
    "    - Bidirectional\n",
    "- **Informed Strategies**: Domain knowledge of the direction of goal nodes.\n",
    "    - Hill Climbing\n",
    "    - Best-First\n",
    "    - Greedy Search\n",
    "    - Beam Search\n",
    "    - A\n",
    "    - A*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uninformed Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth-First Search\n",
    "\n",
    "- Expand the shallowest unexpanded nodes, storing the fringe to be expanded in a FIFO queue.\n",
    "\n",
    "#### Properties of Breadth-First Search\n",
    "\n",
    "- *Completeness*:\n",
    "    - Yes - If $b$ is Finite\n",
    "- *Optimality*:\n",
    "    - Yes - If Cost = Depth\n",
    "- *Time Complexity*: $O(b^{d + 1}) \\approx O(b^d)$\n",
    "- *Space Complexity*: $O(b^{d + 1}) \\approx O(b^d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Cost Search\n",
    "\n",
    "- Expand the lowest cost unexpanded node, storing the fringe to be expanded in a minimum priority queue.\n",
    "- **Required**: *No Zero/Negative-Cost Edges*\n",
    "\n",
    "#### Properties of Uniform Cost Search\n",
    "\n",
    "- Let $C^*$ be the path cost to the goal.\n",
    "- Let $\\epsilon$ be the minimum cost of all other actions.\n",
    "- *Completeness*:\n",
    "    - Yes - If $b$ is Finite\n",
    "- *Optimality*: Yes\n",
    "- *Time Complexity*: $O(b^{\\frac{C^*}{\\epsilon} + 1}) \\approx O(b^d)$\n",
    "- *Space Complexity*: $O(b^{\\frac{C^*}{\\epsilon} + 1}) \\approx O(b^d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth-First Search\n",
    "\n",
    "- Expand the deepest unexpanded nodes, storing the fringe to be expanded in a LIFO stack.\n",
    "\n",
    "#### Properties of Depth-First Search\n",
    "\n",
    "- *Completeness*:\n",
    "    - No - If Search Space with Infinite-Depth/Loops\n",
    "- *Optimality*: No\n",
    "- *Time Complexity*: $O(b^m)$\n",
    "- *Space Complexity*: $O(bm)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth-Limited Search\n",
    "\n",
    "- Execute DFS with a maximum search depth as a restriction.\n",
    "    - Prevents Infinite-Depth Problem\n",
    "    - Prevents Loops Problem\n",
    "\n",
    "#### Properties of Depth-Limited Search\n",
    "\n",
    "- Let $l$ be the maximum search depth.\n",
    "- *Completeness*:\n",
    "    - Yes - If Solution's Depth $d \\le l$\n",
    "- *Optimality*: No\n",
    "- *Time Complexity*: $O(b^l)$\n",
    "- *Space Complexity*: $O(bl)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Deepening Search\n",
    "\n",
    "- Iteratively, execute DLS with an increasing maximum search depth $l$ until a solution is found.\n",
    "\n",
    "#### Properties of Iterative Deepening Search\n",
    "\n",
    "- *Completeness*:\n",
    "    - Yes - If $b$ is Finite\n",
    "- *Optimality*:\n",
    "    - Yes - If Cost = Depth\n",
    "- *Time Complexity*: $O(b^d)$\n",
    "- *Space Complexity*: $O(bd)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth-First vs. Depth-First Strategies\n",
    "\n",
    "#### Breadth-First Strategies\n",
    "\n",
    "- High Memory Requirement\n",
    "- Never Stuck on Infinite Depths\n",
    "- Find Shortest Path to Goal\n",
    "\n",
    "#### Depth-First Strategies\n",
    "\n",
    "- Low Memory Requirement\n",
    "- Stuck on Infinite Depths\n",
    "- Find Any Path to Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoiding Repeated States\n",
    "\n",
    "\n",
    "- *Increasing Computational Costs*:\n",
    "\n",
    "\n",
    "1. Do not return to the state your just came from.\n",
    "2. Do not create paths with cycles in them.\n",
    "3. Do not generate any state that was ever created before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informed Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "- Apply domain knowledge in a problem to search the \"most promising\" branches first.\n",
    "- Potentially, find solutions faster or cheaper than uninformed search algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics\n",
    "\n",
    "- A **heuristic function** $h(n)$ can be used to estimate the \"goodness\" of node $n$.\n",
    "    - $\\forall n, h(n) \\ge 0$\n",
    "    - $h(n) = 0$ $\\implies$ $n$ is a goal node.\n",
    "    - $h(n) = \\infty$ $\\implies$ $n$ is a dead end that does not lead to a goal.\n",
    "- **Admissible/Optimistic**: If a heuristic function never overestimates the cost of reaching the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong vs. Weak Methods\n",
    "\n",
    "- **Strong Methods**: *Specific Approach to Some Problems*\n",
    "- **Weak Methods**: *General Approach to Many Problems*\n",
    "\n",
    "#### Examples of Weak Methods\n",
    "\n",
    "- **Mean-End Analysis**: A strategy where a representation is formed for the current and goal state, and actions are analyzed that shrink the difference between the two.\n",
    "- **Space Splitting**: A strategy where possible solutions to a problem are listed, and then classes of these solutions are ruled out to shrink the search space.\n",
    "- **Subgoaling**: A strategy where a large problem is split into independent smaller ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best-First Search/Greedy Search\n",
    "\n",
    "- *~Uniform Cost Search with Priority Queue*\n",
    "    - Minimize $f(n) \\mapsto h(n)$\n",
    "    - Greedy If $f(n) = h(n)$\n",
    "\n",
    "#### Properties of Best-First Search/Greedy Search\n",
    "\n",
    "- *Completeness*:\n",
    "    - No - Stuck in Loops\n",
    "- *Optimality*:\n",
    "    - No\n",
    "- *Time Complexity*: $O(b^m)$\n",
    "- *Space Complexity*: $O(b^m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "\n",
    "- *~Breadth-First Search + Reduced Memory Requirements*\n",
    "    - Expands Best $\\beta$ (*Beam Width*) Nodes Per Level\n",
    "\n",
    "#### Properties of Beam Search\n",
    "\n",
    "- *Admissible*:\n",
    "    - No\n",
    "- *Completeness*:\n",
    "    - No\n",
    "- *Optimality*:\n",
    "    - No\n",
    "- *Time Complexity*: $O(\\beta b)$\n",
    "- *Space Complexity*: $O(\\beta b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Search/A&ast; Search\n",
    "\n",
    "- *A Search: Best-First Search with $f(n) = g(n) + h(n)$*\n",
    "    - $g(n)$ is the cost from the start to $n$.\n",
    "    - $h(n)$ is the cost from $n$ to the goal.\n",
    "- *A&ast; Search: Constraint $h(n)\n",
    "\\le h^{*}(n)$*\n",
    "    - $h^{*}(n)$ is the actual minimal path cost from $n$ to the goal.\n",
    "\n",
    "#### Properties of A Search\n",
    "\n",
    "- *Admissible*:\n",
    "    - No\n",
    "- *Completeness*:\n",
    "    - No - If $h(n) \\to \\infty$\n",
    "- *Optimality*:\n",
    "    - No\n",
    "\n",
    "#### Properties of A&ast; Search\n",
    "\n",
    "- *Admissible*:\n",
    "    - Yes - If $h(n) \\le h^{*}(n)$*\n",
    "- *Completeness*:\n",
    "    - Yes - If $b$ is finite and only fixed positive costs.\n",
    "- *Optimality*:\n",
    "    - Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hill Climbing Search\n",
    "\n",
    "\n",
    "- *Improvement of Depth-First Search*\n",
    "- *~Beam Search with $\\beta = 1$*\n",
    "- *~Greedy Search with No Backtracking*\n",
    "- *Not Complete at Local Minima, Plateaus, Ridges*\n",
    "\n",
    "\n",
    "1. Start with an arbitrary solution.\n",
    "2. Attempt to improve the solution by changing a single element at a time.\n",
    "3. Sort the successors of a node according to their heuristic values, and then adding them to the list to be expanded.\n",
    "4. Make changes until no further improvements can be found.\n",
    "\n",
    "#### Rule of Hill Climbing Search\n",
    "\n",
    "- If there is a successor $s$ for node $n$ such that:\n",
    "    - $h(s) < h(n)$ and\n",
    "    - $h(s) \\le h(t)$ for all successors $t$ of $n$.\n",
    "- True $\\implies$ Advance from $n$ to $s$.\n",
    "- False $\\implies$ Halt at $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics\n",
    "\n",
    "- **Perfect Heuristic**: If $h(n) = h^{*}(n)$, then only nodes on the optimal solution are expanded.\n",
    "- **Null Heuristic**: If $h(n) = 0$, then A&ast behaves like uniform cost search.\n",
    "- **Better Heuristic**: If $h_{1}(n) < h_{2}(n) < h^{*}(n)$, then $h_{2}$ is a better heuristic than $h_{1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Playing as Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "- Games involve playing against an opponent, where search problems involve finding a good move, waiting for an opponent's response, and then repeating.\n",
    "- Time is typically limited in each search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Formulation of Games\n",
    "\n",
    "- **Initial State**: *Initial Position + Whose Move It Is*\n",
    "- **Operators**: *Legal Player Moves*\n",
    "- **Goal (Terminal Test)**: *Is Game Over?*\n",
    "- **Utility (Payoff)**: *Measures Outcome/Desirability*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Games\n",
    "\n",
    "- **Perfect Information**: Each player has complete information on the opponent's state and available choices.\n",
    "- **Imperfect Information**: Each player does not have complete information on the opponent's state and available choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Min Strategy\n",
    "\n",
    "- With perfect information and two players, a game tree can be expanded to describe all possible moves of the player and the opponent in the game.\n",
    "- **Zero Sum Games**: *Player Win $\\implies$ Opponent Loss*\n",
    "- **Minimax Principle**: *Minimize the maximum losses that occur.*\n",
    "\n",
    "#### Minimax Algorithm\n",
    "\n",
    "![Example of Minimax Algorithm](images/Minimax_Algorithm_1.png)\n",
    "\n",
    "\n",
    "- **Important Note**: *Bottom-Up*\n",
    "\n",
    "\n",
    "1. Generate the game tree labeling each level with alternating $\\text{MAX}(player)$ and $\\text{MIN}(opponent)$ labels.\n",
    "2. Apply the utility function to each terminal state (leaf) to get its minimax value.\n",
    "3. Extrapolate these minimax values to determine the utility of the nodes on level higher in the search tree.\n",
    "    - For a $\\text{MAX}(player)$ level, select the maximum minimax value of its successors.\n",
    "    - For a $\\text{MIN}(opponent)$ level, select the minimum minimax value of its successors.\n",
    "4. From the root node, select the move which leads to the highest minimax value.\n",
    "\n",
    "#### Limited Depth\n",
    "\n",
    "- For complicated games, a limited depth of the game tree should be explored.\n",
    "- An **evaluation function $f(n)$** is used to measure the \"goodness\" of a game state.\n",
    "\n",
    "#### Properties of Minimax Algorithm\n",
    "\n",
    "- *Completeness*:\n",
    "    - Yes - If game tree is finite\n",
    "- *Optimality*:\n",
    "    - Yes - If opponent is optimal\n",
    "- *Time Complexity*: $O(b^{d})$\n",
    "- *Space Complexity*: $O(bd)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\alpha$-$\\beta$ Pruning\n",
    "\n",
    "- *Branch and Bound: Reduce # of Generated/Evaluated Nodes*\n",
    "    - *Avoid Processing Subtrees $\\ne$ Affecting Result*\n",
    "- **Alpha ($\\alpha$)**: The best value for $\\text{MAX}$ seen so far.\n",
    "    - Used in $\\text{MIN}$ nodes\n",
    "    - Assigned in $\\text{MAX}$ nodes\n",
    "    - Never Decreases\n",
    "- **Beta ($\\beta$)**: The best value for $\\text{MIN}$ seen so far.\n",
    "    - Used in $\\text{MAX}$ nodes\n",
    "    - Assigned in $\\text{MIN}$ nodes\n",
    "    - Never Increases\n",
    "- **Alpha Cutoff** (*Lower Bound*): When the value of a minimum position is less than or equal to the alpha-value of its parent, stop generating further successors.\n",
    "- **Beta Cutoff** (*Upper Bound*): When the value of a maximum position is greater than the beta-value of its parent, stop generating further successors.\n",
    "\n",
    "#### $\\alpha$-$\\beta$ Minimax Algorithm Revisions\n",
    "\n",
    "1. Search discontinued below any $\\text{MIN}$ with $\\beta \\le \\alpha$ of one of its ancestors.\n",
    "    - Set final value of the node to be this $\\beta$ value.\n",
    "2. Search discontinued below any $\\text{MAX}$ with $\\alpha \\ge \\beta$ of one of its ancestors.\n",
    "    - Set final value of the node to be this $\\alpha$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaheuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "![Overview of Metaheuristic Methods](images/Metaheuristics_1.png)\n",
    "\n",
    "- **Metaheuristics**: High-level heuristics designed to select other heuristics to solve a problem by exploring and exploiting its search space.\n",
    "    - *Approximate Solutions*\n",
    "    - *Nondeterministic Solutions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "- Mechanisms to avoid getting trapped in confined areas of the search space.\n",
    "- Not problem-specific; may use domain-specific knowledge from heuristics controlled by upper-level strategy.\n",
    "- Search history to guide te search.\n",
    "- Hybrid search models where the search identifies neighborhoods where a goal may lie, and then the search is intensified in that area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population-Based Methods\n",
    "\n",
    "- Population-based methods are metaheuristic approaches that apply multiple agents to a search space and can handle multiple simultaneous solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Methods\n",
    "\n",
    "- Trajectory methods are metaheuristic variants of local search that apply memory structure to avoid getting stuck at local minima, and implement an explorative strategy that tries to avoid revisiting nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physical Annealing Analogy\n",
    "\n",
    "- Physical annealing involves heating a substance (e.g. a metal) and then letting it cool to increase its ductility and reduce hardness.\n",
    "- The goal is to make the molecules in a cooled substances arrange themselves in a low-energy structure, and the properties of this structure are inuenced by the temperatures reached and the rate of cooling.\n",
    "- A sequence of cooling times and temperatures is referred to as an annealing or cooling schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing Algorithm\n",
    "\n",
    "\n",
    "- Let $s = s_{0}$ be a current solution initialized to $s_{0}$.\n",
    "- Let $t = t_{0}$ be a current temperature initialized to $t_{0}$.\n",
    "- Let $\\alpha$ be a temperature reduction function.\n",
    "\n",
    "\n",
    "1. Repeat,\n",
    "    1. Repeat,\n",
    "        1. Select a solution $s_{i}$ from the neighborhood $N(s)$.\n",
    "        2. Calculate the change in cost $\\Delta C$.\n",
    "        3. If $\\Delta C < 0$, then accept the new solution: $s = s_{i}$.\n",
    "        4. Else, generate a random number $x \\in (0, 1)$.\n",
    "        5. If $x < \\exp(\\frac{-\\Delta C}{t})$, then accept the new solution: $s = s_{i}$.\n",
    "    2. Until maximum number of iteration for $t$.\n",
    "    3. Decrease $t$ using $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "![Simulated Annealing Strategy](images/Simulated_Annealing_1.png)\n",
    "\n",
    "- Simulated annealing always accepts better solutions.\n",
    "- Simulated annealing randomly accepts worse solutions.\n",
    "- At higher temperatures, explore parameter space.\n",
    "- At lower temperatures, restrict exploration.\n",
    "\n",
    "$$\\text{ Low Temperature } \\wedge \\text{ High Change in Cost } \\implies \\text{ Low Acceptance Probability }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annealing Schedule\n",
    "\n",
    "- **Annealing Schedule**: *Adjusts Temperature*\n",
    "    - *Initial Temperature*\n",
    "    - *Final Temperature*\n",
    "    - *Temperature Decrement Rule*\n",
    "    - *Temperature Iterations*\n",
    "    \n",
    "#### Initial Temperature\n",
    "\n",
    "- The initial temperature should be high enough to allow exploration to any part of the search space.\n",
    "- If the initial temperature is too hot, simulated annealing would behave too randomly.\n",
    "- The maximum change of a cost function should be considered when setting the initial temperature.\n",
    "- **General Rule**: Set the initial temperature to accept around $60\\%$ of worse solutions.\n",
    "\n",
    "#### Final Temperature\n",
    "\n",
    "- The final temperature should be quite low but not neccessarily have to reach zero.\n",
    "- A search using simulated annealing can be stopped once no better moves are being found and no worse moves are being accepted.\n",
    "\n",
    "#### Temperature Decrement Rule\n",
    "\n",
    "- **Linear**: $t = t - \\alpha$\n",
    "- **Geometric**: $t = t \\times alpha$\n",
    "- **Slow Decrease**: $t = \\frac{t}{1 + \\beta t}$\n",
    "\n",
    "#### Temperature Iterations\n",
    "\n",
    "- Enough iterations should be allowed at every temperature for the system to be stable at that temperature.\n",
    "- If the search space is very large, a large number of iterations may be required.\n",
    "- If the slow decrease rule is used, one iteration per temperature should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence\n",
    "\n",
    "- Simulated annealing is guaranteed to eventually converge to a solution at a constant temperature, assuming some sequence of moves leads to the goal state.\n",
    "- When temperature is not constant, convergence can still be guaranteed but only under conditions that result in very slow temperature reduction and an exponential increase in the number of iterations at each temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "- Easy\n",
    "- Widely Applicable\n",
    "\n",
    "#### Disadvantages\n",
    "\n",
    "- Time Complexity\n",
    "- Many Tunable Parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
